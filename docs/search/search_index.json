{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ML cube Platform","text":"<p>Welcome to the official ML cube Platform documentation site. Here you can find everything you need to start using the product.</p>"},{"location":"api/","title":"Client SDK","text":"<p>ML cube Platform allows interaction through REST APIs:</p> <ul> <li> Python \u2013 Install Python Client on your environment</li> <li> REST \u2013 Use directly the API</li> <li> EXAMPLES - Jupyer Notebook examples</li> </ul>"},{"location":"api/examples/","title":"Examples","text":"<p>We wrote for you a set of notebooks that can help you to understand how to use ML cube Platform SDK:</p> <ul> <li>0 - Company and Project</li> <li>1 - Task and Model</li> <li>2 - Production</li> </ul>"},{"location":"api/python/","title":"ml3-platform-sdk","text":"<p>ML3 platform client SDK</p>"},{"location":"api/python/client/","title":"Client","text":""},{"location":"api/python/client/#ml3platformclient","title":"ML3PlatformClient","text":"<pre><code>ML3PlatformClient(\nurl: str, api_key: str\n)\n</code></pre> <p>Client class is the single point of interaction with ML cube Platform APIs, it is initialized providing the <code>url</code> and the User <code>api_key</code>. Every operation is performed verifying the API Key and the permissions associated to the User that own that key.</p>"},{"location":"api/python/client/#methods-categories","title":"Methods categories","text":"<p>There are the following types of methods:</p> <ul> <li>entity creation: create the entity and return its identifier. It is used in the other methods to indicate the entity.</li> <li>entity update: modify the entity but do not return anything.</li> <li>entity getters: return a Pydantic <code>BaseModel</code> with the required entity.</li> <li>entity show: print to the stdout the entity, but they do not return anything.</li> <li>entity delete: delete the entity</li> <li>job submission: submit a job on ML cube Platform that will take some time. They return the job identifier that can be used to monitor its state.</li> <li>job waiters: given a job id wait the until the job is completed</li> </ul>"},{"location":"api/python/client/#exceptions","title":"Exceptions","text":"<p>The Client class raises only exceptions that are subclasses of <code>SDKClientException</code>. The exception has two fields that you can share with ML cube Support to get help in identifying the problem:</p> <ul> <li>error_code: unique identifier of the error</li> <li>error_message: message that explain the error</li> </ul> <p>The page is structured in different blocks of methods, one for each entity.</p> <p>Methods:</p>"},{"location":"api/python/client/#create_company","title":".create_company","text":"<pre><code>.create_company(\nname: str, address: str, vat: str\n)\n</code></pre> <p>Create a company for the User, this method works only is the User has not a company yet. After the Company is created the User is the Company Owner.</p> <p>Args</p> <ul> <li>name  : the name of the company</li> <li>address  : the address of the company</li> <li>vat  : the vat of the company</li> </ul> <p>Returns</p> <ul> <li>company_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateCompanyException</code></p>"},{"location":"api/python/client/#get_company","title":".get_company","text":"<pre><code>.get_company()\n</code></pre> <p>Returns the company of the User</p> <p>Returns</p> <ul> <li>company  : <code>Company</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_company","title":".update_company","text":"<pre><code>.update_company(\nname: Optional[str], address: Optional[str], vat: Optional[str]\n)\n</code></pre> <p>Update company information.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : new the of the company</li> <li>address  : new billing address for the company</li> <li>vat  : new vat of the company</li> </ul> <p>Raises</p> <p><code>UpdateCompanyException</code></p>"},{"location":"api/python/client/#create_project","title":".create_project","text":"<pre><code>.create_project(\nname: str, description: Optional[str], default_storage_policy: StoragePolicy\n)\n</code></pre> <p>Create a project inside the company. You don't need to specify the company because a User belongs only to one company and it is retrieved automatically.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : the name of the project</li> <li>description  : optional description of the project</li> <li>default_storage_policy  : represents the default policy to     use for storing data in ML cube Platform</li> </ul> <p>Returns</p> <ul> <li>project_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateProjectException</code></p>"},{"location":"api/python/client/#get_projects","title":".get_projects","text":"<pre><code>.get_projects()\n</code></pre> <p>Get the list of all projects in the company the User has permissions to view.</p> <p>Returns</p> <ul> <li>projects_list  : <code>List[Project]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_project","title":".get_project","text":"<pre><code>.get_project(\nproject_id: str\n)\n</code></pre> <p>Get a project with the given id</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_project","title":".update_project","text":"<pre><code>.update_project(\nproject_id: str, name: Optional[str], description: Optional[str],\ndefault_storage_policy: Optional[StoragePolicy]\n)\n</code></pre> <p>Update project details.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> <li>name  : new name of the project</li> <li>description  : new description of the project</li> <li>default_storage_policy  : represents the default policy to     use for storing data in ML cube Platform</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>UpdateProjectException</code></p>"},{"location":"api/python/client/#show_projects","title":".show_projects","text":"<pre><code>.show_projects()\n</code></pre> <p>Show a list all projects printing to stdout.</p> <p>Example output: <pre><code>Project ID                Name\n------------------------  ----------\n6475f8c9ebac5081e529s63f  my project\n</code></pre></p>"},{"location":"api/python/client/#create_task","title":".create_task","text":"<pre><code>.create_task(\nproject_id: str, name: str, tags: List[str], task_type: TaskType\n)\n</code></pre> <p>Create a task inside the project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task</li> <li>task_type  : the type of the task. See <code>TaskType</code>     documentation for more information</li> </ul> <p>Returns</p> <ul> <li>task_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateTaskException</code></p>"},{"location":"api/python/client/#get_tasks","title":".get_tasks","text":"<pre><code>.get_tasks(\nproject_id: str\n)\n</code></pre> <p>Get the list of the Tasks inside the project.</p> <p>Args</p> <ul> <li>project_id  : identifier of the project</li> </ul> <p>Returns</p> <ul> <li>task_list  : <code>List[Task]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_task","title":".get_task","text":"<pre><code>.get_task(\ntask_id: str\n)\n</code></pre> <p>Get task by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>task  : <code>Task</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_tasks","title":".show_tasks","text":"<pre><code>.show_tasks(\nproject_id: str\n)\n</code></pre> <p>Show a list of tasks included in a project to stdout.</p> <p>Args</p> <ul> <li>project_id  : the identifier of a project</li> </ul> <p>Example output: <pre><code>Task ID                   Name     Type            Status     Status start date\n------------------------  -------  --------------  --------   -----------------\n6476040d583201813ab4539a  my task  classification  OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/client/#create_model","title":".create_model","text":"<pre><code>.create_model(\ntask_id: str, name: str, version: str, metric_name: ModelMetricName\n)\n</code></pre> <p>Create a model inside the task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the model</li> <li>version  : the current version of the model</li> <li>metric_name  : performance or error metric associated with     the model</li> </ul> <p>Returns</p> <ul> <li>model_id  : <code>str</code> identifier of the created model</li> </ul> <p>Raises</p> <p><code>CreateModelException</code></p>"},{"location":"api/python/client/#get_models","title":".get_models","text":"<pre><code>.get_models(\ntask_id: str\n)\n</code></pre> <p>Get all models of a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>models_list  : <code>List[Model]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model","title":".get_model","text":"<pre><code>.get_model(\nmodel_id: str\n)\n</code></pre> <p>Get model by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : identifier of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model_by_name_and_version","title":".get_model_by_name_and_version","text":"<pre><code>.get_model_by_name_and_version(\ntask_id: str, model_name: str, model_version: str\n)\n</code></pre> <p>Get model by name and version.</p> <p>A Model can have multiple versions according to the updates and retraining done. This method allow to get the Model object by specifying its name and the version tag.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>model_name  : the name of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_models","title":".show_models","text":"<pre><code>.show_models(\ntask_id: str\n)\n</code></pre> <p>Show a list of models included in a task to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> </ul> <p>Example output: <pre><code>Model Id                  Task Id                   Name                    Version    Status           Status start timestamp    Status insert date          Metric Name\n------------------------  ------------------------  ----------------------  ---------  ---------------  ------------------------  --------------------------  --------------------\n64fecf7d323311ab78f17280  64fecf7c323311ab78f17262  model_local_experiment  v0.0.1     not_initialized                            2023-09-11 08:27:41.431000  ModelMetricName.RMSE\n</code></pre></p>"},{"location":"api/python/client/#get_suggestions","title":".get_suggestions","text":"<pre><code>.get_suggestions(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>Retrieve suggestions associated with a model.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>suggestion_list  : <code>List[Suggestion]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_suggestions","title":".show_suggestions","text":"<pre><code>.show_suggestions(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>Show the list of suggestions associated with a model printing them to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Example output: <pre><code>Suggestion Id                     Executed    Timestamp\n--------------------------------  ----------  --------------------------\n79a8710c351c4b6a9ece7322e153f200  True        2023-08-21 10:54:40.386189\n</code></pre></p> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_model_version_by_suggestion_id","title":".update_model_version_by_suggestion_id","text":"<pre><code>.update_model_version_by_suggestion_id(\nmodel_id: str, new_model_version: str, suggestion_id: str\n)\n</code></pre> <p>Update model version by suggestion id. To retrain the Model, ML cube Platform provides importance weights through a <code>Suggestion</code>. After the retraining is completed, you use this method to create the new model version in ML cube Platform. By specifying the <code>suggestion_id</code>, ML cube Platform automatically knows which is the reference data the model is trained on.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model</li> <li>suggestion_id  : the identifier of the suggestion</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> job identifier of the pipeline in execution</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p>"},{"location":"api/python/client/#update_model_version_from_raw_data","title":".update_model_version_from_raw_data","text":"<pre><code>.update_model_version_from_raw_data(\nmodel_id: str, new_model_version: str, features_data_source: DataSource,\ntargets_data_source: DataSource\n)\n</code></pre> <p>Update model version by suggestion id. To retrain the Model, ML cube Platform provides importance weights through a <code>Suggestion</code>. However, it is possible to train the model with new data that has been not already upload to ML cube Platform. After the retraining is completed, you use this method to create the new model version in ML cube Platform by specifying the data to load.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model</li> <li>dataset_type  :  Dataset type describes the nature                of data stored (DatasetType)</li> <li>features_data_source  : data source that contains features data</li> <li>targets_data_source  : data source that contains targets data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> job identifier of the pipeline in execution</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#add_data_schema","title":".add_data_schema","text":"<pre><code>.add_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Associate a data schema to a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the data schema that characterize your task</li> </ul> <p>Raises</p> <p><code>AddDataSchemaException</code></p>"},{"location":"api/python/client/#get_data_schema","title":".get_data_schema","text":"<pre><code>.get_data_schema(\ntask_id: str\n)\n</code></pre> <p>Get task data schema</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>data_schema  : <code>DataSchema</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_data_schema","title":".show_data_schema","text":"<pre><code>.show_data_schema(\ntask_id: str\n)\n</code></pre> <p>Show data schema of associated with a task</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p> <p>Example output:</p> <pre><code>Column name       Role     Type      Nullable\n----------------  -------  --------  ----------\nsample_id         id       string    False\ntimestamp         time_id  string    False\nsepallength       input    float     False\nsepalwidth        input    float     False\npetallength       input    float     False\npetalwidth        input    float     False\nclass             target   category  False\n</code></pre>"},{"location":"api/python/client/#update_data_schema","title":".update_data_schema","text":"<pre><code>.update_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Update an existing data schema</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the set of new columns that should be added to     the data schema</li> </ul> <p>Raises</p> <p><code>UpdateDataSchemaException</code></p>"},{"location":"api/python/client/#add_historical_data","title":".add_historical_data","text":"<pre><code>.add_historical_data(\ntask_id: str, features_data_source: DataSource, targets_data_source: DataSource\n)\n</code></pre> <p>Add a batch of historical data for the Task.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored</li> <li>features_data_source  : data source that contains features data</li> <li>targets_data_source  : data source that contains targets data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddHistoricalDataException</code></p>"},{"location":"api/python/client/#add_model_reference","title":".add_model_reference","text":"<pre><code>.add_model_reference(\nmodel_id: str, features_data_source: DataSource,\ntargets_data_source: DataSource\n)\n</code></pre> <p>Add a batch of reference data associated with a given model.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>dataset_type  :  Dataset type describes the nature of data stored</li> <li>features_data_source  : data source that contains features data</li> <li>targets_data_source  : data source that contains targets data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddModelReferenceException</code></p>"},{"location":"api/python/client/#add_production_data","title":".add_production_data","text":"<pre><code>.add_production_data(\ntask_id: str, features_data_source: Optional[DataSource] = None,\ntargets_data_source: Optional[DataSource] = None,\npredictions_data_sources: Optional[List[PredictionDataSourceInfo]] = None\n)\n</code></pre> <p>Add a batch of production data associated with a given task.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored</li> <li>features_data_source  : data source that contains features data. It can be None if you upload other kinds of data</li> <li>targets_data_source  : data source that contains targets data. It can be None if you upload other kinds of data</li> <li>predictions_data_sources  : list of data sources for each models' predictions. It can be None if you upload other kinds of data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddProductionDataException</code></p>"},{"location":"api/python/client/#create_kpi","title":".create_kpi","text":"<pre><code>.create_kpi(\nproject_id: str, name: str\n)\n</code></pre> <p>Create a KPI.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>name  : the name of the kpi</li> </ul> <p>Returns</p> <ul> <li>kpi_id  : <code>str</code> identifier of the created kpi</li> </ul> <p>Raises</p> <p><code>CreateKpiException</code></p>"},{"location":"api/python/client/#get_kpi","title":".get_kpi","text":"<pre><code>.get_kpi(\nkpi_id: str\n)\n</code></pre> <p>Get kpi by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>kpi_id  : identifier of the kpi</li> </ul> <p>Returns</p> <ul> <li>kpi  : <code>KPI</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_kpis","title":".get_kpis","text":"<pre><code>.get_kpis(\nproject_id: str\n)\n</code></pre> <p>Get all kpis of a project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : identifier of the project</li> </ul> <p>Returns</p> <ul> <li>kpis_list  : <code>List[KPI]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_kpis","title":".show_kpis","text":"<pre><code>.show_kpis(\nproject_id: str\n)\n</code></pre> <p>Show the list of KPIs included in a project to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> </ul> <p>Example output: <pre><code>KPI Id                    Project Id                Name                    Status           Status start timestamp    Status insert date\n------------------------  ------------------------  ----------------------  ---------------  ------------------------  --------------------------\n64fecf7d323311ab78f17280  64fecf7c323311ab78f17262  model_local_experiment  not_initialized                            2023-09-11 08:27:41.431000\n</code></pre></p>"},{"location":"api/python/client/#add_kpi_data","title":".add_kpi_data","text":"<pre><code>.add_kpi_data(\nproject_id: str, kpi_id: str, kpi_data_source: DataSource\n)\n</code></pre> <p>Add a batch of a given kpi with the given project.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>kpi_id  : the identifier of the kpi</li> <li>kpi_data_source  : data source that contains data.</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddKPIDataException</code></p>"},{"location":"api/python/client/#compute_retraining_report","title":".compute_retraining_report","text":"<pre><code>.compute_retraining_report(\nmodel_id: str\n)\n</code></pre> <p>Compute the retraining report for a given model</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>ComputeRetrainingReportException</code></p>"},{"location":"api/python/client/#get_retraining_report","title":".get_retraining_report","text":"<pre><code>.get_retraining_report(\nmodel_id: str\n)\n</code></pre> <p>For a given model id, get the sample weights computed and additional information about them included in the retraining report</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> </ul> <p>Returns</p> <ul> <li>retraining_report  : <code>RetrainingReport</code></li> </ul> <p>Raises</p> <p><code>GetRetrainingReportException</code></p>"},{"location":"api/python/client/#get_jobs","title":".get_jobs","text":"<pre><code>.get_jobs(\nproject_id: Optional[str] = None, task_id: Optional[str] = None,\nmodel_id: Optional[str] = None, status: Optional[JobStatus] = None,\njob_id: Optional[str] = None\n)\n</code></pre> <p>Get current jobs information. Jobs can be filtered by project_id, task_id, model_id or status.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the project_id to filter job.     If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job.     If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job.     If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job.     If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter.     If <code>None</code> job with every id will be retrieved</li> </ul> <p>Returns</p> <ul> <li>jobs_list  : <code>List[Job]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_job","title":".get_job","text":"<pre><code>.get_job(\njob_id: str\n)\n</code></pre> <p>Get current job information.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>job_id  : id of the job to retrieve</li> </ul> <p>Returns</p> <ul> <li>job  : <code>Job</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_jobs","title":".show_jobs","text":"<pre><code>.show_jobs()\n</code></pre> <p>Show current job information to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_detection_event_rules","title":".get_detection_event_rules","text":"<pre><code>.get_detection_event_rules(\ntask_id: str\n)\n</code></pre> <p>Get all detection event rules of a given task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : id of the task for which you want to retrieve the detection event rules</li> </ul> <p>Returns</p> <ul> <li>rules_list  : <code>List[DetectionEventRule]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_detection_event_rule","title":".get_detection_event_rule","text":"<pre><code>.get_detection_event_rule(\nrule_id: str\n)\n</code></pre> <p>Get a detection event rule by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : id of the rule</li> </ul> <p>Returns</p> <ul> <li>rule  : <code>DetectionEventRule</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_detection_event_rule","title":".create_detection_event_rule","text":"<pre><code>.create_detection_event_rule(\nname: str, task_id: str, model_id: str, severity: DetectionEventSeverity,\ndetection_event_type: DetectionEventType, monitoring_target: MonitoringTarget,\nactions: List[Union[DiscordNotificationAction, SlackNotificationAction]]\n)\n</code></pre> <p>Create a detection event rule.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : the name of the rule</li> <li>task_id  : the id of the task to which the rule belongs.     The rule will only respond to detection events     generated by this task.</li> <li>model_id  : the id of the model, only required if     event_type is set to PERFORMANCE.</li> <li>detection_event_type  : the type of detection event that     this rule should respond to.</li> <li>monitoring_target  : the type of monitoring target that     this rule should respond to.</li> <li>severity  : the level of severity of the detection event     that this rule should respond to.</li> <li>actions  : the list of actions to execute, in order,     when the conditions of the rule are matched.</li> </ul> <p>Returns</p> <ul> <li>rule_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateDetectionEventRuleException</code></p>"},{"location":"api/python/client/#update_detection_event_rule","title":".update_detection_event_rule","text":"<pre><code>.update_detection_event_rule(\nrule_id: str, name: Optional[str] = None, model_id: Optional[str] = None,\nseverity: Optional[DetectionEventSeverity] = None,\ndetection_event_type: Optional[DetectionEventType] = None,\nmonitoring_target: Optional[MonitoringTarget] = None,\nactions: Optional[List[Union[DiscordNotificationAction,\nSlackNotificationAction]]] = None\n)\n</code></pre> <p>Update a detection event rule.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : the id of the rule to update</li> <li>name  : the name of the rule. If None, keeps the existing value.</li> <li>model_id  : the id of the model, only required if event_type     is set to PERFORMANCE. If None, keeps the existing value.</li> <li>detection_event_type  : the type of detection event that this     rule should respond to. If None, keeps the existing value.</li> <li>monitoring_target  : the type of monitoring target that this     rule should respond to. If None, keeps the existing value.</li> <li>severity  : the level of severity of the detection event that     this rule should respond to. If None, keeps the     existing value.</li> <li>actions  : the list of actions to execute, in order, when the     conditions of the rule are matched. If None,      keeps the existing value.</li> </ul> <p>Raises</p> <p><code>CreateDetectionEventRuleException</code></p>"},{"location":"api/python/client/#delete_detection_event_rule","title":".delete_detection_event_rule","text":"<pre><code>.delete_detection_event_rule(\nrule_id: str\n)\n</code></pre> <p>Delete a detection event rule by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : id of the rule to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#wait_job_completion","title":".wait_job_completion","text":"<pre><code>.wait_job_completion(\njob_id: str, max_wait_timeout: int = 600\n)\n</code></pre> <p>Wait that the ML cube Platform job terminates successfully its execution.</p> <p>Note that this method stops the execution.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>job_id  : identifier of the job</li> <li>max_wait_timeout  : maximum amount of seconds to wait before     launching <code>JobWaitTimeoutException</code></li> </ul> <p>Raises</p> <ul> <li><code>JobWaitTimeoutException</code> when the maximum timeout time     is reached</li> <li><code>JobNotFoundException</code> when the requested job does not     exist</li> <li><code>JobFailureException</code> when the requested job is failed</li> </ul>"},{"location":"api/python/client/#create_company_user","title":".create_company_user","text":"<pre><code>.create_company_user(\nname: str, surname: str, username: str, password: str, email: str,\ncompany_role: UserCompanyRole\n)\n</code></pre> <p>Creates a new User in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> </ul> <p>Args</p> <ul> <li>name  : name of the user</li> <li>surname  : surname of the user</li> <li>username  : username of the user</li> <li>password  : temporary password for the user. It will change     this at the first login</li> <li>email  : email of the user</li> <li>company_role  : role of the user inside the company</li> </ul> <p>Returns</p> <ul> <li>user_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_company_users","title":".get_company_users","text":"<pre><code>.get_company_users()\n</code></pre> <p>Returns the list of users in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>users_list  : <code>List[CompanyUser]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#change_user_company_role","title":".change_user_company_role","text":"<pre><code>.change_user_company_role(\nuser_id: str, company_role: UserCompanyRole\n)\n</code></pre> <p>Change the company role of a user in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code>: can change the roles of all the Users     Users apart from other Admins and the Owner</li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which the role is updated</li> <li>company_role  : the new role to assign</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_company_users","title":".show_company_users","text":"<pre><code>.show_company_users()\n</code></pre> <p>Show company users to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_user_projects","title":".get_user_projects","text":"<pre><code>.get_user_projects(\nuser_id: str\n)\n</code></pre> <p>Returns a list of projects that the user can view.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> </ul> <p>Returns</p> <ul> <li>projects_list  : <code>List[Project]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_user_projects","title":".show_user_projects","text":"<pre><code>.show_user_projects(\nuser_id: str\n)\n</code></pre> <p>Shows the projects that the user can view to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#add_user_project_role","title":".add_user_project_role","text":"<pre><code>.add_user_project_role(\nuser_id: str, project_id: str, project_role: UserProjectRole\n)\n</code></pre> <p>Add a project role to the user for the given project.</p> <p>The User Project role can be assigned only to <code>COMPANY_USER</code> because Admin and Owner already have all the permission over projects.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> <li>project_id  : identifies the project</li> <li>project_role  : the project role to assign</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_project_role","title":".delete_project_role","text":"<pre><code>.delete_project_role(\nuser_id: str, project_id: str\n)\n</code></pre> <p>Delete the role of the user for the given project.</p> <p>The User Project role can be deleted only for <code>COMPANY_USER</code> because Admin and Owner have all the permission over projects.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> <li>project_id  : identifies the project</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_api_keys","title":".get_api_keys","text":"<pre><code>.get_api_keys()\n</code></pre> <p>Returns a list of api keys the user has.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>api_keys_list  : <code>List[ApiKey]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_api_keys","title":".show_api_keys","text":"<pre><code>.show_api_keys()\n</code></pre> <p>Shows the list of api keys the user has to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_api_key","title":".create_api_key","text":"<pre><code>.create_api_key(\nname: str, expiration_time: ApiKeyExpirationTime\n)\n</code></pre> <p>Create a new api key for the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>name  : the name of the api key</li> <li>expiration_time  : the expiration time of the api key</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_api_key","title":".delete_api_key","text":"<pre><code>.delete_api_key(\napi_key: str\n)\n</code></pre> <p>Delete the api key of the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>api_key  : api key to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_user_api_keys","title":".get_user_api_keys","text":"<pre><code>.get_user_api_keys(\nuser_id: str\n)\n</code></pre> <p>Get the list of api keys a user has.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to get his api keys</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_user_api_keys","title":".show_user_api_keys","text":"<pre><code>.show_user_api_keys(\nuser_id: str\n)\n</code></pre> <p>Shows the list of api keys a user has to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to get his api keys</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_user_api_key","title":".create_user_api_key","text":"<pre><code>.create_user_api_key(\nuser_id: str, name: str, expiration_time: ApiKeyExpirationTime\n)\n</code></pre> <p>Create a new api key for the user.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to create a new api key</li> <li>name  : the name of the api key</li> <li>expiration_time  : the expiration time of the api key</li> </ul> <p>Returns</p> <ul> <li>api_key  : the new created api key for the user</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_user_api_key","title":".delete_user_api_key","text":"<pre><code>.delete_user_api_key(\nuser_id: str, api_key: str\n)\n</code></pre> <p>Delete the api key of the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code>     Admin</li> </ul> <p>Args</p> <ul> <li>user_id  : the user to delete an api key</li> <li>api_key  : the api key to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#change_company_owner","title":".change_company_owner","text":"<pre><code>.change_company_owner(\nuser_id: str\n)\n</code></pre> <p>Change the company owner role from the requesting user to the other user.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user that become Company Owner</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_company_user","title":".delete_company_user","text":"<pre><code>.delete_company_user(\nuser_id: str\n)\n</code></pre> <p>Delete a user from the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code>: cannot delete other company admins</li> </ul> <p>Args</p> <ul> <li>user_id  : the user to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_integration_credentials","title":".get_integration_credentials","text":"<pre><code>.get_integration_credentials(\ncredentials_id: str\n)\n</code></pre> <p>Get the credentials with the given id for 3<sup>rd</sup> party service provider integration.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for the project where the credentials have been configured</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>credentials_id  : id of the integration credentials to retrieve.</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>IntegrationCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_all_project_integration_credentials","title":".get_all_project_integration_credentials","text":"<pre><code>.get_all_project_integration_credentials(\nproject_id: str\n)\n</code></pre> <p>Get the list of credentials for 3<sup>rd</sup> party service provider integrations that are currently configured in a project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : id of the project for which all configured credentials should be retrieved.</li> </ul> <p>Returns</p> <ul> <li>credentials_list  : <code>List[IntegrationCredentials]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_integration_credentials","title":".delete_integration_credentials","text":"<pre><code>.delete_integration_credentials(\ncredentials_id: str\n)\n</code></pre> <p>Delete credentials for the integration with a 3<sup>rd</sup> party  service provider.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project where the credentials have been configured</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code>: cannot delete other company admins</li> </ul> <p>Args</p> <ul> <li>credentials_id  : id of the integration credentials to delete.</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_aws_integration_credentials","title":".create_aws_integration_credentials","text":"<pre><code>.create_aws_integration_credentials(\nname: str, default: bool, project_id: str, role_arn: str\n)\n</code></pre> <p>Create credentials to integrate with AWS. Returns an object that contains the external_id you will need to configure in your trust policy.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>role_arn  : the ARN of the IAM role that will be assumed by ML     cube Platform</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>SecretAWSCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_gcp_integration_credentials","title":".create_gcp_integration_credentials","text":"<pre><code>.create_gcp_integration_credentials(\nname: str, default: bool, project_id: str, service_account_info_json: str\n)\n</code></pre> <p>Create credentials to integrate with GCP.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>service_account_info_json  : the json-encoded string     containing the key of the service account</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>GCPCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_azure_integration_credentials","title":".create_azure_integration_credentials","text":"<pre><code>.create_azure_integration_credentials(\nname: str, default: bool, project_id: str,\nservice_principal_credentials_json: str\n)\n</code></pre> <p>Create credentials to integrate with Azure.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>service_principal_credentials_json  : the json-encoded string     containing the credentials of the service principal</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>AzureCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/enums/","title":"Enums","text":""},{"location":"api/python/enums/#apikeyexpirationtime","title":"ApiKeyExpirationTime","text":"<pre><code>ApiKeyExpirationTime()\n</code></pre> <p>Fields:</p> <ul> <li>ONE_MONTH</li> <li>THREE_MONTHS</li> <li>SIX_MONTHS</li> <li>ONE_YEAR</li> <li>NEVER</li> </ul>"},{"location":"api/python/enums/#datasettype","title":"DatasetType","text":"<pre><code>DatasetType()\n</code></pre> <p>Fields:</p> <ul> <li>TABULAR</li> </ul>"},{"location":"api/python/enums/#detectioneventactiontype","title":"DetectionEventActionType","text":"<pre><code>DetectionEventActionType()\n</code></pre> <p>Fields:</p> <ul> <li>DISCORD_NOTIFICATION</li> <li>SLACK_NOTIFICATION</li> </ul>"},{"location":"api/python/enums/#detectioneventseverity","title":"DetectionEventSeverity","text":"<pre><code>DetectionEventSeverity()\n</code></pre> <p>Fields:</p> <ul> <li>LOW</li> <li>MEDIUM</li> <li>HIGH</li> </ul>"},{"location":"api/python/enums/#detectioneventtype","title":"DetectionEventType","text":"<pre><code>DetectionEventType()\n</code></pre> <p>Fields:</p> <ul> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#externalintegration","title":"ExternalIntegration","text":"<pre><code>ExternalIntegration()\n</code></pre> <p>An integration with a 3<sup>rd</sup> party service provider</p> <p>Fields: - AWS - GCP</p>"},{"location":"api/python/enums/#filetype","title":"FileType","text":"<pre><code>FileType()\n</code></pre> <p>Fields:</p> <ul> <li>CSV</li> <li>JSON</li> </ul>"},{"location":"api/python/enums/#jobstatus","title":"JobStatus","text":"<pre><code>JobStatus()\n</code></pre> <p>Fields:</p> <ul> <li>IDLE</li> <li>STARTING</li> <li>RUNNING</li> <li>COMPLETED</li> <li>ERROR</li> </ul>"},{"location":"api/python/enums/#kpistatus","title":"KPIStatus","text":"<pre><code>KPIStatus()\n</code></pre> <p>Fields:</p> <ul> <li>NOT_INITIALIZED</li> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#modelmetricname","title":"ModelMetricName","text":"<pre><code>ModelMetricName()\n</code></pre> <p>Name of the model metrics that is associated with the model</p> <p>Fields: - RMSE - RSQUARE</p>"},{"location":"api/python/enums/#modelstatus","title":"ModelStatus","text":"<pre><code>ModelStatus()\n</code></pre> <p>Fields:</p> <ul> <li>NOT_INITIALIZED</li> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#monitoringtarget","title":"MonitoringTarget","text":"<pre><code>MonitoringTarget()\n</code></pre> <p>Fields:</p> <ul> <li>MODEL</li> <li>INPUT</li> <li>CONCEPT</li> </ul>"},{"location":"api/python/enums/#storagepolicy","title":"StoragePolicy","text":"<pre><code>StoragePolicy()\n</code></pre> <p>Enumeration that specify the storage policy for the data sent to ML cube Platform</p> <p>Fields:     cloud     it needs to read data</p>"},{"location":"api/python/enums/#storingdatatype","title":"StoringDataType","text":"<pre><code>StoringDataType()\n</code></pre> <p>Fields:</p> <ul> <li>HISTORICAL</li> <li>REFERENCE</li> <li>PRODUCTION</li> </ul>"},{"location":"api/python/enums/#taskstatus","title":"TaskStatus","text":"<pre><code>TaskStatus()\n</code></pre> <p>Fields:</p> <ul> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#tasktype","title":"TaskType","text":"<pre><code>TaskType()\n</code></pre> <p>Fields:</p> <ul> <li>REGRESSION</li> <li>CLASSIFICATION</li> </ul>"},{"location":"api/python/enums/#usercompanyrole","title":"UserCompanyRole","text":"<pre><code>UserCompanyRole()\n</code></pre> <p>Fields:</p> <ul> <li>COMPANY_OWNER</li> <li>COMPANY_ADMIN</li> <li>COMPANY_USER</li> <li>COMPANY_NONE</li> </ul>"},{"location":"api/python/enums/#userprojectrole","title":"UserProjectRole","text":"<pre><code>UserProjectRole()\n</code></pre> <p>Fields:</p> <ul> <li>PROJECT_ADMIN</li> <li>PROJECT_USER</li> <li>PROJECT_VIEW</li> </ul>"},{"location":"api/python/exceptions/","title":"Exceptions","text":""},{"location":"api/python/exceptions/#adddataschemaexception","title":"AddDataSchemaException","text":"<pre><code>AddDataSchemaException()\n</code></pre> <p>AddDataSchemaException</p>"},{"location":"api/python/exceptions/#addhistoricaldataexception","title":"AddHistoricalDataException","text":"<pre><code>AddHistoricalDataException()\n</code></pre> <p>AddHistoricalDataException</p>"},{"location":"api/python/exceptions/#addkpidataexception","title":"AddKPIDataException","text":"<pre><code>AddKPIDataException()\n</code></pre> <p>AddKPIDataException</p>"},{"location":"api/python/exceptions/#addmodelreferenceexception","title":"AddModelReferenceException","text":"<pre><code>AddModelReferenceException()\n</code></pre> <p>AddModelReferenceException</p>"},{"location":"api/python/exceptions/#addproductiondataexception","title":"AddProductionDataException","text":"<pre><code>AddProductionDataException()\n</code></pre> <p>AddProductionDataException</p>"},{"location":"api/python/exceptions/#computeretrainingreportexception","title":"ComputeRetrainingReportException","text":"<pre><code>ComputeRetrainingReportException()\n</code></pre> <p>ComputeRetrainingReportException</p>"},{"location":"api/python/exceptions/#createcompanyexception","title":"CreateCompanyException","text":"<pre><code>CreateCompanyException()\n</code></pre> <p>CreateCompanyException</p>"},{"location":"api/python/exceptions/#createdetectioneventruleexception","title":"CreateDetectionEventRuleException","text":"<pre><code>CreateDetectionEventRuleException()\n</code></pre> <p>CreateDetectionEventRuleException</p>"},{"location":"api/python/exceptions/#createkpiexception","title":"CreateKPIException","text":"<pre><code>CreateKPIException()\n</code></pre> <p>CreateKPIEventRuleException</p>"},{"location":"api/python/exceptions/#createmodelexception","title":"CreateModelException","text":"<pre><code>CreateModelException()\n</code></pre> <p>CreateModelException</p>"},{"location":"api/python/exceptions/#createprojectexception","title":"CreateProjectException","text":"<pre><code>CreateProjectException()\n</code></pre> <p>CreateProjectException</p>"},{"location":"api/python/exceptions/#createtaskexception","title":"CreateTaskException","text":"<pre><code>CreateTaskException()\n</code></pre> <p>CreateTaskException</p>"},{"location":"api/python/exceptions/#getretrainingreportexception","title":"GetRetrainingReportException","text":"<pre><code>GetRetrainingReportException()\n</code></pre> <p>GetRetrainingReportException</p>"},{"location":"api/python/exceptions/#jobfailureexception","title":"JobFailureException","text":"<pre><code>JobFailureException()\n</code></pre> <p>JobFailureException</p>"},{"location":"api/python/exceptions/#jobnotfoundexception","title":"JobNotFoundException","text":"<pre><code>JobNotFoundException()\n</code></pre> <p>JobNotFoundException</p>"},{"location":"api/python/exceptions/#jobwaittimeoutexception","title":"JobWaitTimeoutException","text":"<pre><code>JobWaitTimeoutException()\n</code></pre> <p>JobWaitTimeoutException</p>"},{"location":"api/python/exceptions/#sdkclientexception","title":"SDKClientException","text":"<pre><code>SDKClientException(\nerror_code: str = 'UNEXPECTED', error_message: str = 'Anunexpectederroroccurred'\n)\n</code></pre> <p>Base class for client sdk exceptions</p>"},{"location":"api/python/exceptions/#updatecompanyexception","title":"UpdateCompanyException","text":"<pre><code>UpdateCompanyException()\n</code></pre> <p>UpdateCompanyException</p>"},{"location":"api/python/exceptions/#updatedataschemaexception","title":"UpdateDataSchemaException","text":"<pre><code>UpdateDataSchemaException()\n</code></pre> <p>UpdateDataSchemaException</p>"},{"location":"api/python/exceptions/#updatedetectioneventruleexception","title":"UpdateDetectionEventRuleException","text":"<pre><code>UpdateDetectionEventRuleException()\n</code></pre> <p>UpdateDetectionEventRuleException</p>"},{"location":"api/python/exceptions/#updatemodelversionexception","title":"UpdateModelVersionException","text":"<pre><code>UpdateModelVersionException()\n</code></pre> <p>UpdateModelVersionException</p>"},{"location":"api/python/exceptions/#updateprojectexception","title":"UpdateProjectException","text":"<pre><code>UpdateProjectException()\n</code></pre> <p>UpdateProjectException</p>"},{"location":"api/python/models/","title":"Models","text":""},{"location":"api/python/models/#awscredentials","title":"AWSCredentials","text":"<pre><code>AWSCredentials()\n</code></pre> <p>AWS integration credentials.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>role_arn  : The ARN of the role that should be assumed via STS</li> </ul>"},{"location":"api/python/models/#apikey","title":"ApiKey","text":"<pre><code>ApiKey()\n</code></pre> <p>base model for api key</p> <p>Attributes</p> <ul> <li>api_key  : str</li> </ul>"},{"location":"api/python/models/#azureblobdatasource","title":"AzureBlobDataSource","text":"<pre><code>AzureBlobDataSource()\n</code></pre> <p>A source that identifies a blob in Azure Storage.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul>"},{"location":"api/python/models/#azurecredentials","title":"AzureCredentials","text":"<pre><code>AzureCredentials()\n</code></pre> <p>Azure integration credentials.</p> <p>Attributes</p> <ul> <li>app_id  : The id of the service principal</li> </ul>"},{"location":"api/python/models/#columninfo","title":"ColumnInfo","text":"<pre><code>ColumnInfo()\n</code></pre> <p>Column base model</p> <p>Attributes</p> <ul> <li>name  : str</li> <li>data_type  : str</li> <li>role  : str</li> <li>is_nullable  : bool</li> <li>predicted_target  : Optional[str] = None</li> <li>possible_values  : Optional[List] = None</li> <li>model_id  : Optional[str] = None</li> </ul>"},{"location":"api/python/models/#company","title":"Company","text":"<pre><code>Company()\n</code></pre> <p>Company model</p> <p>Attributes</p> <ul> <li>company_id  : str</li> <li>name  : str</li> <li>address  : str</li> <li>vat  : str</li> </ul>"},{"location":"api/python/models/#companyuser","title":"CompanyUser","text":"<pre><code>CompanyUser()\n</code></pre> <p>base model for company user</p> <p>Attributes</p> <ul> <li>user_id  : str</li> <li>company_role  : UserCompanyRole</li> </ul>"},{"location":"api/python/models/#dataschema","title":"DataSchema","text":"<pre><code>DataSchema()\n</code></pre> <p>Data schema base model</p> <p>Attributes</p> <ul> <li>columns  : List[ColumnInfo]</li> </ul>"},{"location":"api/python/models/#datasource","title":"DataSource","text":"<pre><code>DataSource()\n</code></pre> <p>Generic data source.</p> <p>Attributes</p> <ul> <li>dataset_type  : DatasetType</li> </ul>"},{"location":"api/python/models/#detectioneventaction","title":"DetectionEventAction","text":"<pre><code>DetectionEventAction()\n</code></pre> <p>Generic action that can be performed</p> <p>Attributes</p> <ul> <li>type  : DetectionEventActionType</li> </ul>"},{"location":"api/python/models/#detectioneventrule","title":"DetectionEventRule","text":"<pre><code>DetectionEventRule(\n**kwargs\n)\n</code></pre> <p>A rule that can be triggered by a detection event, and executes a series of actions.</p> <p>Attributes</p> <ul> <li>rule_id  : str</li> <li>name  : str</li> <li>task_id  : str</li> <li>model_id  : Optional[str]</li> <li>severity  : DetectionEventSeverity</li> <li>detection_event_type  : DetectionEventType</li> <li>monitoring_target  : MonitoringTarget</li> <li>actions  : List[DetectionEventAction]</li> </ul>"},{"location":"api/python/models/#discordnotificationaction","title":"DiscordNotificationAction","text":"<pre><code>DiscordNotificationAction()\n</code></pre> <p>Action that sends a notification to a Discord server through a webhook that you configure</p> <p>Attributes</p> <ul> <li>webhook  : str type = DetectionEventActionType.DISCORD_NOTIFICATION</li> </ul>"},{"location":"api/python/models/#gcpcredentials","title":"GCPCredentials","text":"<pre><code>GCPCredentials()\n</code></pre> <p>GCP integration credentials.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>gcp_project_id  : The id of the project on GCP</li> <li>client_email  : The email that identifies the service account</li> <li>client_id  : The client id</li> </ul>"},{"location":"api/python/models/#gcsdatasource","title":"GCSDataSource","text":"<pre><code>GCSDataSource()\n</code></pre> <p>A source that identifies a file in a GCS bucket.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul>"},{"location":"api/python/models/#integrationcredentials","title":"IntegrationCredentials","text":"<pre><code>IntegrationCredentials()\n</code></pre> <p>Credentials to authenticate to a 3<sup>rd</sup> party service provider via an integration.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> </ul>"},{"location":"api/python/models/#job","title":"Job","text":"<pre><code>Job()\n</code></pre> <p>Job information item model</p> <p>Attributes</p> <ul> <li>job_id  : str</li> <li>job_group  : str</li> <li>project_id  : str</li> <li>project_name  : str</li> <li>task_id  : str</li> <li>task_name  : str</li> <li>model_id  : Optional[str]</li> <li>model_name  : Optional[str]</li> <li>status  : str</li> <li>error  : Optional[str]</li> </ul>"},{"location":"api/python/models/#kpi","title":"KPI","text":"<pre><code>KPI()\n</code></pre> <p>KPI base model</p> <p>Attributes</p> <ul> <li>kpi_id  : str</li> <li>name  : str</li> <li>status  : ModelStatus</li> <li>status_kpi_start_timestamp  : Optional[datetime]</li> <li>status_insert_datetime  : datetime</li> </ul>"},{"location":"api/python/models/#localdatasource","title":"LocalDataSource","text":"<pre><code>LocalDataSource()\n</code></pre> <p>Use this data source if you want to upload a file from your local disk to the ML cube platform cloud.</p> <p>Attributes</p> <ul> <li>file_path  : str</li> </ul>"},{"location":"api/python/models/#model","title":"Model","text":"<pre><code>Model()\n</code></pre> <p>Base model to define model item</p> <p>Attributes</p> <ul> <li>model_id  : str</li> <li>task_id  : str</li> <li>name  : str</li> <li>version  : str</li> <li>status  : ModelStatus</li> <li>status_data_start_timestamp  : Optional[datetime]</li> <li>status_insert_datetime  : datetime</li> <li>metric_name  : performance or error metric associated with     the model</li> </ul>"},{"location":"api/python/models/#predictiondatasourceinfo","title":"PredictionDataSourceInfo","text":"<pre><code>PredictionDataSourceInfo()\n</code></pre> <p>Base model to define the relationship between a model and its prediction file</p>"},{"location":"api/python/models/#project","title":"Project","text":"<pre><code>Project()\n</code></pre> <p>Project model</p> <p>Attributes</p> <ul> <li>project_id  : str</li> <li>name  : str</li> </ul>"},{"location":"api/python/models/#remotedatasource","title":"RemoteDataSource","text":"<pre><code>RemoteDataSource()\n</code></pre> <p>A source that identifies where data is stored.</p> <p>Attributes</p> <ul> <li>credentials_id  : The id of the credentials to use to authenticate to the remote data source. If None, the default will be used</li> </ul>"},{"location":"api/python/models/#retrainingreport","title":"RetrainingReport","text":"<pre><code>RetrainingReport()\n</code></pre> <p>base model for Retraining Report</p> <p>Attributes</p> <ul> <li>report_id  : str</li> <li>sample_ids  : List[str]</li> <li>sample_weights  : List[float]</li> <li>effective_sample_size  : float</li> <li>model_metric_name  : str</li> <li>upper_bound  : float</li> <li>lower_bound  : float</li> </ul>"},{"location":"api/python/models/#s3datasource","title":"S3DataSource","text":"<pre><code>S3DataSource()\n</code></pre> <p>A source that identifies a file in an S3 bucket.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul>"},{"location":"api/python/models/#secretawscredentials","title":"SecretAWSCredentials","text":"<pre><code>SecretAWSCredentials()\n</code></pre> <p>AWS integration credentials, that also include the external_id you need to set up the trust policy on AWS.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>role_arn  : The ARN of the IAM role that should be assumed</li> <li>external_id  : Secret key used to assume the IAM role via STS</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#generate_trust_policy","title":".generate_trust_policy","text":"<pre><code>.generate_trust_policy()\n</code></pre> <p>Generates a JSON trust policy that you can copy into the IAM role on AWS.</p>"},{"location":"api/python/models/#slacknotificationaction","title":"SlackNotificationAction","text":"<pre><code>SlackNotificationAction()\n</code></pre> <p>Action that sends a notification to a Slack channel through a webhook that you configure.</p> <p>Attributes</p> <ul> <li>webhook  : str</li> <li>channel  : str type = DetectionEventActionType.SLACK_NOTIFICATION</li> </ul>"},{"location":"api/python/models/#suggestion","title":"Suggestion","text":"<pre><code>Suggestion()\n</code></pre> <p>Suggestion base model</p> <p>Attributes</p> <ul> <li>id  : str</li> <li>executed  : bool</li> <li>timestamp  : str</li> </ul>"},{"location":"api/python/models/#task","title":"Task","text":"<pre><code>Task()\n</code></pre> <p>Task model</p> <p>Attributes</p> <ul> <li>task_id  : str</li> <li>name  : str</li> <li>type  : TaskType</li> <li>status  : TaskStatus</li> <li>status_start_date  : str</li> </ul>"},{"location":"user_guide/","title":"User Guide","text":"<p>ML cube Platform is an MLOps tool in the Serving Stage of MLOps pipeline. It is an AI Supervision tool that implements Monitoring and Observability to avoid AI's models obsolescence and performance degradation.</p> <p>In the Figure below are depicted the covered areas by ML cube Platform:</p> <p> </p> Covered Areas in the MLOps Stack. <p>With ML cube Platform you can:</p> <ul> <li>log inference data and identify the presence of drifts;</li> <li>obtain the best retraining dataset to update your model after a drift;</li> <li>have a business perspective on your AI Tasks to link your KPIs with AI models' performance</li> <li>apply expert learning techniques during inference to mitigate the problems due to changes in the data;</li> <li>use relabeling module to obtain the most important samples to relabel.</li> </ul>"},{"location":"user_guide/#artificial-intelligence-applications-monitoring","title":"Artificial Intelligence applications monitoring","text":"<p>AI monitoring consists of applying detection algorithms to metrics that comes from an Artificial Intelligence system. The monitored metrics are split in two categories:</p> <ul> <li>Serving metrics: quantities related to the infrastructure and the software application like inference time and network rate;</li> <li>AI metrics: quantities related to the Artificial Intelligence application like model performance, missing values and data distributions.</li> </ul> <p>ML cube Platform focuses on AI metrics, its goal is to monitor data and AI models to detect drifts and AI related problems and to provide actions that keep model performance high.</p>"},{"location":"user_guide/#data-and-model-monitoring","title":"Data and model monitoring","text":"<p>ML cube Platform implements data monitoring and model monitoring.  Model monitoring detects drifts and problems in the monitored AI model. Model monitoring means analyzing its performance metric (like RMSE, precision, or any custom performance metric) over time to detect deviations and negative trends before they will be problematic. Whenever a drift in the model performance is detected, an alarm is raised because the model needs to be updated with a new training data.</p> <p>Data monitoring processes the input and the ground truth. Detectors that monitor only the input check for input drift, i.e., a change in \\(P(X)\\) distribution, while detectors that monitor both input and ground truth check for concept drift i.e., change in \\(P(y | X)\\) distribution.</p> <p>Model and data monitoring are related and interdependent since the presence of a concept drift usually determines a model drift as well. They are used simultaneously to improve the overall detection quality.</p>"},{"location":"user_guide/#what-do-you-need-to-log-on-ml-cube-platform","title":"What do you need to log on ML cube Platform?","text":"<p>ML cube Platform's detection algorithms works at model level. Therefore, uploaded input data are the numeric features the model model receives as input to make inferece. Those data are the ones at the end of the data processing pipeline after the cleaning, feature extraction and normalization.</p> <p> </p> ML cube Platform in the ML inference pipeline."},{"location":"user_guide/#creating-a-baseline-with-reference-data","title":"Creating a baseline with Reference Data","text":"<p>Reference data are part of the datasets used during the development of the AI model: they contain training, validation, and test sets, i.e., anything the AI model saw during its training phase. Reference data are used to initialize data detectors calibrating them to what the model learnt.</p> <p>Reference data are not used to initialize the model detectors since the error on training set is not fair with respect the error with external data. Therefore, model detectors initialize themselves with production data assuming that the performance the AI model has in the first timesteps after the deployment belong to the same data distribution.</p>"},{"location":"user_guide/#improving-retraining-quality-with-historical-data","title":"Improving retraining quality with Historical Data","text":"<p>Historical data are composed of any dataset the customer has that were not used to train the AI model that is used in production (they potentially can be old training datasets of old models). Historical data are not used during the drift detection phase but during the retraining dataset selection phase. They are not mandatory, but their availability increase the quality and the information of the retraining dataset ML cube Platform provides to the customer. Indeed, ML cube Platform will use all the information available to provide the best dataset for retraining.  The historical data have the same format as the input data, therefore, they are data after the data processing pipeline.</p>"},{"location":"user_guide/#what-is-a-retraining-dataset","title":"What is a retraining dataset?","text":"<p>When a drift occurs, the AI model performance decreases. The retraining dataset is the new dataset ML cube Platform provides to the customer that should be used to retrain the AI model in order to increase the AI model performance. Conceptually, the retraining dataset is composed of the production data after the data drift with all the data that are similar to them. What ML cube Platform provides is a set of importance weights, one for each data sample belonging to the three data categories: historical, reference, production. The magnitude of the importance weights indicates how much the single sample is important for the current retraining. The customer integrates the weights in the training procedure using a weighted loss function. If the AI model does not support weighted loss function, ML cube Platform can provide a list of sample ids to use as training dataset.</p>"},{"location":"user_guide/basic_concepts/","title":"Basic Concepts","text":"<p>This page provides an overview of the fundamental concepts in the ML Cube Platform, helping you familiarize yourself with the product.</p>"},{"location":"user_guide/basic_concepts/#company-project-task-and-model","title":"Company, Project, Task and Model","text":"<p>At the core of the ML Cube Platform is a Company. Upon registration, you create a Company, which comes with a Subscription Plan defining the number of Projects, Tasks, and Data you can manage. Billing and payments occur at the Company level.</p> <p> </p> Structure of entities in ML Cube Platform. <p>Once your Company is established, you, as the company owner, can create Users and assign them specific Roles.</p> <p>To help you to better understand the concepts and the entities in ML cube Platform we use a fictional company: it is called Delta Energy, and it is a producer of Photovoltaic Modules that own Photovoltaic fields and trades the energy to the market.</p> <p>After the Company is created, you can create a Project and AI Tasks inside it. Think of a Project as an application of Artificial Intelligence algorithms and techniques to optimize a KPI.</p> <p>Delta Energy, for instance, created the Energy Revenue Project to enhance their revenue from energy trading. They invested in four AI algorithms:</p> <ol> <li>Fault detection</li> <li>Fault diagnosis</li> <li>Soiling detection</li> <li>Trading</li> </ol> <p>In ML cube Platform, these four algorithms define four Tasks inside the Project Energy Revenue. They have been placed into the same Project because they share the business goal i.e., the net revenue, the data and are interdependent.</p> <p>Putting Tasks inside the same Project allows to leverage Tasks and data correlation having a comprehensive view of the problem.</p> <p>As you may have guessed, in ML cube Platform a Task corresponds to an AI Algorithm. To be more precise, a Task is an AI Problem with a dataset composed of input features and a target. A Task can have more than one AI Model that uses the input features estimates the target.</p> <p>In out example company, the Fault Detection Task has as input features the PV moduels and weather data and the target is the presence of a fault. The Task has two Models: logistic regression and random forest. Both models use the same data and predict the same target but are different in the techniques used to perform the estimation.</p> <p>The last entity is the Model that is the actual AI model that predicts the target. A Model has a Version that defines the training data used to train it. All model's data will be uploaded specifying the model version in order to track each prediction with the right model instance. The model version is updated whenever a new training of the model is done.</p> <p>It's worth nothing to note that in ML cube Platform you do not actually need to upload the model on the application. We just need to know its training data and its predictions for the production data. In this way, ML cube Platform is considered as model agnostic.</p>"},{"location":"user_guide/basic_concepts/#data-taxonomy","title":"Data Taxonomy","text":"<p>A Batch of data is composed of four types of data:</p> <ul> <li>metadata: additional information that AI models do not use as input but that is important to define the data or the samples. Mandatory for this category are the <code>sample-id</code>, a unique identifier for each sample used to avoid confusion and misinterpretation; and the <code>sample-timestamp</code>, a timestamp associated with each sample used for ordering. Moreover, the User can provide additional data used to segment the data space.  For instance, sensitive information like zip code or country are not used by AI models to prevent bias, however, ML cube Platform can use them to  check and prevent bias in the suggested retraining dataset or to perform segmented drift detection.</li> <li>input: set of input features the AI model uses to predict the output.  ML cube Platform uses the input data that comes at the end of the processing data pipeline and not the raw data. This is due to the fact that ML cube Platform detects drifts in what the AI model uses and not in the general data the customer has.</li> <li>output: target quantity predicted by the AI models. It is present in the training data but can be not available for production data.</li> <li>models' predictions: predicted target for each AI model in the AI Task.</li> </ul>"},{"location":"user_guide/basic_concepts/#data-categories","title":"Data Categories","text":"<p>ML cube Platform are present three categories of data:</p> <ul> <li>Reference: represents the dataset used to train the model. Each model version has a reference dataset. Detection algorithms use reference data during their initialization.</li> <li>Production: represents data that comes from the production environment in which the AI model is operating. Detection algorithms analise production data to detect the presence of drifts.</li> <li>Historical: represents additional data that ML cube Platform can use to define the retraining dataset after a drift.</li> </ul> <p> </p> ML cube Platform data categories. <p>Delta Energy company trained its models using the data in the year 2022 and used the algorithms starting from the 2023. This means that the data in the 2022 are the reference data and every data from the january first 2023 are considered as production data. Data previous 2022 are historical data instead.</p>"},{"location":"user_guide/basic_concepts/#user-roles","title":"User Roles","text":"<p>Before to dive into details about the functionalities and modules covered, let's talk about the Role Based Access Control in ML cube Platform. As mentioned above, the company owner can create new Users assigning to them a Role. See the Roles page to read more about it. The Role defines the set of actions a User has inside the ML cube Platform. There are two levels of roles:</p> <ul> <li>Company: each User has a role inside the company.  The roles are Owner, Admin, Standard User.</li> <li>Project: by default a User does not have roles in a Project.  The Company Owner or Admin will assign a Project Role to User when needed. The roles are Admin, Edit User, View User.</li> </ul> <p> </p> User Roles in ML cube Platform. <p>Delta Energy has one dedicatd AI Team to each Task.  Hence, they assigned specific Project Administrator Role to each Team leader; while the other Data Scientists have the Project Edit Role for the project they are working on.</p>"},{"location":"user_guide/basic_concepts/#drift-detection","title":"Drift Detection","text":"<p>For each AI Task, ML cube Platform provides a set of Detectors that analyze different quantities of the Task. Data Detectors look at the Task's data without considering its AI models. They are resposible to identify input and concept drifts and more generally changes that happen in the data.</p> <p>Indeed, each Model has associated a Model Detector that analyses its performance metrics and detect negative trends.</p>"},{"location":"user_guide/basic_concepts/#retraining","title":"Retraining","text":"<p>A Data drift determines a drop in the model's performance that starts providing bad estimation or predictions. In Artificial Intelligence, Data plays a crucial role and usually, choosing the best data has higher impact in the resulting Model quality with respect to increasing the model complexity.</p> <p>ML cube Platform with its Retraining Tool Module provides you the best retraining dataset to use when updating the Model after a drift reducing the reaction time after the detection. Even if, the data has changed you can extract useful information from the past. ML cube Platform leverages all the available data belonging to the three categories: histrical, reference and production, computing an Importance Score to every data sample you have. These Importance Scores will be used during the training phase of your model as weights in the loss function.</p>"},{"location":"user_guide/basic_concepts/#model-life-cycle","title":"Model Life Cycle","text":"<p>ML cube Platform covers all the aspects of the post-deployment life cycle of your AI models:</p> <p> </p> Post-deployment AI model life cycle. <p>In Delta Energy data are collected every minute and are sent simultaneously to ML cube Platform. Ground truth data like the presence of a fault and the fault category are uploaded after they are available and therefore, they will sent with a delay compared the others.</p> <p>Drift alerting system is integrated with their Microsoft Teams and ML cube Platform sends alerts to the specified channels. After they receive an alerting message, they run a retraining pipeline that communicated with ML cube Platform to retrieve the retraining dataset to use. After that, they are ready to update the new version on ML cube Platform to start the monitoring.</p>"},{"location":"user_guide/data_sources/","title":"Data Sources","text":"<p>This page provides guidance on integrating your data sources into your ML cube Platform project. There are three types of data sources you can use to enable the ML cube Platform to access your data:</p> <ol> <li>Local data source</li> <li>Remote data source with ML cube Storage</li> <li>Remote data source with Customer Storage</li> </ol>"},{"location":"user_guide/data_sources/#local-data-source","title":"Local Data Source","text":"<p>This is the easiest way to send data to the ML cube Platform. You can simply specify the path to the local file you want to upload, and it will be uploaded to the ML cube Platform Secure Storage, where it is automatically processed.</p> <p>Example</p> <pre><code>job_id = client.add_historical_data(\ntask_id='your_task_id',\nfeatures_data_source=LocalDataSource(\ndataset_type=DatasetType.TABULAR, file_path='historical_features.csv'\n),\ntargets_data_source=LocalDataSource(\ndataset_type=DatasetType.TABULAR, file_path='historical_targets.csv'\n),\n)\n</code></pre>"},{"location":"user_guide/data_sources/#remote-data-source","title":"Remote Data Source","text":"<p>While using a local data source can be a good way to try out the features that the ML cube Platform can offer, in a production scenario you will usually want to integrate your remote data sources with your project. You can decide where you want your data to be stored.</p>"},{"location":"user_guide/data_sources/#ml-cube-storage","title":"ML cube Storage","text":"<p>This method should be used when the ML cube Platform is allowed to perform a one-time read of the raw data from your data source, and make a copy of it inside the ML cube Platform Secure Storage. This allows the ML cube Platform to store a server-side copy of the processed dataset for quicker access and analysis. Remember that you can request the deletion of your data at any time.</p>"},{"location":"user_guide/data_sources/#customer-storage","title":"Customer Storage","text":"<p>This method should be used when, due to compliance requirements, the ML cube Platform is only allowed to read data from your data sources when it needs to access it, without storing any sensitive information in its systems. The ML cube Platform will only store a set of anonymous identifiers that are used for data mapping. This gives you the ability to be in full control of when the ML cube Platform can access your data, but it comes at the expense of performance and cost, since constant data transfers can be slow and expensive.</p>"},{"location":"user_guide/data_sources/#integration-credentials","title":"Integration Credentials","text":"<p>The ML cube Platform SDK provides a way to configure credentials that can be used to access the integrated data sources of your choice. The scope of these credentials is a project, so multiple tasks in the same project will be able to access the same credentials. You can configure multiple credentials for the same provider, for example you could have two sets of credentials to access two different AWS S3 buckets.</p> <p>Below, you can find the configuration steps required to integrate the data source of your choice</p> Amazon S3Google Cloud StorageAzure Blob StorageDatabricks <p></p> <p>To integrate Amazon S3, you will need to create a set of AWS credentials. Before doing this, you need to create an IAM Role in your AWS Account that will be used by the ML cube Platform to read data from the S3 bucket of your choice.</p> <p>First of all, log into your AWS account and open the AWS console. Here, go to the IAM service, then navigate to the Policies section. Here, we will create an IAM Policy.</p> <p>Example</p> <p>The following policy will allow read access to objects in the <code>my-company-data-bucket</code> to the IAM entity it is attached to.</p> <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"Statement1\",\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetBucketTagging\",\n\"s3:GetObject\",\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::my-company-data-bucket\",\n\"arn:aws:s3:::my-company-data-bucket/*\"\n]\n}\n]\n}\n</code></pre> <p>Once the IAM Policy has been created, navigate to the Roles section and create a new role. When asked, select the <code>Custom trust policy</code> option and accept the default policy. Then, assign the IAM Policy we created previously to the role, so any entity that assumes the role will be able to access the S3 bucket.</p> <p>Now, you will need to create the credentials through the ML cube Platform SDK.</p> <p>Example</p> <p>The following code will create a set of AWS credentials from the IAM Role we just created.</p> <pre><code>aws_creds = client.create_aws_integration_credentials(\nname='AWS_01',\ndefault=True,  # Set these credentials as the default to use when not specified\nproject_id='your_project_id',\nrole_arn='arn:aws:iam::{{YOUR_AWS_ACCOUNT_ID}}:role/{{YOUR_ROLE_NAME}}',\n)\ntrust_policy = aws_creds.generate_trust_policy()\nprint(trust_policy)\n</code></pre> <p>You can call the <code>generate_trust_policy</code> function on the created credentials to obtain the trust policy. Edit your IAM Role and change the trust policy to the one you just obtained.</p> <p>Now, you will be able to specify an <code>S3DataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>job_id = client.add_historical_data(\ntask_id='your_task_id',\nfeatures_data_source=S3DataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='s3://my-company-data-bucket/historical/features.csv',\ncredentials_id=aws_creds.credentials_id\n),\ntargets_data_source=S3DataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='s3://my-company-data-bucket/historical/targets.csv',\ncredentials_id=aws_creds.credentials_id\n),\n)\n</code></pre> <p>Congratulations! You have successfully connected your S3 bucket to the ML cube Platform. The ML cube Platform will now be able to assume the role via STS by providing the secret <code>external_id</code> that is included in the trust policy. This way, only the ML cube Platform is able to access that specific role on your AWS account. To revoke access, simply delete the role or change the trust policy.</p> <p></p> <p>To integrate Google Cloud Storage, you will need to create a set of GCP credentials. Before doing this, you need to create a Service Account in your GCP Account that will be used by the ML cube Platform to read data from the GCS bucket of your choice.</p> <p>First of all, log into your GCP account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Now we will enter some commands that will create the Service Account with the required permissions. A description of each command is provided to help you understand its purpose.</p> <pre><code># Change these according to your project and bucket\nexport GCP_PROJECT=my-project\nexport GCP_BUCKET=my-company-data-bucket\n\n# Creates an IAM Role called ml3PlatformServiceRole for your project, with read permissions on buckets and objects in the storage service\ngcloud iam roles create ml3PlatformServiceRole --project=$GCP_PROJECT --title=\"ML3 Platform Service Role\" --description=\"Role that allows the ML cube Platform to access resources in a project\" --permissions=storage.buckets.get,storage.buckets.list,storage.objects.get,storage.objects.list --stage=ALPHA\n\n# Creates a service account called ml3PlatformServiceAccount\ngcloud iam service-accounts create ml3PlatformServiceAccount --display-name \"ML3 Platform Service Account\"\n# Adds the previously created IAM Role to the service account\ngcloud projects add-iam-policy-binding $GCP_PROJECT --member=serviceAccount:ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com --role=projects/$GCP_PROJECT/roles/ml3PlatformServiceRole\n\n# Allows the service account we created to access the given bucket with the objectViewer role\ngsutil iam ch serviceAccount:ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com:roles/storage.objectViewer gs://$GCP_BUCKET\n# Generates the access key that will be used to authenticate as the service account\ngcloud iam service-accounts keys create ml3-platform-key.json --iam-account=ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com\n\n# Displays the access key to the terminal screen\ncat ml3-platform-key.json\n</code></pre> <p>Copy the JSON object containing the key and save it to a file with the same name on your disk.</p> <p>Now, you will need to create the credentials through the ML cube Platform SDK.</p> <p>Example</p> <p>The following code will create a set of GCP credentials that will be able to access the service account.</p> <pre><code>with open('path/to/ml3-platform-key.json', 'r') as f:\ncreds_json = f.read()\ngcp_creds = client.create_gcp_integration_credentials(\nname='GCP_01',\ndefault=True,  # Set these credentials as the default to use when not specified\nproject_id='your_project_id',\nservice_account_info_json=creds_json\n)\n</code></pre> <p>Now, you will be able to specify a <code>GCSDataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>job_id = client.add_historical_data(\ntask_id='your_task_id',\nfeatures_data_source=GCSDataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='gs://my-company-data-bucket/historical/features.csv',\ncredentials_id=gcp_creds.credentials_id\n),\ntargets_data_source=GCSDataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='gs://my-company-data-bucket/historical/targets.csv',\ncredentials_id=gcp_creds.credentials_id\n),\n)\n</code></pre> <p>Congratulations! You have successfully connected your GCS bucket to the ML cube Platform. The ML cube Platform will now be able to authenticate to the service account you created via the generated key. To revoke access, simply delete the key.</p> <p></p> <p>To integrate Azure Blob Storage, you will need to create a set of Azure credentials. Before doing this, you need to create a Service Principal in your Azure Account that will be used by the ML cube Platform to read data from the specified Container in the Storage Account of your choice.</p> <p>First of all, log into your Azure account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Set the Cloud Shell to use bash instead of powershell. Now we will enter the following commands that will create the Service Principal with the required permissions to read blobs from your container.</p> <pre><code># Change these according to your Azure resources\nexport SUBSCRIPTION_ID=your-subscription-id\nexport RESOURCE_GROUP=your-resource-group\nexport STORAGE_ACCOUNT=your-storage-account\nexport BLOB_CONTAINER=your-blob-container\n\naz ad sp create-for-rbac --name ML3PlatformSP --role \"Storage Blob Data Reader\" --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.Storage/storageAccounts/$STORAGE_ACCOUNT/blobServices/default/containers/$BLOB_CONTAINER\n</code></pre> <p>If you would like to use a custom role, for example to restrict the reads to a specific subfolder, create it and then replace \"Storage Blob Data Reader\" with the name of your role.</p> <p>Once the operation finishes running, it will output a JSON object with the following fields: <code>appId</code>, <code>displayName</code>, <code>password</code> and <code>tenant</code>. Copy this object and save it to a file on your disk, for example <code>azure-credentials.json</code>.</p> <p>Now, you will need to create the credentials through the ML cube Platform SDK.</p> <p>Example</p> <p>The following code will create a set of Azure credentials that will be able to access the service account.</p> <pre><code>with open('path/to/azure-credentials.json', 'r') as f:\ncreds_json = f.read()\nazure_creds = client.create_azure_integration_credentials(\nname='AZURE_01',\ndefault=True,  # Set these credentials as the default to use when not specified\nproject_id='your_project_id',\nservice_principal_credentials_json=creds_json\n)\n</code></pre> <p>Now, you will be able to specify an <code>AzureBlobDataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>job_id = client.add_historical_data(\ntask_id='your_task_id',\nfeatures_data_source=AzureBlobDataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='https://mystorageaccount.blob.core.windows.net/my-container/historical/features.csv',\ncredentials_id=azure_creds.credentials_id\n),\ntargets_data_source=AzureBlobDataSource(\ndataset_type=DatasetType.TABULAR,\nobject_path='https://mystorageaccount.blob.core.windows.net/my-container/historical/targets.csv',\ncredentials_id=azure_creds.credentials_id\n),\n)\n</code></pre> <p>Congratulations! You have successfully connected your Azure blob container to the ML cube Platform. The ML cube Platform will now be able to authenticate to the service principal you created via the generated key. To revoke access, search for 'App Registrations' in the Azure Console, then navigate to the 'All Applications' tab, select 'ML3PlatformSP' and delete it.</p> <p></p> <p>Coming Soon...</p>"},{"location":"user_guide/glossary/","title":"Glossary","text":""},{"location":"user_guide/glossary/#general-terms","title":"General Terms","text":"<ul> <li>User: registered user with username and password that interact with ML cube Platform.  A User can create API keys that inherits his/her permissions and that the he/she uses to communicate with ML cube Platform though API. </li> <li>Company: collection of Users that work with ML cube Platform.  Subscription plan and contracts with ML cube are managed at Company level. A Company has one owner that has all the privileges and that can assign admin role to other Users in the Company.</li> <li>Project: collection of AI Tasks that belong to the same business domain.</li> <li>Task: it is the standard AI problem with a dataset, a target and a set of AI models that predicts the target. All AI models inside the AI Task predicts the same target quantity and they are considered as champion and challengers or deployed and shadow models. Data drift detection is done at Task level because the models uses the same dataset.</li> <li>Model: AI model inside a Task that makes predictions over the Task's dataset.</li> </ul>"},{"location":"user_guide/glossary/#data-terms","title":"Data Terms","text":"<ul> <li>Historical data: data not used for the newest retraining but that belong to the Task. ML cube Platform uses these data during the retraining dataset selection to exploit all the available information. They are not mandatory, if they are not present then the Retraining Tool selects data from the reference set and the production data.</li> <li>Reference data: dataset used as reference for the current model version. It can be the training dataset, the test set or both. Reference data represents the current view of the model over the Task</li> <li>Production data: data the model encounter during production, the production data are monitored by the ML cube Platform detectors to detect drifts</li> <li>Data schema: represents the schema of the data that ML cube Platform uses to know the features and the target columns.</li> </ul>"},{"location":"user_guide/glossary/#drifts-terms","title":"Drifts Terms","text":"<ul> <li>Input drift: statistically significant change in the input data P(X)</li> <li>Concept drift: statistically significant change in the input and target data P(X, y)</li> <li>Model drift: statistically significant change in the model error P(y \u2013 y_pred).</li> </ul>"},{"location":"user_guide/glossary/#actions-terms","title":"Actions Terms","text":"<ul> <li>Importance weights: the retraining dataset is given in form of a set of importance weights associated to every data available for the Task. This importance score will be used during the training pipeline of the customer to weights samples. In particular, the ML model will use the form of the sample weighted loss instead of the standard loss during its retraining phase</li> <li>Dataset boostrapping: if the ML model does not support the sample weighted loss then ML cube Platform can provide a dataset extracted from the available data using sampling with replacement based on the importance weights of the data. The customer can specify the size of the retraining dataset and ML cube Platform provides the best retraining bootstapped dataset of that size</li> <li>Relabeling: in case of concept drift in a classification Task, old labels are no meaningful, given a budget/size constraint ML cube Platform provides the subset of data to be relabelled</li> <li>Active Learning: ML cube Platform provides a set of new synthetic data to label or it provides indication where to collect new real data from the environment</li> </ul>"},{"location":"user_guide/notifications/","title":"Notifications","text":"<p>This section provides an overview of how you can receive notifications when a detection event occurs on the ML cube Platform.</p>"},{"location":"user_guide/notifications/#detection-event-rules","title":"Detection Event Rules","text":"<p>When a detection event occurs, the platform evaluates your set detection event rules. If a rule matches the event, the specified actions will be triggered. These rules are specific to a task and require the following parameters for configuration:</p> <ul> <li><code>name</code>: A descriptive label for your rule, helping you understand its purpose quickly.</li> <li><code>task_id</code>: The unique identifier of the task to which the rule is applicable.</li> <li><code>severity</code>: Indicates the severity level of the event - it can be <code>HIGH</code>, <code>MEDIUM</code>, or <code>LOW</code>.</li> <li><code>detection_event_type</code>: Currently, only <code>DRIFT</code> events are available for detection.</li> <li><code>monitoring_target</code>: Specifies what is being monitored, which can be <code>MODEL</code>, <code>INPUT</code>, or <code>CONCEPT</code>. If the value is <code>MODEL</code>, you need to provide a corresponding <code>model_name</code>.</li> <li><code>actions</code>: A sequential list of actions to be executed when the rule is triggered.</li> </ul>"},{"location":"user_guide/notifications/#supported-actions","title":"Supported Actions","text":"<p>The following actions are currently supported:</p> <ul> <li><code>SlackNotificationAction</code>: sends a notification to a Slack channel via webhook.</li> <li><code>DiscordNotificationAction</code>: sends a notification to a Discord channel via webhook.</li> <li><code>EmailNotificationAction</code>: sends an email to the provided email address.</li> <li><code>TeamsNotificationAction</code>: sends a notification to Microsoft Teams via webhook.</li> </ul> <p>Example</p> <p>The following code snippet demonstrates how to create a rule that matches high severity drift events for a specific model. When triggered, it sends a notification to the <code>ml3-platform-notifications</code> channel on your Slack workspace using the provided webhook URL.</p> <pre><code>rule_id = client.create_detection_event_rule(\nname='Send Slack notification on my_model severe drift',\ntask_id='my-task-id,\nmodel_name='my-model',\nseverity=DetectionEventSeverity.HIGH,\ndetection_event_type=DetectionEventType.DRIFT,\nmonitoring_target=MonitoringTarget.MODEL,\nactions=[\nSlackNotificationAction(\nwebhook='https://hooks.slack.com/services/...',\nchannel='ml3-platform-notifications'\n),\n],\n)\n</code></pre>"},{"location":"user_guide/rbac/","title":"User Roles","text":"<p>ML cube Platform uses Role Based Access Control to manage user permissions over the entities.</p> <p>Each User has associated a company role and one or more project roles.</p>"},{"location":"user_guide/rbac/#company-permissions","title":"Company Permissions","text":"Role DELETE_COMPANY CHANGE_COMPANY_OWNER MANAGE_COMPANY_ADMIN MANAGE_COMPANY_USER CHANGE_COMPANY_USER_ROLE UPDATE_COMPANY_INFORMATION READ_COMPANY CREATE_PROJECT COMPANY_OWNER COMPANY_ADMIN COMPANY_USER COMPANY_NONE"},{"location":"user_guide/rbac/#project-permissions","title":"Project Permissions","text":"Role DELETE_PROJECT MANAGE_PROJECT_ADMIN UPDATE_PROJECT_INFORMATION MANAGE_PROJECT_USER CHANGE_PROJECT_USER_ROLE WORK_ON_PROJECT READ_PROJECT COMPANY_OWNER COMPANY_ADMIN COMPANY_USER COMPANY_NONE PROJECT_ADMIN PROJECT_USER PROJECT_VIEW"},{"location":"user_guide/retrain_trigger/","title":"Retrain trigger","text":"<p>This section provides an overview of how you can setup retrain triggers for your models so that you can automatically start your retraining pipeline from ML cube Platform. A retrain trigger can be used inside a Detection Event Rule that when specific criteria are met automatically computes the retrain report and then push the trigger, or in the retraining tool page where you can manually push the trigger for the model.</p> <p>A retrain trigger is modelled as an integration to an external service and requires credentials with the right privileges to perform the action.</p>"},{"location":"user_guide/retrain_trigger/#supported-triggers","title":"Supported Triggers","text":"<p>The following retrain triggers are supported:</p> <ul> <li><code>AWS Event Bridge</code>: creates an event to Event Bus with specific metadata.</li> </ul>"},{"location":"user_guide/retrain_trigger/#aws-event-bridge","title":"AWS Event Bridge","text":"<p>If you have your MLOps pipelines inside AWS ecosystem then you probably need the AWS Event Bridge retrain trigger. The trigger consists in creating an event in a Event Bus of your AWS account with custom metadata. You need to create an Event Bus rule that recognises the right the ML cube Platform pattern and attach the target action you want. Examples of targets are:</p> <ul> <li>launching a Lambda function;</li> <li>launching a SageMaker pipeline;</li> <li>sending a message to a SQS Queue with a retraining request.</li> </ul>"},{"location":"user_guide/retrain_trigger/#event-bus-setup","title":"Event Bus Setup","text":"<ol> <li>From AWS console open the EventBridge service and on the left menu select the voice <code>Event buses</code></li> </ol> <ol> <li>In the <code>Custom event bus</code> tab create a new event bus</li> </ol> <ol> <li>Select the <code>Rules</code> section on the left menu and click the button <code>Create Rule</code></li> <li> <p>Insert the rule name and in the Event Bus section the created Event Bus. Click <code>Next</code></p> <ol> <li><code>Event source</code>: select the voice AWS events or EventBridge patner events </li> <li><code>Sample event</code>: copy and paste this: <pre><code>{\n\"version\": \"0\",\n\"id\": \"fcdd87c7-f56e-c722-4f85-4cb6ba85a00a\",\n\"detail-type\": \"retrain-trigger\",\n\"source\": \"ml3_platform\",\n\"time\": \"2023-11-02T14:16:23Z\",\n\"resources\": [],\n\"detail\": {\n\"model_id\": \"fcdd87c7-f56e-c722-4f85-4cb6ba85a00a\"\n}\n}\n</code></pre> </li> <li><code>Creation method</code>: select Custom pattern (JSON editor)  </li> <li><code>Event pattern</code>: copy and paste this:  <pre><code>{\n\"source\": [{\n\"prefix\": \"ml3_platform\"\n}],\n\"detail-type\": [{\n\"prefix\": \"retrain_trigger\"\n}]\n}\n</code></pre></li> <li>click the button Test pattern to check the match and then click next</li> </ol> </li> <li> <p>Select the target you want to start. If you want to test the rule, you can add a CloudWatch target that stores the event to a new Log Group.      </p> </li> <li>Create the rule</li> </ol>"}]}