{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ML cube Platform","text":"<p>Welcome to the official ML cube Platform documentation site. Here you can find everything you need to start using the product.</p> <p>This site contains two sections:</p> <ul> <li>User Guide provides high overview of ML cube Platform and describes its main components.</li> <li>API provides details about the API to interact with ML cube Platform.</li> </ul>"},{"location":"api/","title":"Client SDK","text":"<p>ML cube Platform allows interaction through REST APIs:</p> <ul> <li> Python \u2013 Install Python Client on your environment</li> <li> REST \u2013 Use directly the API</li> <li> EXAMPLES - Jupyer Notebook examples</li> </ul>"},{"location":"api/examples/","title":"Examples","text":"<p>We wrote for you a set of notebooks that can help you to understand how to use ML cube Platform SDK:</p> <ul> <li>0 - Company and Project</li> <li>1 - Task and Model</li> <li>2 - Production</li> </ul>"},{"location":"api/python/","title":"ML3 platform client SDK","text":""},{"location":"api/python/#installation","title":"Installation","text":"<pre><code>pip install ml3-platform-sdk\n</code></pre>"},{"location":"api/python/#usage","title":"Usage","text":"<p>Please refer to the documentation</p>"},{"location":"api/python/client/","title":"Client","text":""},{"location":"api/python/client/#ml3platformclient","title":"ML3PlatformClient","text":"<pre><code>ML3PlatformClient(\n   url: str, api_key: str\n)\n</code></pre> <p>Client class is the single point of interaction with ML cube Platform APIs, it is initialized providing the <code>url</code> and the User <code>api_key</code>. Every operation is performed verifying the API Key and the permissions associated to the User that own that key.</p>"},{"location":"api/python/client/#methods-categories","title":"Methods categories","text":"<p>There are the following types of methods:</p> <ul> <li>entity creation: create the entity and return its identifier. It is used in the other methods to indicate the entity.</li> <li>entity update: modify the entity but do not return anything.</li> <li>entity getters: return a Pydantic <code>BaseModel</code> with the required entity.</li> <li>entity show: print to the stdout the entity, but they do not return anything.</li> <li>entity delete: delete the entity</li> <li>job submission: submit a job on ML cube Platform that will take some time. They return the job identifier that can be used to monitor its state.</li> <li>job waiters: given a job id wait the until the job is completed</li> </ul>"},{"location":"api/python/client/#exceptions","title":"Exceptions","text":"<p>The Client class raises only exceptions that are subclasses of <code>SDKClientException</code>. The exception has two fields that you can share with ML cube Support to get help in identifying the problem:</p> <ul> <li>error_code: unique identifier of the error</li> <li>error_message: message that explain the error</li> </ul> <p>The page is structured in different blocks of methods, one for each entity.</p> <p>Methods:</p>"},{"location":"api/python/client/#create_company","title":".create_company","text":"<pre><code>.create_company(\n   name: str, address: str, vat: str\n)\n</code></pre> <p>Create a company for the User, this method works only is the User has not a company yet. After the Company is created the User is the Company Owner.</p> <p>Args</p> <ul> <li>name  : the name of the company</li> <li>address  : the address of the company</li> <li>vat  : the vat of the company</li> </ul> <p>Returns</p> <ul> <li>company_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateCompanyException</code></p>"},{"location":"api/python/client/#get_company","title":".get_company","text":"<pre><code>.get_company()\n</code></pre> <p>Returns the company of the User</p> <p>Returns</p> <ul> <li>company  : <code>Company</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_company","title":".update_company","text":"<pre><code>.update_company(\n   name: Optional[str], address: Optional[str], vat: Optional[str]\n)\n</code></pre> <p>Update company information.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : new the of the company</li> <li>address  : new billing address for the company</li> <li>vat  : new vat of the company</li> </ul> <p>Raises</p> <p><code>UpdateCompanyException</code></p>"},{"location":"api/python/client/#create_project","title":".create_project","text":"<pre><code>.create_project(\n   name: str, description: Optional[str], default_storage_policy: StoragePolicy\n)\n</code></pre> <p>Create a project inside the company. You don't need to specify the company because a User belongs only to one company and it is retrieved automatically.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : the name of the project</li> <li>description  : optional description of the project</li> <li>default_storage_policy  : represents the default policy to     use for storing data in ML cube Platform</li> </ul> <p>Returns</p> <ul> <li>project_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateProjectException</code></p>"},{"location":"api/python/client/#get_projects","title":".get_projects","text":"<pre><code>.get_projects()\n</code></pre> <p>Get the list of all projects in the company the User has permissions to view.</p> <p>Returns</p> <ul> <li>projects_list  : <code>List[Project]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_project","title":".get_project","text":"<pre><code>.get_project(\n   project_id: str\n)\n</code></pre> <p>Get a project with the given id</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_project","title":".update_project","text":"<pre><code>.update_project(\n   project_id: str, name: Optional[str], description: Optional[str],\n   default_storage_policy: Optional[StoragePolicy]\n)\n</code></pre> <p>Update project details.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> <li>name  : new name of the project</li> <li>description  : new description of the project</li> <li>default_storage_policy  : represents the default policy to     use for storing data in ML cube Platform</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>UpdateProjectException</code></p>"},{"location":"api/python/client/#show_projects","title":".show_projects","text":"<pre><code>.show_projects()\n</code></pre> <p>Show a list all projects printing to stdout.</p> <p>Example output: <pre><code>Project ID                Name\n------------------------  ----------\n6475f8c9ebac5081e529s63f  my project\n</code></pre></p>"},{"location":"api/python/client/#create_task","title":".create_task","text":"<pre><code>.create_task(\n   project_id: str, name: str, tags: List[str], task_type: TaskType,\n   data_structure: DataStructure, cost_info: Optional[TaskCostInfo] = None,\n   optional_target: bool = False\n)\n</code></pre> <p>Create a task inside the project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task</li> <li>task_type  : the type of the task. See <code>TaskType</code>     documentation for more information</li> <li>data_structure  : type of data in the task</li> <li>cost_info  : optional argument that specify the cost     information of the task</li> <li>optional_target  : True if the target value in not always     available. This changes the behaviour and the detection     phase of ML cube Platform that will analyse production     data without considering the actual target</li> </ul> <p>Returns</p> <ul> <li>task_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateTaskException</code></p>"},{"location":"api/python/client/#update_task","title":".update_task","text":"<pre><code>.update_task(\n   task_id: str, name: Optional[str] = None, tags: Optional[List[str]] = None,\n   cost_info: Optional[TaskCostInfo] = None\n)\n</code></pre> <p>Update task attributes.</p> <p><code>None</code> parameters are ignored for the update.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task. To remove     all the tags then pass an empty list.</li> <li>cost_info  : optional argument that specify the cost     information of the task</li> </ul> <p>Raises</p> <p><code>UpdateTaskException</code></p>"},{"location":"api/python/client/#get_tasks","title":".get_tasks","text":"<pre><code>.get_tasks(\n   project_id: str\n)\n</code></pre> <p>Get the list of the Tasks inside the project.</p> <p>Args</p> <ul> <li>project_id  : identifier of the project</li> </ul> <p>Returns</p> <ul> <li>task_list  : <code>List[Task]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_task","title":".get_task","text":"<pre><code>.get_task(\n   task_id: str\n)\n</code></pre> <p>Get task by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>task  : <code>Task</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_tasks","title":".show_tasks","text":"<pre><code>.show_tasks(\n   project_id: str\n)\n</code></pre> <p>Show a list of tasks included in a project to stdout.</p> <p>Args</p> <ul> <li>project_id  : the identifier of a project</li> </ul> <p>Example output: <pre><code>Task ID                   Name     Type            Status     Status start date\n------------------------  -------  --------------  --------   -----------------\n6476040d583201813ab4539a  my task  classification  OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/client/#create_model","title":".create_model","text":"<pre><code>.create_model(\n   task_id: str, name: str, version: str, metric_name: ModelMetricName,\n   preferred_suggestion_type: SuggestionType, retraining_cost: float = 0.0,\n   resampled_dataset_size: Optional[int] = None\n)\n</code></pre> <p>Create a model inside the task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the model</li> <li>version  : the current version of the model</li> <li>metric_name  : performance or error metric associated with     the model</li> <li>retraining_cost  : estimated costs in the Task currency to     retrain the model. This information is used by the     retraining tool to show gain-cost information.     Default value is 0.0 meaning that the cost is negligible</li> <li>preferred_suggestion_type  : preferred type of suggestion that     will be computed to retrain the model</li> <li>resampled_dataset_size  : size of the resampled dataset that     will be proposed to retrain the model     note: this parameter is required if     <code>preferred_suggestion_type</code> is     <code>SuggestionType.RESAMPLED_DATASET</code></li> </ul> <p>Returns</p> <ul> <li>model_id  : <code>str</code> identifier of the created model</li> </ul> <p>Raises</p> <p><code>CreateModelException</code></p>"},{"location":"api/python/client/#get_models","title":".get_models","text":"<pre><code>.get_models(\n   task_id: str\n)\n</code></pre> <p>Get all models of a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>models_list  : <code>List[Model]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model","title":".get_model","text":"<pre><code>.get_model(\n   model_id: str\n)\n</code></pre> <p>Get model by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : identifier of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model_by_name_and_version","title":".get_model_by_name_and_version","text":"<pre><code>.get_model_by_name_and_version(\n   task_id: str, model_name: str, model_version: str\n)\n</code></pre> <p>Get model by name and version.</p> <p>A Model can have multiple versions according to the updates and retraining done. This method allow to get the Model object by specifying its name and the version tag.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>model_name  : the name of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_models","title":".show_models","text":"<pre><code>.show_models(\n   task_id: str\n)\n</code></pre> <p>Show a list of models included in a task to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> </ul> <p>Example output: <pre><code>Model Id                  Task Id                   Name                    Version    Status           Status start timestamp    Status insert date          Metric Name\n------------------------  ------------------------  ----------------------  ---------  ---------------  ------------------------  --------------------------  --------------------\n64fecf7d323311ab78f17280  64fecf7c323311ab78f17262  model_local_experiment  v0.0.1     not_initialized                            2023-09-11 08:27:41.431000  ModelMetricName.RMSE\n</code></pre></p>"},{"location":"api/python/client/#get_suggestions_info","title":".get_suggestions_info","text":"<pre><code>.get_suggestions_info(\n   model_id: str, model_version: str\n)\n</code></pre> <p>Retrieve suggestions associated with a model.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>suggestion_info_list  : <code>List[SuggestionInfo]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_suggestions","title":".show_suggestions","text":"<pre><code>.show_suggestions(\n   model_id: str, model_version: str\n)\n</code></pre> <p>Show the list of suggestions associated with a model printing them to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Example output: <pre><code>Suggestion Id                     Executed    Timestamp\n--------------------------------  ----------  --------------------------\n79a8710c351c4b6a9ece7322e153f200  True        2023-08-21 10:54:40.386189\n</code></pre></p> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#set_model_suggestion_type","title":".set_model_suggestion_type","text":"<pre><code>.set_model_suggestion_type(\n   model_id: str, preferred_suggestion_type: SuggestionType,\n   resampled_dataset_size: Optional[int] = None\n)\n</code></pre> <p>Set model suggestion type.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>preferred_suggestion_type  : preferred type of suggestion that     will be computed to retrain the model</li> <li>resampled_dataset_size  : size of the resampled dataset that     will be proposed to retrain the model     note: this parameter is required if     <code>preferred_suggestion_type</code> is     <code>SuggestionType.RESAMPLED_DATASET</code></li> </ul> <p>Raises</p> <p><code>SetModelSuggestionTypeException</code></p>"},{"location":"api/python/client/#update_model_version_by_suggestion_id","title":".update_model_version_by_suggestion_id","text":"<pre><code>.update_model_version_by_suggestion_id(\n   model_id: str, new_model_version: str, suggestion_id: str\n)\n</code></pre> <p>Update model version by suggestion id. To retrain the Model, ML cube Platform provides importance weights through a <code>SuggestionInfo</code>. After the retraining is completed, you use this method to create the new model version in ML cube Platform. By specifying the <code>suggestion_id</code>, ML cube Platform automatically knows which is the reference data the model is trained on.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model</li> <li>suggestion_id  : the identifier of the suggestion</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> job identifier of the pipeline in execution</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p>"},{"location":"api/python/client/#update_model_version_from_time_range","title":".update_model_version_from_time_range","text":"<pre><code>.update_model_version_from_time_range(\n   model_id: str, new_model_version: str, from_timestamp: float,\n   to_timestamp: float\n)\n</code></pre> <p>Update model version by specifying the time range of uploaded data on ML cube Platform.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model from_timestamp to_timestamp</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#add_data_schema","title":".add_data_schema","text":"<pre><code>.add_data_schema(\n   task_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Associate a data schema to a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the data schema that characterize your task</li> </ul> <p>Raises</p> <p><code>AddDataSchemaException</code></p>"},{"location":"api/python/client/#get_data_schema","title":".get_data_schema","text":"<pre><code>.get_data_schema(\n   task_id: str\n)\n</code></pre> <p>Get task data schema</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>data_schema  : <code>DataSchema</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_data_schema","title":".show_data_schema","text":"<pre><code>.show_data_schema(\n   task_id: str\n)\n</code></pre> <p>Show data schema of associated with a task</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p> <p>Example output:</p> <pre><code>Column name       Role     Type      Nullable\n----------------  -------  --------  ----------\nsample_id         id       string    False\ntimestamp         time_id  string    False\nsepallength       input    float     False\nsepalwidth        input    float     False\npetallength       input    float     False\npetalwidth        input    float     False\nclass             target   category  False\n</code></pre>"},{"location":"api/python/client/#add_historical_data","title":".add_historical_data","text":"<pre><code>.add_historical_data(\n   task_id: str, inputs: Data, target: Optional[Data] = None\n)\n</code></pre> <p>Add a batch of historical data for the Task.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>inputs  : data object that contain input data source.     It can be None if you upload other kinds of data</li> <li>target  : data object that contains target data.     It can be None if you upload other kinds of data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddHistoricalDataException</code></p>"},{"location":"api/python/client/#add_target_data","title":".add_target_data","text":"<pre><code>.add_target_data(\n   task_id: str, target: Data\n)\n</code></pre> <p>Add target samples for data already uploaded on the Task. This operation is used for Tasks with optional target which is manually labelled. For instance, fter the labelling process (maybe with our Active Learning module) you have a set of labelled samples spread over all the uploaded data. Indeed, they can belong to different data batches (historical or production consistent uploads) and can be a subset of the uploaded data.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>target  : data object that contains target data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddHistoricalDataException</code></p>"},{"location":"api/python/client/#set_model_reference","title":".set_model_reference","text":"<pre><code>.set_model_reference(\n   model_id: str, from_timestamp: float, to_timestamp: float\n)\n</code></pre> <p>Specify data to use as reference for the model with time range. Data need to be already uploaded on ML cube Platform.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model from_timestamp to_timestamp</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddModelReferenceException</code></p>"},{"location":"api/python/client/#add_production_data","title":".add_production_data","text":"<pre><code>.add_production_data(\n   task_id: str, inputs: Optional[Data] = None, target: Optional[Data] = None,\n   predictions: Optional[List[Tuple[str, Data]]] = None\n)\n</code></pre> <p>Add a batch of production data associated with a given task.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>inputs  : data object that contain input data source.     It can be None if you upload other kinds of data</li> <li>target  : data object that contains target data.     It can be None if you upload other kinds of data</li> <li>predictions  : list of data objects that contain prediction data.     Each element is a tuple with model_id and data object.     It can be None if you upload other kinds of data</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddProductionDataException</code></p>"},{"location":"api/python/client/#create_kpi","title":".create_kpi","text":"<pre><code>.create_kpi(\n   project_id: str, name: str\n)\n</code></pre> <p>Create a KPI.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>name  : the name of the kpi</li> </ul> <p>Returns</p> <ul> <li>kpi_id  : <code>str</code> identifier of the created kpi</li> </ul> <p>Raises</p> <p><code>CreateKpiException</code></p>"},{"location":"api/python/client/#get_kpi","title":".get_kpi","text":"<pre><code>.get_kpi(\n   kpi_id: str\n)\n</code></pre> <p>Get kpi by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>kpi_id  : identifier of the kpi</li> </ul> <p>Returns</p> <ul> <li>kpi  : <code>KPI</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_kpis","title":".get_kpis","text":"<pre><code>.get_kpis(\n   project_id: str\n)\n</code></pre> <p>Get all kpis of a project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : identifier of the project</li> </ul> <p>Returns</p> <ul> <li>kpis_list  : <code>List[KPI]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_kpis","title":".show_kpis","text":"<pre><code>.show_kpis(\n   project_id: str\n)\n</code></pre> <p>Show the list of KPIs included in a project to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> </ul> <p>Example output: <pre><code>KPI Id                    Project Id                Name                    Status           Status start timestamp    Status insert date\n------------------------  ------------------------  ----------------------  ---------------  ------------------------  --------------------------\n64fecf7d323311ab78f17280  64fecf7c323311ab78f17262  model_local_experiment  not_initialized                            2023-09-11 08:27:41.431000\n</code></pre></p>"},{"location":"api/python/client/#add_kpi_data","title":".add_kpi_data","text":"<pre><code>.add_kpi_data(\n   project_id: str, kpi_id: str, kpi: TabularData\n)\n</code></pre> <p>Add a batch of a given kpi with the given project.</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>kpi_id  : the identifier of the kpi</li> <li>kpi  : data object that contains data source.</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>AddKPIDataException</code></p>"},{"location":"api/python/client/#compute_retraining_report","title":".compute_retraining_report","text":"<pre><code>.compute_retraining_report(\n   model_id: str\n)\n</code></pre> <p>Compute the retraining report for a given model</p> <p>This request starts an operation pipeline that is executed by ML cube Platform. Thus, the method returns the identifier of the job that you can monitor to know its status and proceed with the other work using the method <code>wait_job_completion(job_id)</code></p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> identifier of the submitted job</li> </ul> <p>Raises</p> <p><code>ComputeRetrainingReportException</code></p>"},{"location":"api/python/client/#get_retraining_report","title":".get_retraining_report","text":"<pre><code>.get_retraining_report(\n   model_id: str\n)\n</code></pre> <p>For a given model id, get the sample weights computed and additional information about them included in the retraining report</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> </ul> <p>Returns</p> <ul> <li>retraining_report  : <code>RetrainingReport</code></li> </ul> <p>Raises</p> <p><code>GetRetrainingReportException</code></p>"},{"location":"api/python/client/#get_jobs","title":".get_jobs","text":"<pre><code>.get_jobs(\n   project_id: Optional[str] = None, task_id: Optional[str] = None,\n   model_id: Optional[str] = None, status: Optional[JobStatus] = None,\n   job_id: Optional[str] = None\n)\n</code></pre> <p>Get current jobs information. Jobs can be filtered by project_id, task_id, model_id or status.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the project_id to filter job.     If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job.     If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job.     If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job.     If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter.     If <code>None</code> job with every id will be retrieved</li> </ul> <p>Returns</p> <ul> <li>jobs_list  : <code>List[Job]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_job","title":".get_job","text":"<pre><code>.get_job(\n   job_id: str\n)\n</code></pre> <p>Get current job information.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>job_id  : id of the job to retrieve</li> </ul> <p>Returns</p> <ul> <li>job  : <code>Job</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_jobs","title":".show_jobs","text":"<pre><code>.show_jobs()\n</code></pre> <p>Show current job information to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_detection_events","title":".get_detection_events","text":"<pre><code>.get_detection_events(\n   task_id: str\n)\n</code></pre> <p>Get all detection event of a given task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : id of the task for which you want to retrieve the detection event</li> </ul> <p>Returns</p> <ul> <li>rules_list  : <code>List[DetectionEvent]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_detection_event_rules","title":".get_detection_event_rules","text":"<pre><code>.get_detection_event_rules(\n   task_id: str\n)\n</code></pre> <p>Get all detection event rules of a given task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : id of the task for which you want to retrieve the detection event rules</li> </ul> <p>Returns</p> <ul> <li>rules_list  : <code>List[DetectionEventRule]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_detection_event_rule","title":".get_detection_event_rule","text":"<pre><code>.get_detection_event_rule(\n   rule_id: str\n)\n</code></pre> <p>Get a detection event rule by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : id of the rule</li> </ul> <p>Returns</p> <ul> <li>rule  : <code>DetectionEventRule</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_detection_event_rule","title":".create_detection_event_rule","text":"<pre><code>.create_detection_event_rule(\n   name: str, task_id: str, severity: DetectionEventSeverity,\n   detection_event_type: DetectionEventType, monitoring_target: MonitoringTarget,\n   actions: List[DetectionEventAction], model_name: Optional[str] = None\n)\n</code></pre> <p>Create a detection event rule.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : the name of the rule</li> <li>task_id  : the id of the task to which the rule belongs.     The rule will only respond to detection events     generated by this task.</li> <li>model_name  : the name of the model, only required if     monitoring_target is set to MODEL.</li> <li>detection_event_type  : the type of detection event that     this rule should respond to.</li> <li>monitoring_target  : the type of monitoring target that     this rule should respond to.</li> <li>severity  : the level of severity of the detection event     that this rule should respond to.</li> <li>actions  : the list of actions to execute, in order,     when the conditions of the rule are matched.</li> </ul> <p>Returns</p> <ul> <li>rule_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateDetectionEventRuleException</code></p>"},{"location":"api/python/client/#update_detection_event_rule","title":".update_detection_event_rule","text":"<pre><code>.update_detection_event_rule(\n   rule_id: str, name: Optional[str] = None, model_name: Optional[str] = None,\n   severity: Optional[DetectionEventSeverity] = None,\n   detection_event_type: Optional[DetectionEventType] = None,\n   monitoring_target: Optional[MonitoringTarget] = None,\n   actions: Optional[List[DetectionEventAction]] = None\n)\n</code></pre> <p>Update a detection event rule.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : the id of the rule to update</li> <li>name  : the name of the rule. If None, keeps the existing value.</li> <li>model_name  : the name of the model, only required if     monitoring_target is set to MODEL.     If None, keeps the existing value.</li> <li>detection_event_type  : the type of detection event that this     rule should respond to. If None, keeps the existing value.</li> <li>monitoring_target  : the type of monitoring target that this     rule should respond to. If None, keeps the existing value.</li> <li>severity  : the level of severity of the detection event that     this rule should respond to. If None, keeps the     existing value.</li> <li>actions  : the list of actions to execute, in order, when the     conditions of the rule are matched. If None,      keeps the existing value.</li> </ul> <p>Raises</p> <p><code>CreateDetectionEventRuleException</code></p>"},{"location":"api/python/client/#delete_detection_event_rule","title":".delete_detection_event_rule","text":"<pre><code>.delete_detection_event_rule(\n   rule_id: str\n)\n</code></pre> <p>Delete a detection event rule by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>rule_id  : id of the rule to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#wait_job_completion","title":".wait_job_completion","text":"<pre><code>.wait_job_completion(\n   job_id: str, max_wait_timeout: int = 3000\n)\n</code></pre> <p>Wait that the ML cube Platform job terminates successfully its execution.</p> <p>Note that this method stops the execution.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>job_id  : identifier of the job</li> <li>max_wait_timeout  : maximum amount of seconds to wait before     launching <code>JobWaitTimeoutException</code></li> </ul> <p>Raises</p> <ul> <li><code>JobWaitTimeoutException</code> when the maximum timeout time     is reached</li> <li><code>JobNotFoundException</code> when the requested job does not     exist</li> <li><code>JobFailureException</code> when the requested job is failed</li> </ul>"},{"location":"api/python/client/#create_company_user","title":".create_company_user","text":"<pre><code>.create_company_user(\n   name: str, surname: str, username: str, password: str, email: str,\n   company_role: UserCompanyRole\n)\n</code></pre> <p>Creates a new User in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> </ul> <p>Args</p> <ul> <li>name  : name of the user</li> <li>surname  : surname of the user</li> <li>username  : username of the user</li> <li>password  : temporary password for the user. It will change     this at the first login</li> <li>email  : email of the user</li> <li>company_role  : role of the user inside the company</li> </ul> <p>Returns</p> <ul> <li>user_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_company_users","title":".get_company_users","text":"<pre><code>.get_company_users()\n</code></pre> <p>Returns the list of users in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>users_list  : <code>List[CompanyUser]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#change_user_company_role","title":".change_user_company_role","text":"<pre><code>.change_user_company_role(\n   user_id: str, company_role: UserCompanyRole\n)\n</code></pre> <p>Change the company role of a user in the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code>: can change the roles of all the Users     Users apart from other Admins and the Owner</li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which the role is updated</li> <li>company_role  : the new role to assign</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_company_users","title":".show_company_users","text":"<pre><code>.show_company_users()\n</code></pre> <p>Show company users to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_user_projects","title":".get_user_projects","text":"<pre><code>.get_user_projects(\n   user_id: str\n)\n</code></pre> <p>Returns a list of projects that the user can view.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> </ul> <p>Returns</p> <ul> <li>projects_list  : <code>List[Project]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_user_projects","title":".show_user_projects","text":"<pre><code>.show_user_projects(\n   user_id: str\n)\n</code></pre> <p>Shows the projects that the user can view to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#add_user_project_role","title":".add_user_project_role","text":"<pre><code>.add_user_project_role(\n   user_id: str, project_id: str, project_role: UserProjectRole\n)\n</code></pre> <p>Add a project role to the user for the given project.</p> <p>The User Project role can be assigned only to <code>COMPANY_USER</code> because Admin and Owner already have all the permission over projects.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> <li>project_id  : identifies the project</li> <li>project_role  : the project role to assign</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_project_role","title":".delete_project_role","text":"<pre><code>.delete_project_role(\n   user_id: str, project_id: str\n)\n</code></pre> <p>Delete the role of the user for the given project.</p> <p>The User Project role can be deleted only for <code>COMPANY_USER</code> because Admin and Owner have all the permission over projects.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user for which you want to see the list</li> <li>project_id  : identifies the project</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_api_keys","title":".get_api_keys","text":"<pre><code>.get_api_keys()\n</code></pre> <p>Returns a list of api keys the user has.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>api_keys_list  : <code>List[ApiKey]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_api_keys","title":".show_api_keys","text":"<pre><code>.show_api_keys()\n</code></pre> <p>Shows the list of api keys the user has to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_api_key","title":".create_api_key","text":"<pre><code>.create_api_key(\n   name: str, expiration_time: ApiKeyExpirationTime\n)\n</code></pre> <p>Create a new api key for the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Returns</p> <ul> <li>name  : the name of the api key</li> <li>expiration_time  : the expiration time of the api key</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_api_key","title":".delete_api_key","text":"<pre><code>.delete_api_key(\n   api_key: str\n)\n</code></pre> <p>Delete the api key of the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_USER</code></li> </ul> <p>Args</p> <ul> <li>api_key  : api key to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_user_api_keys","title":".get_user_api_keys","text":"<pre><code>.get_user_api_keys(\n   user_id: str\n)\n</code></pre> <p>Get the list of api keys a user has.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to get his api keys</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_user_api_keys","title":".show_user_api_keys","text":"<pre><code>.show_user_api_keys(\n   user_id: str\n)\n</code></pre> <p>Shows the list of api keys a user has to stdout.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to get his api keys</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_user_api_key","title":".create_user_api_key","text":"<pre><code>.create_user_api_key(\n   user_id: str, name: str, expiration_time: ApiKeyExpirationTime\n)\n</code></pre> <p>Create a new api key for the user.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user to create a new api key</li> <li>name  : the name of the api key</li> <li>expiration_time  : the expiration time of the api key</li> </ul> <p>Returns</p> <ul> <li>api_key  : the new created api key for the user</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_user_api_key","title":".delete_user_api_key","text":"<pre><code>.delete_user_api_key(\n   user_id: str, api_key: str\n)\n</code></pre> <p>Delete the api key of the user</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code>     Admin</li> </ul> <p>Args</p> <ul> <li>user_id  : the user to delete an api key</li> <li>api_key  : the api key to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#change_company_owner","title":".change_company_owner","text":"<pre><code>.change_company_owner(\n   user_id: str\n)\n</code></pre> <p>Change the company owner role from the requesting user to the other user.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> </ul> <p>Args</p> <ul> <li>user_id  : the user that become Company Owner</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_company_user","title":".delete_company_user","text":"<pre><code>.delete_company_user(\n   user_id: str\n)\n</code></pre> <p>Delete a user from the company.</p> <p>Allowed Roles:</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code>: cannot delete other company admins</li> </ul> <p>Args</p> <ul> <li>user_id  : the user to delete</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_integration_credentials","title":".get_integration_credentials","text":"<pre><code>.get_integration_credentials(\n   credentials_id: str\n)\n</code></pre> <p>Get the credentials with the given id for 3<sup>rd</sup> party service provider integration.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for the project where the credentials have been configured</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>credentials_id  : id of the integration credentials to retrieve.</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>IntegrationCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_all_project_integration_credentials","title":".get_all_project_integration_credentials","text":"<pre><code>.get_all_project_integration_credentials(\n   project_id: str\n)\n</code></pre> <p>Get the list of credentials for 3<sup>rd</sup> party service provider integrations that are currently configured in a project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : id of the project for which all configured credentials should be retrieved.</li> </ul> <p>Returns</p> <ul> <li>credentials_list  : <code>List[IntegrationCredentials]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#delete_integration_credentials","title":".delete_integration_credentials","text":"<pre><code>.delete_integration_credentials(\n   credentials_id: str\n)\n</code></pre> <p>Delete credentials for the integration with a 3<sup>rd</sup> party  service provider.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project where the credentials have been configured</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code>: cannot delete other company admins</li> </ul> <p>Args</p> <ul> <li>credentials_id  : id of the integration credentials to delete.</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#set_integration_credentials_as_default","title":".set_integration_credentials_as_default","text":"<pre><code>.set_integration_credentials_as_default(\n   credentials_id: str\n)\n</code></pre> <p>Set the credentials with the given id as default for 3<sup>rd</sup> party  service provider integration.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project where the credentials have been configured</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>credentials_id  : id of the integration credentials to set as default.</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_aws_integration_credentials","title":".create_aws_integration_credentials","text":"<pre><code>.create_aws_integration_credentials(\n   name: str, default: bool, project_id: str, role_arn: str\n)\n</code></pre> <p>Create credentials to integrate with AWS. Returns an object that contains the external_id you will need to configure in your trust policy.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>role_arn  : the ARN of the IAM role that will be assumed by ML     cube Platform</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>SecretAWSCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_gcp_integration_credentials","title":".create_gcp_integration_credentials","text":"<pre><code>.create_gcp_integration_credentials(\n   name: str, default: bool, project_id: str, service_account_info_json: str\n)\n</code></pre> <p>Create credentials to integrate with GCP.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>service_account_info_json  : the json-encoded string     containing the key of the service account</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>GCPCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#create_azure_integration_credentials","title":".create_azure_integration_credentials","text":"<pre><code>.create_azure_integration_credentials(\n   name: str, default: bool, project_id: str,\n   service_principal_credentials_json: str\n)\n</code></pre> <p>Create credentials to integrate with Azure.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>UPDATE_PROJECT_INFORMATION</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : a simple name to identify this set of credentials</li> <li>default  : whether to use these credentials by default when     using an AWS integration</li> <li>project_id  : the project in which these credentials will     be configured</li> <li>service_principal_credentials_json  : the json-encoded string     containing the credentials of the service principal</li> </ul> <p>Returns</p> <ul> <li>credentials  : <code>AzureCredentials</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#set_retrain_trigger","title":".set_retrain_trigger","text":"<pre><code>.set_retrain_trigger(\n   model_id: str, trigger: Optional[RetrainTrigger]\n)\n</code></pre> <p>Set the retrain trigger for a given model.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the id of the model</li> <li>trigger  : the trigger to set. If you want to remove the     trigger, set it to None</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#test_retrain_trigger","title":".test_retrain_trigger","text":"<pre><code>.test_retrain_trigger(\n   model_id: str, trigger: RetrainTrigger\n)\n</code></pre> <p>Test the retrain trigger for a given model.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the id of the model</li> <li>trigger  : the trigger to test</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#retrain_model","title":".retrain_model","text":"<pre><code>.retrain_model(\n   model_id: str\n)\n</code></pre> <p>Retrain a model via the configured retrain trigger.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>WORK_ON_PROJECT</code> for the project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the id of the model</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/enums/","title":"Enums","text":""},{"location":"api/python/enums/#apikeyexpirationtime","title":"ApiKeyExpirationTime","text":"<pre><code>ApiKeyExpirationTime()\n</code></pre> <p>Fields:</p> <ul> <li>ONE_MONTH</li> <li>THREE_MONTHS</li> <li>SIX_MONTHS</li> <li>ONE_YEAR</li> <li>NEVER</li> </ul>"},{"location":"api/python/enums/#columnrole","title":"ColumnRole","text":"<pre><code>ColumnRole()\n</code></pre> <p>Column role enum Describe the role of a column</p>"},{"location":"api/python/enums/#currency","title":"Currency","text":"<pre><code>Currency()\n</code></pre> <p>Currency of to use for the Task</p>"},{"location":"api/python/enums/#datastructure","title":"DataStructure","text":"<pre><code>DataStructure()\n</code></pre> <p>Represents the typology of the data to send</p> <p>Fields:</p> <ul> <li>TABULAR</li> <li>IMAGE</li> </ul>"},{"location":"api/python/enums/#datatype","title":"DataType","text":"<pre><code>DataType()\n</code></pre> <p>Data type enum Describe data type of an input</p>"},{"location":"api/python/enums/#detectioneventactiontype","title":"DetectionEventActionType","text":"<pre><code>DetectionEventActionType()\n</code></pre> <p>Fields:</p> <ul> <li>DISCORD_NOTIFICATION</li> <li>SLACK_NOTIFICATION</li> </ul>"},{"location":"api/python/enums/#detectioneventseverity","title":"DetectionEventSeverity","text":"<pre><code>DetectionEventSeverity()\n</code></pre> <p>Fields:</p> <ul> <li>LOW</li> <li>MEDIUM</li> <li>HIGH</li> </ul>"},{"location":"api/python/enums/#detectioneventtype","title":"DetectionEventType","text":"<pre><code>DetectionEventType()\n</code></pre> <p>Fields:</p> <ul> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#externalintegration","title":"ExternalIntegration","text":"<pre><code>ExternalIntegration()\n</code></pre> <p>An integration with a 3<sup>rd</sup> party service provider</p> <p>Fields: - AWS - GCP - AZURE</p>"},{"location":"api/python/enums/#filetype","title":"FileType","text":"<pre><code>FileType()\n</code></pre> <p>Fields:</p> <ul> <li>CSV</li> <li>JSON</li> </ul>"},{"location":"api/python/enums/#foldertype","title":"FolderType","text":"<pre><code>FolderType()\n</code></pre> <p>Type of folder</p> <p>Fields</p> <ul> <li>UNCOMPRESSED</li> <li>TAR</li> <li>ZIP</li> </ul>"},{"location":"api/python/enums/#jobstatus","title":"JobStatus","text":"<pre><code>JobStatus()\n</code></pre> <p>Fields:</p> <ul> <li>IDLE</li> <li>STARTING</li> <li>RUNNING</li> <li>COMPLETED</li> <li>ERROR</li> </ul>"},{"location":"api/python/enums/#kpistatus","title":"KPIStatus","text":"<pre><code>KPIStatus()\n</code></pre> <p>Fields:</p> <ul> <li>NOT_INITIALIZED</li> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#modelmetricname","title":"ModelMetricName","text":"<pre><code>ModelMetricName()\n</code></pre> <p>Name of the model metrics that is associated with the model</p> <p>Fields: - RMSE - RSQUARE</p>"},{"location":"api/python/enums/#modelstatus","title":"ModelStatus","text":"<pre><code>ModelStatus()\n</code></pre> <p>Fields:</p> <ul> <li>NOT_INITIALIZED</li> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#monitoringtarget","title":"MonitoringTarget","text":"<pre><code>MonitoringTarget()\n</code></pre> <p>Fields:</p> <ul> <li>ERROR</li> <li>INPUT</li> <li>CONCEPT</li> <li>PREDICTION</li> </ul>"},{"location":"api/python/enums/#retraintriggertype","title":"RetrainTriggerType","text":"<pre><code>RetrainTriggerType()\n</code></pre> <p>Enumeration of the possible retrain triggers</p>"},{"location":"api/python/enums/#storagepolicy","title":"StoragePolicy","text":"<pre><code>StoragePolicy()\n</code></pre> <p>Enumeration that specifies the storage policy for the data sent to ML cube Platform</p> <p>Fields:     cloud     it needs to read data</p>"},{"location":"api/python/enums/#storingdatatype","title":"StoringDataType","text":"<pre><code>StoringDataType()\n</code></pre> <p>Fields:</p> <ul> <li>HISTORICAL</li> <li>REFERENCE</li> <li>PRODUCTION</li> </ul>"},{"location":"api/python/enums/#suggestiontype","title":"SuggestionType","text":"<pre><code>SuggestionType()\n</code></pre> <p>Enum to specify the preferred type of suggestion</p> <p>Fields: - SAMPLE_WEIGHTS - RESAMPLED_DATASET</p>"},{"location":"api/python/enums/#taskstatus","title":"TaskStatus","text":"<pre><code>TaskStatus()\n</code></pre> <p>Fields:</p> <ul> <li>OK</li> <li>WARNING</li> <li>DRIFT</li> </ul>"},{"location":"api/python/enums/#tasktype","title":"TaskType","text":"<pre><code>TaskType()\n</code></pre> <p>Fields:</p> <ul> <li>REGRESSION</li> <li>CLASSIFICATION</li> </ul>"},{"location":"api/python/enums/#usercompanyrole","title":"UserCompanyRole","text":"<pre><code>UserCompanyRole()\n</code></pre> <p>Fields:</p> <ul> <li>COMPANY_OWNER</li> <li>COMPANY_ADMIN</li> <li>COMPANY_USER</li> <li>COMPANY_NONE</li> </ul>"},{"location":"api/python/enums/#userprojectrole","title":"UserProjectRole","text":"<pre><code>UserProjectRole()\n</code></pre> <p>Fields:</p> <ul> <li>PROJECT_ADMIN</li> <li>PROJECT_USER</li> <li>PROJECT_VIEW</li> </ul>"},{"location":"api/python/exceptions/","title":"Exceptions","text":""},{"location":"api/python/exceptions/#adddataschemaexception","title":"AddDataSchemaException","text":"<pre><code>AddDataSchemaException()\n</code></pre> <p>AddDataSchemaException</p>"},{"location":"api/python/exceptions/#addhistoricaldataexception","title":"AddHistoricalDataException","text":"<pre><code>AddHistoricalDataException()\n</code></pre> <p>AddHistoricalDataException</p>"},{"location":"api/python/exceptions/#addkpidataexception","title":"AddKPIDataException","text":"<pre><code>AddKPIDataException()\n</code></pre> <p>AddKPIDataException</p>"},{"location":"api/python/exceptions/#addproductiondataexception","title":"AddProductionDataException","text":"<pre><code>AddProductionDataException()\n</code></pre> <p>AddProductionDataException</p>"},{"location":"api/python/exceptions/#addtargetdataexception","title":"AddTargetDataException","text":"<pre><code>AddTargetDataException()\n</code></pre> <p>AddTargetDataException</p>"},{"location":"api/python/exceptions/#computeretrainingreportexception","title":"ComputeRetrainingReportException","text":"<pre><code>ComputeRetrainingReportException()\n</code></pre> <p>ComputeRetrainingReportException</p>"},{"location":"api/python/exceptions/#createcompanyexception","title":"CreateCompanyException","text":"<pre><code>CreateCompanyException()\n</code></pre> <p>CreateCompanyException</p>"},{"location":"api/python/exceptions/#createdetectioneventruleexception","title":"CreateDetectionEventRuleException","text":"<pre><code>CreateDetectionEventRuleException()\n</code></pre> <p>CreateDetectionEventRuleException</p>"},{"location":"api/python/exceptions/#createkpiexception","title":"CreateKPIException","text":"<pre><code>CreateKPIException()\n</code></pre> <p>CreateKPIEventRuleException</p>"},{"location":"api/python/exceptions/#createmodelexception","title":"CreateModelException","text":"<pre><code>CreateModelException()\n</code></pre> <p>CreateModelException</p>"},{"location":"api/python/exceptions/#createprojectexception","title":"CreateProjectException","text":"<pre><code>CreateProjectException()\n</code></pre> <p>CreateProjectException</p>"},{"location":"api/python/exceptions/#createtaskexception","title":"CreateTaskException","text":"<pre><code>CreateTaskException()\n</code></pre> <p>CreateTaskException</p>"},{"location":"api/python/exceptions/#getretrainingreportexception","title":"GetRetrainingReportException","text":"<pre><code>GetRetrainingReportException()\n</code></pre> <p>GetRetrainingReportException</p>"},{"location":"api/python/exceptions/#invalidactionlist","title":"InvalidActionList","text":"<pre><code>InvalidActionList()\n</code></pre> <p>Exception raised when the detection event actions in the rule are not valid</p>"},{"location":"api/python/exceptions/#jobfailureexception","title":"JobFailureException","text":"<pre><code>JobFailureException()\n</code></pre> <p>JobFailureException</p>"},{"location":"api/python/exceptions/#jobnotfoundexception","title":"JobNotFoundException","text":"<pre><code>JobNotFoundException()\n</code></pre> <p>JobNotFoundException</p>"},{"location":"api/python/exceptions/#jobwaittimeoutexception","title":"JobWaitTimeoutException","text":"<pre><code>JobWaitTimeoutException()\n</code></pre> <p>JobWaitTimeoutException</p>"},{"location":"api/python/exceptions/#sdkclientexception","title":"SDKClientException","text":"<pre><code>SDKClientException(\n   error_code: str = 'UNEXPECTED', error_message: str = 'Anunexpectederroroccurred'\n)\n</code></pre> <p>Base class for client sdk exceptions</p>"},{"location":"api/python/exceptions/#setmodelreferenceexception","title":"SetModelReferenceException","text":"<pre><code>SetModelReferenceException()\n</code></pre> <p>AddModelReferenceException</p>"},{"location":"api/python/exceptions/#setmodelsuggestiontypeexception","title":"SetModelSuggestionTypeException","text":"<pre><code>SetModelSuggestionTypeException()\n</code></pre> <p>SetModelSuggestionTypeException</p>"},{"location":"api/python/exceptions/#updatecompanyexception","title":"UpdateCompanyException","text":"<pre><code>UpdateCompanyException()\n</code></pre> <p>UpdateCompanyException</p>"},{"location":"api/python/exceptions/#updatedataschemaexception","title":"UpdateDataSchemaException","text":"<pre><code>UpdateDataSchemaException()\n</code></pre> <p>UpdateDataSchemaException</p>"},{"location":"api/python/exceptions/#updatedetectioneventruleexception","title":"UpdateDetectionEventRuleException","text":"<pre><code>UpdateDetectionEventRuleException()\n</code></pre> <p>UpdateDetectionEventRuleException</p>"},{"location":"api/python/exceptions/#updatemodelversionexception","title":"UpdateModelVersionException","text":"<pre><code>UpdateModelVersionException()\n</code></pre> <p>UpdateModelVersionException</p>"},{"location":"api/python/exceptions/#updateprojectexception","title":"UpdateProjectException","text":"<pre><code>UpdateProjectException()\n</code></pre> <p>UpdateProjectException</p>"},{"location":"api/python/exceptions/#updatetaskexception","title":"UpdateTaskException","text":"<pre><code>UpdateTaskException()\n</code></pre> <p>UpdateTaskException</p>"},{"location":"api/python/models/","title":"Models","text":""},{"location":"api/python/models/#awscredentials","title":"AWSCredentials","text":"<pre><code>AWSCredentials()\n</code></pre> <p>AWS integration credentials.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>role_arn  : The ARN of the role that should be assumed via STS</li> </ul>"},{"location":"api/python/models/#awseventbridgeretraintrigger","title":"AWSEventBridgeRetrainTrigger","text":"<pre><code>AWSEventBridgeRetrainTrigger()\n</code></pre> <p>Base model to define an AWS EventBridge retrain trigger</p> <p>Fields: type credentials_id aws_region_name event_bus_name</p>"},{"location":"api/python/models/#apikey","title":"ApiKey","text":"<pre><code>ApiKey()\n</code></pre> <p>base model for api key</p> <p>Attributes</p> <ul> <li>api_key  : str</li> </ul>"},{"location":"api/python/models/#azureblobdatasource","title":"AzureBlobDataSource","text":"<pre><code>AzureBlobDataSource()\n</code></pre> <p>A source that identifies a blob in Azure Storage.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#get_path","title":".get_path","text":"<pre><code>.get_path()\n</code></pre>"},{"location":"api/python/models/#get_source_type","title":".get_source_type","text":"<pre><code>.get_source_type()\n</code></pre>"},{"location":"api/python/models/#azurecredentials","title":"AzureCredentials","text":"<pre><code>AzureCredentials()\n</code></pre> <p>Azure integration credentials.</p> <p>Attributes</p> <ul> <li>app_id  : The id of the service principal</li> </ul>"},{"location":"api/python/models/#azureeventgridretraintrigger","title":"AzureEventGridRetrainTrigger","text":"<pre><code>AzureEventGridRetrainTrigger()\n</code></pre> <p>Base model to define an Azure EventGrid retrain trigger</p> <p>Fields: type credentials_id topic_endpoint</p>"},{"location":"api/python/models/#classificationtaskcostinfo","title":"ClassificationTaskCostInfo","text":"<pre><code>ClassificationTaskCostInfo()\n</code></pre> <p>Regression cost info is expressed in two terms: - cost due to overestimation - cost due to underestimation</p> <p>Fields: currency false_positive_cost false_negative_cost</p>"},{"location":"api/python/models/#columninfo","title":"ColumnInfo","text":"<pre><code>ColumnInfo()\n</code></pre> <p>Column base model</p> <p>Attributes</p> <ul> <li>name  : str</li> <li>role  : ColumnRole</li> <li>is_nullable  : bool</li> <li>data_type  : DataType</li> <li>predicted_target  : Optional[str] = None</li> <li>possible_values  : Optional[List] = None</li> <li>model_id  : Optional[str] = None</li> <li>dims  : Optional[Tuple[int]] = None     it is manadatory when data_type is Array</li> </ul>"},{"location":"api/python/models/#company","title":"Company","text":"<pre><code>Company()\n</code></pre> <p>Company model</p> <p>Attributes</p> <ul> <li>company_id  : str</li> <li>name  : str</li> <li>address  : str</li> <li>vat  : str</li> </ul>"},{"location":"api/python/models/#companyuser","title":"CompanyUser","text":"<pre><code>CompanyUser()\n</code></pre> <p>base model for company user</p> <p>Attributes</p> <ul> <li>user_id  : str</li> <li>company_role  : UserCompanyRole</li> </ul>"},{"location":"api/python/models/#data","title":"Data","text":"<pre><code>Data()\n</code></pre> <p>Generic data model that contains all information about a data</p> <p>Attributes</p> <ul> <li>data_structure  : DataStructure</li> <li>source  : DataSource</li> </ul>"},{"location":"api/python/models/#dataschema","title":"DataSchema","text":"<pre><code>DataSchema()\n</code></pre> <p>Data schema base model</p> <p>Attributes</p> <ul> <li>columns  : List[ColumnInfo]</li> </ul>"},{"location":"api/python/models/#datasource","title":"DataSource","text":"<pre><code>DataSource()\n</code></pre> <p>Generic data source.</p>"},{"location":"api/python/models/#detectionevent","title":"DetectionEvent","text":"<pre><code>DetectionEvent()\n</code></pre> <p>An event created during the detection process.</p> <p>Attributes</p> <ul> <li>event_id  : str</li> <li>event_type  : DetectionEventType</li> <li>monitoring_target  : MonitoringTarget</li> <li>severity_type  : Optional[DetectionEventSeverity]</li> <li>insert_datetime  : str</li> <li>sample_timestamp  : float</li> <li>sample_id  : str</li> <li>model_id  : Optional[str]</li> <li>model_name  : Optional[str]</li> <li>model_version  : Optional[str]</li> </ul>"},{"location":"api/python/models/#detectioneventaction","title":"DetectionEventAction","text":"<pre><code>DetectionEventAction()\n</code></pre> <p>Generic action that can be performed</p> <p>Attributes</p> <ul> <li>type  : DetectionEventActionType</li> </ul>"},{"location":"api/python/models/#detectioneventrule","title":"DetectionEventRule","text":"<pre><code>DetectionEventRule(\n   **kwargs\n)\n</code></pre> <p>A rule that can be triggered by a detection event, and executes a series of actions.</p> <p>Attributes</p> <ul> <li>rule_id  : str</li> <li>name  : str</li> <li>task_id  : str</li> <li>model_name  : Optional[str]</li> <li>severity  : DetectionEventSeverity</li> <li>detection_event_type  : DetectionEventType</li> <li>monitoring_target  : MonitoringTarget</li> <li>actions  : List[DetectionEventAction]</li> </ul>"},{"location":"api/python/models/#discordnotificationaction","title":"DiscordNotificationAction","text":"<pre><code>DiscordNotificationAction()\n</code></pre> <p>Action that sends a notification to a Discord server through a webhook that you configure</p> <p>Attributes</p> <ul> <li>webhook  : str type = DetectionEventActionType.DISCORD_NOTIFICATION</li> </ul>"},{"location":"api/python/models/#emailnotificationaction","title":"EmailNotificationAction","text":"<pre><code>EmailNotificationAction()\n</code></pre> <p>Base Model for Email Notification Action</p> <p>Attributes</p> <ul> <li>address  : str type = DetectionEventActionType.EMAIL_NOTIFICATION</li> </ul>"},{"location":"api/python/models/#gcpcredentials","title":"GCPCredentials","text":"<pre><code>GCPCredentials()\n</code></pre> <p>GCP integration credentials.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>gcp_project_id  : The id of the project on GCP</li> <li>client_email  : The email that identifies the service account</li> <li>client_id  : The client id</li> </ul>"},{"location":"api/python/models/#gcppubsubretraintrigger","title":"GCPPubSubRetrainTrigger","text":"<pre><code>GCPPubSubRetrainTrigger()\n</code></pre> <p>Base model to define a GCP PubSub retrain trigger</p> <p>Fields: type credentials_id topic_name</p>"},{"location":"api/python/models/#gcsdatasource","title":"GCSDataSource","text":"<pre><code>GCSDataSource()\n</code></pre> <p>A source that identifies a file in a GCS bucket.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#get_path_1","title":".get_path","text":"<pre><code>.get_path()\n</code></pre>"},{"location":"api/python/models/#get_source_type_1","title":".get_source_type","text":"<pre><code>.get_source_type()\n</code></pre>"},{"location":"api/python/models/#imagedata","title":"ImageData","text":"<pre><code>ImageData()\n</code></pre> <p>Image unstructured data</p>"},{"location":"api/python/models/#integrationcredentials","title":"IntegrationCredentials","text":"<pre><code>IntegrationCredentials()\n</code></pre> <p>Credentials to authenticate to a 3<sup>rd</sup> party service provider via an integration.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> </ul>"},{"location":"api/python/models/#job","title":"Job","text":"<pre><code>Job()\n</code></pre> <p>Job information item model</p> <p>Attributes</p> <ul> <li>job_id  : str</li> <li>job_group  : str</li> <li>project_id  : str</li> <li>project_name  : str</li> <li>task_id  : str</li> <li>task_name  : str</li> <li>model_id  : Optional[str]</li> <li>model_name  : Optional[str]</li> <li>status  : str</li> <li>error  : Optional[str]</li> </ul>"},{"location":"api/python/models/#kpi","title":"KPI","text":"<pre><code>KPI()\n</code></pre> <p>KPI base model</p> <p>Attributes</p> <ul> <li>kpi_id  : str</li> <li>name  : str</li> <li>status  : ModelStatus</li> <li>status_kpi_start_timestamp  : Optional[datetime]</li> <li>status_insert_datetime  : datetime</li> </ul>"},{"location":"api/python/models/#localdatasource","title":"LocalDataSource","text":"<pre><code>LocalDataSource()\n</code></pre> <p>Use this data source if you want to upload a file from your local disk to the ML cube platform cloud.</p> <p>Attributes</p> <ul> <li>file_path  : str</li> </ul>"},{"location":"api/python/models/#model","title":"Model","text":"<pre><code>Model()\n</code></pre> <p>Base model to define model item</p> <p>Attributes</p> <ul> <li>model_id  : str</li> <li>task_id  : str</li> <li>name  : str</li> <li>version  : str</li> <li>status  : ModelStatus</li> <li>status_data_start_timestamp  : Optional[str]</li> <li>status_insert_datetime  : datetime</li> <li>metric_name  : performance or error metric associated with     the model</li> <li>creation_datetime  : Optional[datetime]</li> <li>retrain_trigger  : Optional[RetrainTrigger]</li> </ul>"},{"location":"api/python/models/#project","title":"Project","text":"<pre><code>Project()\n</code></pre> <p>Project model</p> <p>Attributes</p> <ul> <li>project_id  : str</li> <li>name  : str</li> </ul>"},{"location":"api/python/models/#regressiontaskcostinfo","title":"RegressionTaskCostInfo","text":"<pre><code>RegressionTaskCostInfo()\n</code></pre> <p>Regression cost info is expressed in two terms: - cost due to overestimation - cost due to underestimation</p> <p>Fields: currency overestimation_cost underestimation_cost</p>"},{"location":"api/python/models/#remotedatasource","title":"RemoteDataSource","text":"<pre><code>RemoteDataSource()\n</code></pre> <p>A source that identifies where data is stored.</p> <p>Attributes</p> <ul> <li>credentials_id  : The id of the credentials to use to authenticate to the remote data source. If None, the default will be used</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#get_path_2","title":".get_path","text":"<pre><code>.get_path()\n</code></pre> <p>Return the path of the object</p>"},{"location":"api/python/models/#get_source_type_2","title":".get_source_type","text":"<pre><code>.get_source_type()\n</code></pre> <p>Returns raw data source type</p>"},{"location":"api/python/models/#resampleddatasetsuggestion","title":"ResampledDatasetSuggestion","text":"<pre><code>ResampledDatasetSuggestion()\n</code></pre> <p>ResampledDatasetSuggestion base model</p> <p>Attributes</p> <ul> <li>suggestion_id  : str</li> <li>suggestion_type  : SuggestionType</li> <li>sample_ids  : List[str]</li> <li>sample_counts  : List[int]</li> </ul>"},{"location":"api/python/models/#retrainaction","title":"RetrainAction","text":"<pre><code>RetrainAction()\n</code></pre> <p>Base Model for Retrain Action</p> <p>Attributes</p> <ul> <li>type  : DetectionEventActionType.RETRAIN</li> <li>model_name  : str</li> </ul>"},{"location":"api/python/models/#retraintrigger","title":"RetrainTrigger","text":"<pre><code>RetrainTrigger()\n</code></pre> <p>Base model to define a retrain trigger</p> <p>Fields: type credentials_id</p>"},{"location":"api/python/models/#retrainingreport","title":"RetrainingReport","text":"<pre><code>RetrainingReport()\n</code></pre> <p>base model for Retraining Report</p> <p>Attributes</p> <ul> <li>report_id  : str</li> <li>suggestion  : Suggestion</li> <li>effective_sample_size  : float</li> <li>model_metric_name  : str</li> <li>performance_upper_bound  : float</li> <li>performance_lower_bound  : float</li> <li>cost_upper_bound  : float</li> <li>cost_lower_bound  : float</li> </ul>"},{"location":"api/python/models/#s3datasource","title":"S3DataSource","text":"<pre><code>S3DataSource()\n</code></pre> <p>A source that identifies a file in an S3 bucket.</p> <p>Attributes</p> <ul> <li>object_path  : str</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#get_path_3","title":".get_path","text":"<pre><code>.get_path()\n</code></pre>"},{"location":"api/python/models/#get_source_type_3","title":".get_source_type","text":"<pre><code>.get_source_type()\n</code></pre>"},{"location":"api/python/models/#sampleweightssuggestion","title":"SampleWeightsSuggestion","text":"<pre><code>SampleWeightsSuggestion()\n</code></pre> <p>SampleWeightsSuggestion base model</p> <p>Attributes</p> <ul> <li>suggestion_id  : str</li> <li>suggestion_type  : SuggestionType</li> <li>sample_ids  : List[str]</li> <li>sample_weights  : List[float]</li> </ul>"},{"location":"api/python/models/#secretawscredentials","title":"SecretAWSCredentials","text":"<pre><code>SecretAWSCredentials()\n</code></pre> <p>AWS integration credentials, that also include the external_id you need to set up the trust policy on AWS.</p> <p>Attributes</p> <ul> <li>credentials_id  : str</li> <li>name  : str</li> <li>default  : bool</li> <li>type  : ExternalIntegration</li> <li>role_arn  : The ARN of the IAM role that should be assumed</li> <li>external_id  : Secret key used to assume the IAM role via STS</li> </ul> <p>Methods:</p>"},{"location":"api/python/models/#generate_trust_policy","title":".generate_trust_policy","text":"<pre><code>.generate_trust_policy()\n</code></pre> <p>Generates a JSON trust policy that you can copy into the IAM role on AWS.</p>"},{"location":"api/python/models/#slacknotificationaction","title":"SlackNotificationAction","text":"<pre><code>SlackNotificationAction()\n</code></pre> <p>Action that sends a notification to a Slack channel through a webhook that you configure.</p> <p>Attributes</p> <ul> <li>webhook  : str</li> <li>channel  : str type = DetectionEventActionType.SLACK_NOTIFICATION</li> </ul>"},{"location":"api/python/models/#suggestion","title":"Suggestion","text":"<pre><code>Suggestion()\n</code></pre> <p>Suggestion base model</p> <p>Attributes</p> <ul> <li>suggestion_id  : str</li> <li>suggestion_type  : SuggestionType</li> </ul>"},{"location":"api/python/models/#suggestioninfo","title":"SuggestionInfo","text":"<pre><code>SuggestionInfo()\n</code></pre> <p>SuggestionInfo base model</p> <p>Attributes</p> <ul> <li>id  : str</li> <li>executed  : bool</li> <li>timestamp  : str</li> </ul>"},{"location":"api/python/models/#tabulardata","title":"TabularData","text":"<pre><code>TabularData()\n</code></pre> <p>Tabular data model i.e., a data that can be represented via DataFrame and is stored in formats like: csv, parquet, json</p>"},{"location":"api/python/models/#task","title":"Task","text":"<pre><code>Task()\n</code></pre> <p>Task model</p> <p>Attributes</p> <ul> <li>task_id  : str</li> <li>name  : str</li> <li>type  : TaskType</li> <li>status  : TaskStatus</li> <li>status_start_date  : str</li> </ul>"},{"location":"api/python/models/#taskcostinfo","title":"TaskCostInfo","text":"<pre><code>TaskCostInfo()\n</code></pre> <p>Base class for task cost info. It depends on TaskType because classification is different from regression in terms of business costs due to errors</p>"},{"location":"api/python/models/#teamsnotificationaction","title":"TeamsNotificationAction","text":"<pre><code>TeamsNotificationAction()\n</code></pre> <p>Base Model for Teams Notification Action</p> <p>Attributes</p> <ul> <li>type  : DetectionEventActionType.TEAMS_NOTIFICATION</li> <li>webhook  : str</li> </ul>"},{"location":"api/python/models/#unstructureddata","title":"UnstructuredData","text":"<pre><code>UnstructuredData()\n</code></pre> <p>Unstructured data model i.e., images, text or other. Since it is composed of multiple files, it needs a mapping between customer ids and those files</p> <p>Attributes</p> <ul> <li>mapping_source  : DataSource</li> </ul>"},{"location":"api/rest/","title":"REST API","text":"<p>Page under construction</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>ML cube Platform is built following the API first principle, by which it can be used both via Web Application and REST API. In this first guide, we explain the basic concepts in ML cube Platform. In order to find easily every information we suggest you to use the search bar, moreover, you can go to Glossary to find the key concepts and definition we use along this site.</p> <p>Example Company</p> <p>Every time you find a section like this you will see a examples with a fictional company that will help you to better understand the concepts and the entities in ML cube Platform. We will use a fictional company called Delta Energy that is a producer of Photovoltaic Modules that own Photovoltaic fields and trades the produced energy to the market.</p>"},{"location":"user_guide/#company","title":"Company","text":"<p>To use ML cube Platform you need to belong to a Company that is created during your first login in the Web Application. Everything will be done inside it, for example, if you want your colleagues to work with you in ML cube Platform you need to create new Users inside the company. Users has assigned a specific Role that defines their privileges and what they are able to do (refer to User Roles for more information).</p>"},{"location":"user_guide/#project","title":"Project","text":"<p>Your work on ML cube Platform is organized through Projects, Task and Models. A Project is an artificial intelligence application that uses a set of algorithms to reach a common set of KPIs, usually a Project contains several Tasks.</p> <p>Delta Energy inc</p> <p>Delta Energy, created the Energy Revenue Project to enhance their revenue from energy trading. They invested in four AI algorithms:</p> <ul> <li>Fault detection</li> <li>Fault diagnosis</li> <li>Soiling detection</li> <li>Trading</li> </ul> <p>In ML cube Platform, these four algorithms define four Tasks inside the Project Energy Revenue. They have been placed into the same Project because they share the business goal i.e., the net revenue, the data and are interdependent.</p>"},{"location":"user_guide/#task","title":"Task","text":"<p>As you may have guessed, in ML cube Platform a Task corresponds to an AI Algorithm. To be more precise, a Task is an AI Problem with a dataset composed of input features and a target. A Task can have more than one AI Model that uses the input features estimates the target.</p> <p>Delta Energy inc</p> <p>In out example company, the Fault Detection Task has as input features the PV modules and weather data and the target is the presence of a fault.  The Task has two Models: logistic regression and random forest.  Both models use the same data and predict the same target but are different in the techniques used to perform the estimation.</p> <p>A Task is specified by several attributes, the most important are:</p> <ul> <li><code>type</code>: regression, classification, object detection ...</li> <li><code>data structure</code>: tabular data, image data, ...</li> <li><code>optional target</code>: if the target is not always available. This happen when input samples are labeled and the most part of production data do not have a label</li> <li><code>data schema</code>: specifies the inputs and the target of the task, see Data Schema section for more details</li> <li><code>cost info</code>: information about the economic costs of the error on the target</li> </ul> <p>Delta Energy inc</p> <p>The Task of Fault Detection has clear costs due to false positives or false negatives.  Every time a fault is not detected the false negative cost is proportional to the power reduction. While, false positives determine costs for the maintenance team that will go on the field for nothing.</p>"},{"location":"user_guide/#model","title":"Model","text":"<p>The last entity is the Model that is the actual AI model that predicts the target. A Model has a Version that defines the training data used to train it. All model's data will be uploaded specifying the model version in order to track each prediction with the right model instance.  The model version is updated whenever a new training of the model is done.</p> <p>A Model has the following attributes:</p> <ul> <li><code>name</code>: uniquely identifies the model inside the Task</li> <li><code>version</code>: specifies different trained instance of the model</li> <li><code>metric name</code>: metric to use to measure the model performance</li> <li><code>suggestion type</code>: type of retraining action to use for that model, see Retraining section for more details</li> <li><code>retraining cost</code>: how much model training cost. This information is used by the Business module</li> </ul> <p>Note</p> <p>It's worth nothing to note that in ML cube Platform you do not actually need to upload the model on the application.  We just need to know its training data and its predictions for the production data.  In this way, ML cube Platform is considered as model agnostic.</p> <p>Now that you have clear the basic concepts we invite you to explore the other ML cube Platform pages:</p> <ul> <li> <p> Modules</p> <p>Explore available features in ML cube Platform</p> <p> More info</p> </li> <li> <p> Integrations</p> <p>We are part of MLOps ecosystem and natively integrated with other solutions.</p> <p> More info</p> </li> <li> <p> Automation rules</p> <p>Discover how to setup automation rules to increase your reactivity.</p> <p> More info</p> </li> <li> <p> Roles and access</p> <p>Get more info about RBAC inside ML cube Platform</p> <p> More info</p> </li> </ul>"},{"location":"user_guide/data_schema/","title":"Data Schema","text":"<p>Data schema is the core attribute of a Machine Learning Task. It specifies the name of the quantities, their data type and role. A Data Schema is a collection of Column entity that has the following attributes:</p> <ul> <li><code>name</code>: name of the quantity. For Tabular data is the name of the column in the table.</li> <li><code>data type</code>: as the name suggests, it is the type data of the quantity: float, integer, categorical, array, ...</li> <li><code>nullable</code>: if the quantity is allowed to be missing</li> <li><code>role</code>: specifies what this quantity represents, it can be: <ul> <li>INPUT</li> <li>PREDICTION</li> <li>TARGET</li> <li>ID</li> <li>TIME_ID</li> </ul> </li> <li><code>dims</code>: if the data type is array, it represents its dimensions, for instance an image is an ARRAY_3 with dimensions (1920, 1080, 3)</li> </ul> <p>The data schema must always have:</p> <ul> <li>one Column with role ID that is the unique identifier of samples used to recognize them</li> <li>one Column with role TIME_ID that is used to temporally order the samples</li> <li>at least one Column with role INPUT</li> <li>one Column with role TARGET</li> <li>one Column for each model created in the Task (this Column is added automatically by the application and have the following name <code>MODEL_NAME@MODEL_VERSION</code>)</li> </ul>"},{"location":"user_guide/detection_event_rules/","title":"Detection Event Rules","text":"<p>This section provides an overview of how you can setup automation rules after a detection event occurs in order to receive notifications or to start retraining.</p> <p>When a detection event occurs, the platform evaluates your set detection event rules. If a rule matches the event, the specified actions will be triggered. These rules are specific to a task and require the following parameters for configuration:</p> <ul> <li><code>name</code>: A descriptive label for your rule, helping you understand its purpose quickly.</li> <li><code>task_id</code>: The unique identifier of the task to which the rule is applicable.</li> <li><code>severity</code>: Indicates the severity level of the event - it can be <code>HIGH</code>, <code>MEDIUM</code>, or <code>LOW</code>.</li> <li><code>detection_event_type</code>: Currently, only <code>DRIFT</code> events are available for detection.</li> <li><code>monitoring_target</code>: Specifies what is being monitored, which can be <code>MODEL</code>, <code>INPUT</code>, or <code>CONCEPT</code>. If the value is <code>MODEL</code>, you need to provide a corresponding <code>model_name</code>.</li> <li><code>actions</code>: A sequential list of actions to be executed when the rule is triggered.</li> </ul>"},{"location":"user_guide/detection_event_rules/#supported-actions","title":"Supported Actions","text":"<p>Two types of actions are currently supported: notification and retrain.</p>"},{"location":"user_guide/detection_event_rules/#notifications","title":"Notifications","text":"<ul> <li><code>SlackNotificationAction</code>: sends a notification to a Slack channel via webhook.</li> <li><code>DiscordNotificationAction</code>: sends a notification to a Discord channel via webhook.</li> <li><code>EmailNotificationAction</code>: sends an email to the provided email address.</li> <li><code>TeamsNotificationAction</code>: sends a notification to Microsoft Teams via webhook.</li> </ul>"},{"location":"user_guide/detection_event_rules/#retrain-actions","title":"Retrain Actions","text":"<p>Retrain actions let you to retrain your model, therefore, they are only available when the rule monitoring target is a model. The retrain action does not need any parameter because it is automatically inferred from the <code>model_name</code> attribute of the rule. Of course, it is mandatory that the model has a retrain trigger associated in order to add a retrain action to the rule.</p> <p>Example</p> <p>The following code snippet demonstrates how to create a rule that matches high severity drift events for a specific model. When triggered, it sends a notification to the <code>ml3-platform-notifications</code> channel on your Slack workspace using the provided webhook URL and then start the retraining of the model.</p> <pre><code>rule_id = client.create_detection_event_rule(\n    name='Retrain model with notification',\n    task_id='my-task-id,\n    model_name='my-model',\n    severity=DetectionEventSeverity.HIGH,\n    detection_event_type=DetectionEventType.DRIFT,\n    monitoring_target=MonitoringTarget.MODEL,\n    actions=[\n        SlackNotificationAction(\n            webhook='https://hooks.slack.com/services/...',\n            channel='ml3-platform-notifications'\n        ),\n        RetrainAction()\n    ],\n)\n</code></pre>"},{"location":"user_guide/glossary/","title":"Glossary","text":""},{"location":"user_guide/glossary/#general-terms","title":"General Terms","text":"<ul> <li>User: registered user with username and password that interact with ML cube Platform.  A User can create API keys that inherits his/her permissions and that the he/she uses to communicate with ML cube Platform though API. </li> <li>Company: collection of Users that work with ML cube Platform.  Subscription plan and contracts with ML cube are managed at Company level. A Company has one owner that has all the privileges and that can assign admin role to other Users in the Company.</li> <li>Project: collection of AI Tasks that belong to the same business domain.</li> <li>Task: it is the standard AI problem with a dataset, a target and a set of AI models that predicts the target. All AI models inside the AI Task predicts the same target quantity and they are considered as champion and challengers or deployed and shadow models. Data drift detection is done at Task level because the models uses the same dataset.</li> <li>Model: AI model inside a Task that makes predictions over the Task's dataset.</li> </ul>"},{"location":"user_guide/glossary/#data-terms","title":"Data Terms","text":"<ul> <li>Historical data: data not used for the newest retraining but that belong to the Task. ML cube Platform uses these data during the retraining dataset selection to exploit all the available information. They are not mandatory, if they are not present then the Retraining Tool selects data from the reference set and the production data.</li> <li>Reference data: dataset used as reference for the current model version. It can be the training dataset, the test set or both. Reference data represents the current view of the model over the Task</li> <li>Production data: data the model encounter during production, the production data are monitored by the ML cube Platform detectors to detect drifts</li> <li>Data schema: represents the schema of the data that ML cube Platform uses to know the features and the target columns.</li> </ul>"},{"location":"user_guide/glossary/#drifts-terms","title":"Drifts Terms","text":"<ul> <li>Input drift: statistically significant change in the input data P(X)</li> <li>Concept drift: statistically significant change in the input and target data P(X, y)</li> <li>Model drift: statistically significant change in the model error P(y \u2013 y_pred).</li> <li>Detection Event: event generated by a detector, it has a monitoring target, a severity and a type (warning, drift)</li> </ul>"},{"location":"user_guide/glossary/#actions-terms","title":"Actions Terms","text":"<ul> <li>Importance weights: the retraining dataset is given in form of a set of importance weights associated to every data available for the Task. This importance score will be used during the training pipeline of the customer to weights samples. In particular, the ML model will use the form of the sample weighted loss instead of the standard loss during its retraining phase</li> <li>Dataset boostrapping: if the ML model does not support the sample weighted loss then ML cube Platform can provide a dataset extracted from the available data using sampling with replacement based on the importance weights of the data. The customer can specify the size of the retraining dataset and ML cube Platform provides the best retraining bootstapped dataset of that size</li> <li>Relabeling: in case of concept drift in a classification Task, old labels are no meaningful, given a budget/size constraint ML cube Platform provides the subset of data to be relabelled</li> <li>Active Learning: ML cube Platform provides a set of new synthetic data to label or it provides indication where to collect new real data from the environment</li> </ul>"},{"location":"user_guide/rbac/","title":"User Roles","text":"<p>The Company owner can create new Users assigning to them a Role. The Role defines a set of actions a User has inside the application. Each User has associated a company role and one or more project roles.</p> <p>Delta Energy inc</p> <p>Delta Energy has one dedicated AI Team to each Task. Hence, they assigned specific Project Administrator Role to each Team leader; while the other Data Scientists have the Project Edit Role for the project they are working on.</p> <p> </p> User Roles in ML cube Platform. <p>The following tables shows the User roles:</p>"},{"location":"user_guide/rbac/#company-permissions","title":"Company Permissions","text":"Role DELETE_COMPANY CHANGE_COMPANY_OWNER MANAGE_COMPANY_ADMIN MANAGE_COMPANY_USER CHANGE_COMPANY_USER_ROLE UPDATE_COMPANY_INFORMATION READ_COMPANY CREATE_PROJECT COMPANY_OWNER COMPANY_ADMIN COMPANY_USER COMPANY_NONE"},{"location":"user_guide/rbac/#project-permissions","title":"Project Permissions","text":"Role DELETE_PROJECT MANAGE_PROJECT_ADMIN UPDATE_PROJECT_INFORMATION MANAGE_PROJECT_USER CHANGE_PROJECT_USER_ROLE WORK_ON_PROJECT READ_PROJECT COMPANY_OWNER COMPANY_ADMIN COMPANY_USER COMPANY_NONE PROJECT_ADMIN PROJECT_USER PROJECT_VIEW"},{"location":"user_guide/integrations/","title":"Integrations","text":"<p>Below, you will find a guide that will help you create the credentials and configure the permissions that ML cube will use to access your resources on the supported cloud providers.</p>"},{"location":"user_guide/integrations/#creating-the-credentials","title":"Creating the credentials","text":"Amazon Web ServicesGoogle Cloud PlatformMicrosoft Azure <p>The ML cube Platform can assume an IAM Role on your AWS Account, that can be used to authorize actions on specific resources. To create this, log into your AWS account and open the AWS console. Here, go to the IAM service, navigate to the Roles section and create a new role. When asked, select the Custom trust policy option and paste the following json:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Statement1\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::883313729965:root\"\n            },\n            \"Action\": \"sts:AssumeRole\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"sts:ExternalId\": \"&lt;EXTERNAL_ID&gt;\"\n                }\n            }\n        }\n    ]\n}\n</code></pre> <p><code>883313729965</code> is the ID of the AWS Account used by the ML cube Platform. It is important that this value is not changed. We will populate the value of <code>&lt;EXTERNAL_ID&gt;</code> in a later step. Give your role a name and save it.</p> <p>Now, you will need to create the credentials through the ML cube Platform SDK or the web application.</p> <p>Example</p> <p>The following code will create a set of AWS credentials from the IAM Role we just created.</p> <pre><code>aws_creds = client.create_aws_integration_credentials(\n    name='AWS_01',\n    default=True,  # Set these credentials as the default to use when not specified\n    project_id='your_project_id',\n    role_arn='arn:aws:iam::{{YOUR_AWS_ACCOUNT_ID}}:role/{{YOUR_ROLE_NAME}}',\n)\n\ntrust_policy = aws_creds.generate_trust_policy()\nprint(trust_policy)\n</code></pre> <p>You can call the <code>generate_trust_policy</code> function on the created credentials to obtain the trust policy. Edit your IAM Role and change the trust policy to the one you just obtained.</p> <p>Right now, your IAM Role grants no permissions. Please refer to the next sections that will explain how to set up IAM Policies for S3, Event Bridge and so on.</p> <p>To revoke access, simply delete the role or change the trust policy.</p> <p></p> <p>The ML cube Platform can operate in your GCP Account through the creation of a dedicated Service Account. You will then be able to assign one or more IAM Roles to this Service Account, to allow the ML cube Platform to perform specific actions.</p> <p>To configure a Service Account for ML cube Platform, log into your GCP account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Now we will enter some commands that will create the Service Account with the required permissions. A description of each command is provided to help you understand its purpose.</p> <pre><code># Change this according to your project\nexport GCP_PROJECT=my-project\n\n# Creates a service account called ml3PlatformServiceAccount\ngcloud iam service-accounts create ml3PlatformServiceAccount --display-name \"ML3 Platform Service Account\"\n\n# Generates the access key that will be used to authenticate as the service account\ngcloud iam service-accounts keys create ml3-platform-key.json --iam-account=ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com\n\n# Displays the access key to the terminal screen\ncat ml3-platform-key.json\n</code></pre> <p>Copy the JSON object containing the key and save it to a file with the same name on your disk. Now, you will need to create the GCP credentials, either through the SDK or the web application, and provide the contents of the JSON file you just created.</p> <p>Example</p> <p>The following code will create a set of GCP credentials that will be able to access the service account.</p> <pre><code>with open('path/to/ml3-platform-key.json', 'r') as f:\n    creds_json = f.read()\n\n    gcp_creds = client.create_gcp_integration_credentials(\n        name='GCP_01',\n        default=True,  # Set these credentials as the default to use when not specified\n        project_id='your_project_id',\n        service_account_info_json=creds_json\n    )\n</code></pre> <p>Right now, your IAM Role grants no permissions. Please refer to the next sections that will explain how to set up IAM Policies for Google Cloud Storage, Pub/Sub and so on.</p> <p></p> <p>The ML cube Platform can operate in your Azure Account through the creation of a dedicated Service Principal. You will then be able to assign one or more Roles to this Service Principal, to allow the ML cube Platform to perform specific actions.</p> <p>To configure a Service Principal for ML cube Platform, log into your Azure account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Set the Cloud Shell to use bash instead of powershell. Now we will enter the following command that will create the Service Principal.</p> <pre><code>az ad sp create-for-rbac --name ML3PlatformSP --skip-assignment\n</code></pre> <p>Once the operation finishes running, it will output a JSON object with the following fields: <code>appId</code>, <code>displayName</code>, <code>password</code> and <code>tenant</code>. Copy this object and save it to a file on your disk, for example <code>azure-credentials.json</code>.</p> <p>Now, you will need to create the Azure credentials, either through the SDK or the web application, and provide the contents of the JSON file you just created.</p> <p>Example</p> <p>The following code will create a set of Azure credentials that will be able to access the service account.</p> <pre><code>with open('path/to/azure-credentials.json', 'r') as f:\n    creds_json = f.read()\n\n    azure_creds = client.create_azure_integration_credentials(\n        name='AZURE_01',\n        default=True,  # Set these credentials as the default to use when not specified\n        project_id='your_project_id',\n        service_principal_credentials_json=creds_json\n    )\n</code></pre>"},{"location":"user_guide/integrations/#storage-integration","title":"Storage integration","text":"AWS S3Google Cloud StorageAzure Blob Storage <p>Log into your AWS account and open the AWS console, then go to the IAM service and navigate to the Policies section. Here, we will create an IAM Policy.</p> <p>Example</p> <p>The following policy will grant read access to objects in the <code>my-company-data-bucket</code> to the IAM entity it is attached to.</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Statement1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetBucketTagging\",\n                \"s3:GetObject\",\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::my-company-data-bucket\",\n                \"arn:aws:s3:::my-company-data-bucket/*\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Once the IAM Policy has been created, navigate to the Roles section, select the IAM Role you previously created and finally attach the IAM Policy to it.</p> <p></p> <p>Log into your GCP account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Now we will enter some commands that will create an IAM Role with the required permissions, bind it to the service account you previously created, and grant access to the bucket. A description of each command is provided to help you understand its purpose.</p> <pre><code># Change these according to your project and bucket\nexport GCP_PROJECT=my-project\nexport GCP_BUCKET=my-company-data-bucket\n\n# Creates an IAM Role called ml3PlatformStorageRole for your project, with read permissions on buckets and objects in the storage service\ngcloud iam roles create ml3PlatformStorageRole --project=$GCP_PROJECT --title=\"ML3 Platform Storage Role\" --description=\"Role that allows the ML cube Platform to access storage resources in a project\" --permissions=storage.buckets.get,storage.buckets.list,storage.objects.get,storage.objects.list --stage=ALPHA\n\n# Adds the IAM Role to the previously created service account\ngcloud projects add-iam-policy-binding $GCP_PROJECT --member=serviceAccount:ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com --role=projects/$GCP_PROJECT/roles/ml3PlatformStorageRole\n\n# Allows the service account we created to access the given bucket with the objectViewer role\ngsutil iam ch serviceAccount:ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com:roles/storage.objectViewer gs://$GCP_BUCKET\n</code></pre> <p></p> <p>Log into your Azure account and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. The following command will associate the previously created Service Principal with a role that is able to read data from a given blob container.</p> <pre><code># Change these according to your project and storage configuration\nexport SERVICE_PRINCIPAL_APP_ID=my-sp-app-id\nexport SUBSCRIPTION_ID=my-azure-subscription-id\nexport RESOURCE_GROUP=my-azure-resource-group\nexport STORAGE_ACCOUNT=my-storage-account\nexport BLOB_CONTAINER=my-blob-container\n\naz role assignment create --assignee $SERVICE_PRINCIPAL_APP_ID --role \"Storage Blob Data Reader\" --scope /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.Storage/storageAccounts/$STORAGE_ACCOUNT/blobServices/default/containers/$BLOB_CONTAINER\n</code></pre>"},{"location":"user_guide/integrations/#retrain-events-integration","title":"Retrain events integration","text":"Amazon EventBridgeGCP Pub/SubAzure Event Grid <p>Log into your AWS account and open the AWS console, then go to the IAM service and navigate to the Policies section. Here, we will create an IAM Policy.</p> <p>Example</p> <p>The following policy will allow an IAM Entity to put events in a specific event bus.</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Statement1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"events:PutEvents\"\n            ],\n            \"Resource\": [\n                \"arn:aws:events:&lt;REGION&gt;:&lt;ACCOUNT_ID&gt;:event-bus/&lt;EVENT_BUS_NAME&gt;\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Replace <code>&lt;REGION&gt;</code>, <code>&lt;ACCOUNT_ID&gt;</code> and <code>&lt;EVENT_BUS_NAME&gt;</code> with your desired values.</p> <p>Once the IAM Policy has been created, navigate to the Roles section, select the IAM Role you previously created and finally attach the IAM Policy to it.</p> <p></p> <p>Log into your GCP account, select the correct project and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. Now we will enter some commands that will create an IAM Policy with the required permissions, bind it to the service account you previously created, and grant access to the Pub/Sub topic. A description of each command is provided to help you understand its purpose.</p> <pre><code># Change these according to your project and topic\nexport GCP_PROJECT=my-project\nexport GCP_TOPIC=my-topic\n\n# Adds a new IAM Policy to the previously created service account, granting publish access to the Pub/Sub topic\ngcloud pubsub topics add-iam-policy-binding $GCP_TOPIC --member=serviceAccount:ml3PlatformServiceAccount@$GCP_PROJECT.iam.gserviceaccount.com --role=roles/pubsub.publisher\n</code></pre> <p></p> <p>Log into your Azure account and open the Cloud Shell. You can find the button to open it in the upper-right corner of the page. The following command will associate the previously created Service Principal with a role that is able to publish events to an Event Grid topic.</p> <pre><code># Change these according to your project and storage configuration\nexport SERVICE_PRINCIPAL_APP_ID=my-sp-app-id\nexport SUBSCRIPTION_ID=my-azure-subscription-id\nexport RESOURCE_GROUP=my-azure-resource-group\nexport TOPIC_ID=my-topic\n\naz role assignment create --assignee $SERVICE_PRINCIPAL_APP_ID --role \"EventGrid Data Sender\" --scope /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.EventGrid/topics/$TOPIC_ID\n</code></pre>"},{"location":"user_guide/integrations/data_sources/","title":"Data Sources","text":"<p>This page provides guidance on integrating external data sources into your ML cube Platform project. There are three types of data sources you can use to enable the ML cube Platform to access your data:</p> <ol> <li>Local data source</li> <li>Remote data source with ML cube Storage</li> <li>Remote data source with Customer Storage</li> </ol>"},{"location":"user_guide/integrations/data_sources/#local-data-source","title":"Local Data Source","text":"<p>This is the easiest way to send data to the ML cube Platform. You can simply specify the path to the local file you want to upload, and it will be uploaded to the ML cube Platform Secure Storage, where it is automatically processed.</p> <p>Example</p> <pre><code>data = TabularData(\n    source=LocalDataSource(\n        data_structure=DataStructure.TABULAR,\n        file_type=FileType.CSV,\n        file_path=file_path,\n        is_folder=False,\n        folder_type=None,\n    )\n)\n</code></pre>"},{"location":"user_guide/integrations/data_sources/#remote-data-source","title":"Remote Data Source","text":"<p>While using a local data source can be a good way to try out the features that the ML cube Platform can offer, in a production scenario you will usually want to integrate your remote data sources with your project. You can decide where you want your data to be stored.</p>"},{"location":"user_guide/integrations/data_sources/#ml-cube-storage","title":"ML cube Storage","text":"<p>This method should be used when the ML cube Platform is allowed to perform a one-time read of the raw data from your data source, and make a copy of it inside the ML cube Platform Secure Storage. This allows the ML cube Platform to store a server-side copy of the processed dataset for quicker access and analysis. Remember that you can request the deletion of your data at any time.</p>"},{"location":"user_guide/integrations/data_sources/#customer-storage","title":"Customer Storage","text":"<p>This method should be used when, due to compliance requirements, the ML cube Platform is only allowed to read data from your data sources when it needs to access it, without storing any sensitive information in its systems. The ML cube Platform will only store a set of anonymous identifiers that are used for data mapping. This gives you the ability to be in full control of when the ML cube Platform can access your data, but it comes at the expense of performance and cost, since constant data transfers can be slow and expensive.</p>"},{"location":"user_guide/integrations/data_sources/#integration-credentials","title":"Integration Credentials","text":"<p>To allow the ML cube Platform to access your external data sources, you need to configure credentials for them. Once the credentials have been configured, they will be available across your entire project, so multiple tasks in the same project will be able to access the same credentials.</p> <p>You can configure multiple credentials for the same provider, for example you could have two sets of credentials to access two different S3 buckets on two different AWS accounts.</p> <p>Below, you can find the configuration steps required to integrate the data source of your choice</p> Amazon S3Google Cloud StorageAzure Blob StorageDatabricks <p></p> <p>To integrate Amazon S3, you will need to create a set of AWS credentials, and add a policy that grants read access to objects in your bucket. Please refer to this page to know more.</p> <p>Once you have some credentials, you will be able to specify an <code>S3DataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>data = TabularData(\n    source=S3DataSource(\n        object_path='s3://my-company-data-bucket/historical/features.csv',\n        credentials_id=aws_creds.credentials_id,\n        data_structure=DataStructure.TABULAR,\n        file_type=FileType.CSV,\n        is_folder=False,\n        folder_type=None,\n    )\n)\n</code></pre> <p></p> <p>To integrate Google Cloud Storage, you will need to create a set of GCP credentials, and add a policy that grants read access to objects in your bucket. Please refer to this page to know more.</p> <p>Once you have some credentials, you will be able to specify a <code>GCSDataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>data = TabularData(\n    source=GCSDataSource(\n        object_path='gs://my-company-data-bucket/historical/features.csv',\n        credentials_id=gcp_creds.credentials_id,\n        data_structure=DataStructure.TABULAR,\n        file_type=FileType.CSV,\n        is_folder=False,\n        folder_type=None,\n    )\n)\n</code></pre> <p></p> <p>To integrate Azure Blob Storage, you will need to create a set of Azure credentials, and add a policy that grants read access to objects in your blob container. Please refer to this page to know more.</p> <p>Once you have some credentials, you will be able to specify an <code>AzureBlobDataSource</code> when adding your data to a task.</p> <p>Example</p> <p>Note that, if you don't specify the <code>credentials_id</code>, the default ones will be used.</p> <pre><code>data = TabularData(\n    source=AzureBlobDataSource(\n        object_path='https://mystorageaccount.blob.core.windows.net/my-container/historical/features.csv',\n        credentials_id=azure_creds.credentials_id\n        data_structure=DataStructure.TABULAR,\n        file_type=FileType.CSV,\n        is_folder=False,\n        folder_type=None,\n    )\n)\n</code></pre> <p></p> <p>Coming Soon...</p>"},{"location":"user_guide/integrations/retrain_triggers/","title":"Retrain triggers","text":"<p>This section offers an overview of setting up retrain triggers for your models. These triggers enable the automatic initiation of your retraining pipeline from the ML cube Platform.</p> <p>A retrain trigger can be utilized within a Detection Event Rule. When specific criteria are met, it automatically generates the retrain report and activates the trigger. Alternatively, you can manually activate the trigger for the model on the retraining tool page.</p> <p>A retrain trigger is designed as an integration with an external service and necessitates credentials with the appropriate privileges to execute the action.</p>"},{"location":"user_guide/integrations/retrain_triggers/#supported-triggers","title":"Supported Triggers","text":"<p>The following retrain triggers are supported:</p> <ul> <li><code>Amazon EventBridge</code>: puts an event in an Event Bus.</li> <li><code>GCP Pub/Sub</code>: puts an event in a Pub/Sub Topic.</li> <li><code>Azure Event Grid</code>: puts an event in an Event Grid Topic.</li> </ul> Amazon EventBridgeGoogle Cloud PlatformAzure Event Grid <p></p> <p>If your MLOps pipelines are set up in the AWS ecosystem, then you probably need the Amazon EventBridge retrain trigger.</p> <p>The trigger, when activated, will create an event in a Event Bus of your AWS account with custom metadata.</p> <p>You need to create an Event Bus rule that recognizes the ML cube Platform event pattern and attach the target action you want. Examples of targets are:</p> <ul> <li>launching a Lambda function;</li> <li>launching a SageMaker pipeline;</li> <li>sending a message to a SQS Queue with a retraining request.</li> </ul> <p></p> <p>If your MLOps pipelines are set up in the Google Cloud Platform ecosystem, then you probably need the GCP Pub/Sub retrain trigger.</p> <p>The trigger, when activated, will create an event in a Pub/Sub topic of your GCP project with custom metadata.</p> <p></p> <p>If your MLOps pipelines are set up in the Microsoft Azure ecosystem, then you probably need the Azure Event Grid retrain trigger.</p> <p>The trigger, when activated, will create an event in an Event Grid topic of your Azure resource group with custom metadata.</p>"},{"location":"user_guide/integrations/retrain_triggers/#event-bus-setup","title":"Event Bus Setup","text":"<ol> <li> <p>In the AWS console, open the Amazon EventBridge service and select the <code>Event buses</code> option in the left-side menu      </p> </li> <li> <p>In the <code>Custom event bus</code> tab, create a new event bus with the default settings</p> </li> <li> <p>Select the <code>Rules</code> section on the left-side menu and click the <code>Create Rule</code> button      </p> </li> <li> <p>Insert the rule name and the created Event Bus in the Event Bus section. Click <code>Next</code></p> <ol> <li><code>Event source</code>: select the voice AWS events or EventBridge partner events </li> <li><code>Sample event</code>: copy and paste this: <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"fcdd87c7-f56e-c722-4f85-4cb6ba85a00a\",\n    \"detail-type\": \"retrain_trigger\",\n    \"source\": \"ml3_platform\",\n    \"account\": \"123456789\",\n    \"time\": \"2023-11-02T14:16:23Z\",\n    \"region\": \"eu-west-3\",\n    \"resources\": [],\n    \"detail\": {\n        \"first_param\": \"hi\",\n        \"second_param\": \"bye\"\n    }\n}\n</code></pre> </li> <li><code>Creation method</code>: select Custom pattern (JSON editor)  </li> <li><code>Event pattern</code>: copy and paste this:  <pre><code>{\n    \"source\": [{\n        \"prefix\": \"ml3_platform\"\n    }],\n    \"detail-type\": [{\n        \"prefix\": \"retrain_trigger\"\n    }]\n}\n</code></pre></li> <li>click the button Test pattern to check the match and then click next</li> </ol> </li> <li> <p>Select the target that will handle the events. If you want to test the rule, you can add a CloudWatch target that stores the event to a new Log Group.      </p> </li> <li> <p>Create the rule</p> </li> </ol> <p>Retrain Trigger Setup</p> <p>To integrate Amazon Event Bridge, you will need to create a set of AWS credentials, and add a policy that allows to put events in your event bus. Please refer to this page to know more.</p> <p>Once the credentials and the policy have been created, you can set up the retrain trigger for your model through the SDK or the web application.</p> <p>Example</p> <pre><code>client.set_retrain_trigger(\n    model_id='your_model_id',\n    trigger=AWSEventBridgeRetrainTrigger(\n        credentials_id='your_credentials_id',\n        aws_region_name='e.g. eu-west-3',\n        event_bus_name='your_event_bus',\n    ),\n)\n</code></pre>"},{"location":"user_guide/integrations/retrain_triggers/#topic-setup","title":"Topic Setup","text":"<ol> <li> <p>In the Google Cloud console, open the Pub/Sub service and select the <code>Topics</code> option in the left-side menu      </p> </li> <li> <p>Click on the <code>Create topic</code> button. Then give it a unique id and create it.      </p> </li> <li> <p>Configure your subscriptions as needed to configure the service that will handle the events.</p> </li> </ol> <p>The ML cube platform will send events with this format: <pre><code>{\n    \"project_id\": \"your gcp project id\",\n    \"topic_name\": \"your unique topic id\",\n    \"source\": \"ml3_platform\",\n    \"event_type\": \"retrain_trigger\",\n    \"payload\": {\n        \"model_id\": \"id of the model on ml cube platform\"\n    }\n}\n</code></pre></p> <p>Retrain Trigger Setup</p> <p>To integrate GCP Pub/Sub, you will need to create a set of GCP credentials, and add a policy that allows to put events in your Pub/Sub topic. Please refer to this page to know more.</p> <p>Once the credentials and the policy have been created, you can set up the retrain trigger for your model through the SDK or the web application.</p> <p>Example</p> <pre><code>client.set_retrain_trigger(\n    model_id='your_model_id',\n    trigger=GCPPubSubRetrainTrigger(\n        credentials_id='your_credentials_id',\n        topic_name='your-topic'\n    ),\n)\n</code></pre>"},{"location":"user_guide/integrations/retrain_triggers/#topic-setup_1","title":"Topic Setup","text":"<ol> <li> <p>In the Azure console, open the Event Grid service and select the <code>Topics</code> option in the left-side menu      </p> </li> <li> <p>Click on the <code>Create</code> button. Select an active subscription and the resource group, then give the topic a unique name, select your preferred region and create it.      </p> </li> <li> <p>Configure your subscriptions as needed to configure the service that will handle the events.</p> </li> </ol> <p>The ML cube platform will send events with this format: <pre><code>{\n    \"subject\": \"ml3_platform\",\n    \"event_type\": \"retrain_trigger\",\n    \"data_version\": \"1.0\",\n    \"data\": {\n        \"model_id\": \"id of the model on ml cube platform\"\n    }\n}\n</code></pre></p> <p>Retrain Trigger Setup</p> <p>To integrate Azure Event Grid, you will need to create a set of Azure credentials, and add a role that allows to publish events in your Event Grid topic. Please refer to this page to know more.</p> <p>Once the credentials and the policy have been created, you can set up the retrain trigger for your model through the SDK or the web application.</p> <p>Example</p> <pre><code>client.set_retrain_trigger(\n    model_id='your_model_id',\n    trigger=AzureEventGridRetrainTrigger(\n        credentials_id='your_credentials_id',\n        topic_endpoint='https://your-retrain-topic.italynorth-1.eventgrid.azure.net/api/events'\n    ),\n)\n</code></pre>"},{"location":"user_guide/modules/","title":"Modules","text":"<p>ML cube Platform covers all the aspects of the post-deployment life cycle of your AI models. The expected usage flow with ML cube Platform is depicted in the Figure below: the model is updated by specifying its reference dataset, then production data are logged and analyzed, if a drift is detected an alarm is raised, then a retraining dataset is computed to retrain the model that will be updated on the application.</p> <p> </p> Post-deployment AI model life cycle. <p>Delta Energy inc</p> <p>In Delta Energy data are collected every minute and are sent simultaneously to ML cube Platform. Ground truth data like the presence of a fault and the fault category are uploaded after they are available and therefore, they will sent with a delay compared the others. Drift alerting system is integrated with their Microsoft Teams and ML cube Platform sends alerts to the specified channels. After they receive an alerting message, they run a retraining pipeline that communicated with ML cube Platform to retrieve the retraining dataset to use. After that, they are ready to update the new version on ML cube Platform to start the monitoring.</p> <p>Each step of this journey is covered by a module:</p> <ul> <li> <p> Monitoring</p> <p>Monitor data and model, detect drifts and receive alerts.</p> <p> More info</p> </li> <li> <p> Retraining</p> <p>Adapt your models to the current concept with new retraining dataset.</p> <p> More info</p> </li> <li> <p> Labeling</p> <p>Find which data to label to improve the overall performance.</p> <p> More info</p> </li> <li> <p> Business</p> <p>Monitor business KPI to validate the impact of your models.</p> <p> More info</p> </li> </ul>"},{"location":"user_guide/modules/business/","title":"Business mode","text":"<p>AI projects have some KPIs to improve and that are used to measure their effectiveness. Business module of ML cube Platform aims at provide a different view over AI projects that is more related to the impact the algorithms have on the company.</p> <p>Differently from the monitoring and retraining modules, this module is at Project level.</p>"},{"location":"user_guide/modules/business/#kpi-monitoring","title":"KPI Monitoring","text":"<p>You can log the project KPIs on ML cube Platform to monitor them like the model performance. Our detection algorithms will analyze each KPI showing its trend and raising alarms whenever a drift is detected.</p>"},{"location":"user_guide/modules/labeling/","title":"Labeling","text":"<p>We are sorry, this page is under construction...</p>"},{"location":"user_guide/modules/monitoring/","title":"Monitoring","text":"<p>Data and model monitoring is fundamental to guarantee performance of your ML models. With ML cube Platform you can log and monitor different aspects of your ML Task by uploading data batches.</p>"},{"location":"user_guide/modules/monitoring/#data-taxonomy","title":"Data Taxonomy","text":"<p>A Batch of data is composed of four types of data:</p> <ul> <li>input: set of input features the AI model uses to predict the output.  ML cube Platform uses the input data that comes at the end of the processing data pipeline and not the raw data. This is due to the fact that ML cube Platform detects drifts in what the AI model uses and not in the general data the customer has.</li> <li>target: target quantity predicted by the AI models. It is present in the training data but can be not available for production data.</li> <li>models' predictions: predicted target for each AI model in the AI Task.</li> <li>metadata: additional information that AI models do not use as input but that is important to define the data or the samples. Mandatory for this category are the <code>sample-id</code>, a unique identifier for each sample used to avoid confusion and misinterpretation; and the <code>sample-timestamp</code>, a timestamp associated with each sample used for ordering. Moreover, the User can provide additional data used to segment the data space.  For instance, sensitive information like zip code or country are not used by AI models to prevent bias, however, ML cube Platform can use them to  check and prevent bias in the suggested retraining dataset or to perform segmented drift detection.</li> </ul>"},{"location":"user_guide/modules/monitoring/#data-categories","title":"Data Categories","text":"<p>ML cube Platform are present three categories of data:</p> <ul> <li>Reference: represents the dataset used to train the model. Each model version has a reference dataset. Detection algorithms use reference data during their initialization.</li> <li>Production: represents data that comes from the production environment in which the AI model is operating. Detection algorithms analyze production data to detect the presence of drifts.</li> <li>Historical: represents additional data that ML cube Platform can use to define the retraining dataset after a drift.</li> </ul> <p>Each data category is uploaded to the application with its specific API call, however, they share the same structure. When a data batch is uploaded the data source for each each data type (input, target, prediction) is specified.</p> <p>The peculiarity of Production upload is that data types can be sent asynchronously with different API calls. That's why during production data arrive at different times, usually input and prediction are available together and target after a while.</p> <p> </p> ML cube Platform data categories. <p>Delta Energy inc</p> <p>Delta Energy company trained its models using the data in the year 2022 and used the algorithms starting from the 2023. This means that the data in the 2022 are the reference data and every data from the january first 2023 are considered as production data. Data previous 2022 are historical data instead.</p>"},{"location":"user_guide/modules/monitoring/#drift-detection","title":"Drift Detection","text":"<p>ML cube Platform provides a set of Detectors for each AI Task. These detectors are used to monitor the task at different levels. The choice over the types of detectors to be instantiated depends on the type of task (classification or regression) and on the type of data available for that task (input, output, model predictions).   </p> <p>There are mainly two classes of detectors:  </p> <ul> <li>Data Detectors: they take into account data associated with the task. They may be input only  data or input and ground truth data. These detectors are independent from the models trained on the  task as they do not either consider their predictions or performances. These detectors are responsible for the identification of  input and concept drifts. According to the type of the used detector, changes in data are either monitored at feature  level or using a multivariate monitoring strategy.</li> <li>Model Detectors: they monitor the performances associated with the models related to the task. In cases where the user has multiple models trained for a single task, a single detector is created for each model.</li> </ul> <p>Each detector is initially created using Reference data provided by the user. Every time a new batch of data  is uploaded, the detectors observe the batch and update their statistics. Each detector updates its statistics independently from the others and each of them presents a double-level alarm scheme in  order to either signal a Warning or a Drift for the monitored task.</p> <p>The detectors may be in three different states: </p> <ul> <li>Regular: the detector is monitoring data that are similar to the reference data, </li> <li>Warning: the detector has fired a Warning alarm since the data has started to change. From this zone, it is possible  to either go into the Drift status or to go back to the Regular one, depending on the monitored data.</li> <li>Drift: the detector has fired a Drift alarm and a change has been established between the reference data and the last  ones. After a drift, the detector is usually reset by defining a new set of reference data. The reset process is different  according to what has been monitored by the detector.  </li> </ul> <p>All the alarms generated during this process are shown in the application like Detection Events available in the Task homepage or in the Detection page. You can create automation rules based on those events to be notified on specific channels or start retraining, see Detection automation rules for more details.</p>"},{"location":"user_guide/modules/retraining/","title":"Retraining","text":"<p>A Data drift determines a drop in the model's performance that starts providing bad estimation or predictions. In Artificial Intelligence, Data plays a crucial role and usually, choosing the best data has higher impact in the resulting Model quality with respect to increasing the model complexity.</p> <p>ML cube Platform with its Retraining Tool Module provides you the best retraining dataset to use when updating the Model after a drift reducing the reaction time after the detection. Even if, the data has changed you can extract useful information from the past. ML cube Platform leverages all the available data belonging to the three categories: historical, reference and production, computing an Importance Score to every data sample you have. These Importance Scores will be used during the training phase of your model as weights in the loss function.</p> <p>A Retraining Report is generated whenever you request it or as a consequence of a Detection automation rules. It contains several information and aspects that let you to decide if it is the right time to retrain your model. It's sections are:</p> <ul> <li>Performance view</li> <li>Cost view</li> <li>Dataset info</li> <li>Data importance</li> </ul> <p>Retraining report is computed for each model you have in the Task. You can generate a retraining report whenever there are new data, moreover, if you added a Retrain trigger to the model you can automatically execute the trigger.</p>"},{"location":"user_guide/modules/retraining/#performance-view","title":"Performance view","text":"<p>Before retraining your model you should know how it is performing. Performance view provides performance interval for three key moments:</p> <ul> <li>Last Concept: the performance the model has before the drift</li> <li>Current: the performance the model has after the drift</li> <li>Forecast: the estimated performance of the model if it was retrained with dataset contained in the retraining report</li> </ul> <p>The performance are shown as an interval, this interval is measured from production data for Last concept and Current while is estimated for Forecast. In particular, the Forecast upper bound is a theoretical optimistic bound that expressed the best scenario given the actual data distribution; the lower bound instead, is an empirical estimation done with a simple ML model.</p>"},{"location":"user_guide/modules/retraining/#cost-view","title":"Cost view","text":"<p>If the Task has cost information it is possible to show this view. It is similar to the performance view but the quantity shown is economic costs of the model with that level of performance.</p>"},{"location":"user_guide/modules/retraining/#dataset-info","title":"Dataset info","text":"<p>Information about the last training dataset and the proposed one:</p> <ul> <li>From detected drift: the number of available samples received from the last drift provides information about the amount of data available from the latest concept.</li> <li>Effective sample size: quantifies the amount of information conveyed by our suggestion. It represents the hypothetical number of independent observations in a sample that would provide the same information as the computed suggestion. As the magnitude of the drift increases, this value decreases because less information from the past can be reused.</li> <li>Last reference: the number of samples used in the last reference data.</li> <li>Whole data: the percentage of data considered in providing the suggestion relative to the total available data.</li> </ul>"},{"location":"user_guide/modules/retraining/#data-importance","title":"Data importance","text":"<p>Retraining dataset we propose is computed by computing importance weights for each sample uploaded in ML cube Platform. This section shows an heatmap to provide a view of the weights distribution. When you download the retraining report we provide you a list of pairs <code>customer id</code> - <code>importance weight</code>. In case of the suggestion type for the model is <code>resampled dataset</code> then instead of the importance weights we provide you the number of time you should consider that specific sample.</p>"}]}