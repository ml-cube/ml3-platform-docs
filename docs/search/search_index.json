{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ML cube Platform","text":"<p>Welcome to the official ML cube Platform documentation site. Here you can find everything you need to start using the product.</p> <p>In the Documentation you will find:</p> <p>Getting Started User Guide API</p>"},{"location":"api/","title":"Client SDK","text":"<p>ML cube Platform allows interaction through REST APIs:</p> <ul> <li> Python \u2013 Install Python Client on your environment</li> <li> REST \u2013 Use directly the API</li> </ul>"},{"location":"api/examples/","title":"Examples","text":"<p>You can check this nodebook:</p> <ul> <li>First example</li> </ul>"},{"location":"api/python/","title":"Python SDK","text":""},{"location":"api/python/#ml3platformclient","title":"ML3PlatformClient","text":"<pre><code>ML3PlatformClient(\nurl: str = '', api_key: str = ''\n)\n</code></pre> <p>Client for interacting with ML3Platform APIs</p> <p>Methods:</p>"},{"location":"api/python/#create_company","title":".create_company","text":"<pre><code>.create_company(\nname: str, address: str, vat: str\n)\n</code></pre> <p>Create a company</p> <p>Args</p> <ul> <li>name  : the name of the company</li> <li>address  : the address of the company</li> <li>vat  : the vat of the company</li> </ul> <p>Returns</p> <p>the company id associated with the new company (string)</p>"},{"location":"api/python/#get_company","title":".get_company","text":"<pre><code>.get_company()\n</code></pre> <p>Get company</p> <p>Returns</p> <p>the company</p>"},{"location":"api/python/#update_company","title":".update_company","text":"<pre><code>.update_company(\nname: Optional[str], address: Optional[str], vat: Optional[str]\n)\n</code></pre> <p>Update company</p> <p>Args</p> <p>Returns</p> <p>None</p>"},{"location":"api/python/#create_project","title":".create_project","text":"<pre><code>.create_project(\nname: str, description: Optional[str]\n)\n</code></pre> <p>Create a project</p> <p>Args</p> <ul> <li>name  : the name of the project</li> <li>description  : optional description of the project</li> </ul> <p>Returns</p> <p>the project id associated with the created project (string)</p>"},{"location":"api/python/#get_projects","title":".get_projects","text":"<pre><code>.get_projects()\n</code></pre> <p>Get the list of all projects</p>"},{"location":"api/python/#get_project","title":".get_project","text":"<pre><code>.get_project(\nproject_id: str\n)\n</code></pre> <p>Get the list of all projects</p>"},{"location":"api/python/#update_project","title":".update_project","text":"<pre><code>.update_project(\nproject_id: str, name: Optional[str], description: Optional[str]\n)\n</code></pre> <p>Update project details</p>"},{"location":"api/python/#show_projects","title":".show_projects","text":"<pre><code>.show_projects()\n</code></pre> <p>Show a list all projects</p> <p>Example output: <pre><code>Project ID                Name\n------------------------  ----------\n6475f8c9ebac5081e529s63f  my project\n</code></pre></p>"},{"location":"api/python/#create_task","title":".create_task","text":"<pre><code>.create_task(\nproject_id: str, name: str, tags: List[str], task_type: TaskType\n)\n</code></pre> <p>Create a task</p> <p>Args</p> <ul> <li>project_id  : the identifier of the project that includes the task</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task</li> <li>task_type  : the type of the task</li> </ul> <p>Returns</p> <p>the task id associated with the created task (string)</p>"},{"location":"api/python/#get_tasks","title":".get_tasks","text":"<pre><code>.get_tasks(\nproject_id: str\n)\n</code></pre> <p>Get all project tasks</p>"},{"location":"api/python/#get_task","title":".get_task","text":"<pre><code>.get_task(\ntask_id: str\n)\n</code></pre> <p>Get task by id</p>"},{"location":"api/python/#show_tasks","title":".show_tasks","text":"<pre><code>.show_tasks(\nproject_id: str\n)\n</code></pre> <p>Show a list of tasks included in a project</p> <p>Args</p> <ul> <li>project_id  : the identifier of a project</li> </ul> <p>Example output: <pre><code>Task ID                   Name     Type            Status     Status start date\n------------------------  -------  --------------  --------   -----------------\n6476040d583201813ab4539a  my task  classification  OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/#create_model","title":".create_model","text":"<pre><code>.create_model(\ntask_id: str, name: str, version: str\n)\n</code></pre> <p>Create a model.</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the model</li> <li>version  : the current version of the model</li> </ul> <p>Returns</p> <p>the model id associated with the created model (string)</p>"},{"location":"api/python/#get_models","title":".get_models","text":"<pre><code>.get_models(\ntask_id: str\n)\n</code></pre> <p>Get all models of a task</p>"},{"location":"api/python/#get_model","title":".get_model","text":"<pre><code>.get_model(\nmodel_id: str\n)\n</code></pre> <p>Get model by id</p>"},{"location":"api/python/#show_models","title":".show_models","text":"<pre><code>.show_models(\ntask_id: str\n)\n</code></pre> <p>Show a list of models included in a task.</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> </ul> <p>Example output: <pre><code>Model ID                  Name        Version    Status     Status start date\n------------------------  ----------  ---------  --------   -----------------\n64760430583201813ab4ad1e  model_name  v1.0       OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/#update_model_version","title":".update_model_version","text":"<pre><code>.update_model_version(\nmodel_id: str, new_model_version: str, suggestion_id: Optional[str] = None,\nraw_data_storing_process_id: Optional[str] = None\n)\n</code></pre> <p>Update model version</p>"},{"location":"api/python/#add_data_schema","title":".add_data_schema","text":"<pre><code>.add_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Associate a data schema to a task</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the data schema that characterize your task</li> </ul>"},{"location":"api/python/#get_data_schema","title":".get_data_schema","text":"<pre><code>.get_data_schema(\ntask_id: str\n)\n</code></pre> <p>Get task data schema</p>"},{"location":"api/python/#show_data_schema","title":".show_data_schema","text":"<pre><code>.show_data_schema(\ntask_id: str\n)\n</code></pre> <p>Show data schema of associated with a task</p> <p>Example output: <pre><code>Column name       Role     Type      Nullable\n----------------  -------  --------  ----------\nsample_id         id       string    False\ntimestamp         time_id  string    False\nsepallength       input    float     False\nsepalwidth        input    float     False\npetallength       input    float     False\npetalwidth        input    float     False\nclass             target   category  False\n</code></pre></p>"},{"location":"api/python/#update_data_schema","title":".update_data_schema","text":"<pre><code>.update_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Update an existing data schema</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the set of new columns that should be added to the data schema</li> </ul>"},{"location":"api/python/#add_historical_data","title":".add_historical_data","text":"<pre><code>.add_historical_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of historical data</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the historical data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#add_model_reference","title":".add_model_reference","text":"<pre><code>.add_model_reference(\nmodel_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of reference data associated with a given model</p> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the reference data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#add_production_data","title":".add_production_data","text":"<pre><code>.add_production_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of production data associated with a given task</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the production data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#compute_importance_weights","title":".compute_importance_weights","text":"<pre><code>.compute_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul> <p>It returns the job_id associated to the job that computes the weights</p>"},{"location":"api/python/#get_importance_weights","title":".get_importance_weights","text":"<pre><code>.get_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul>"},{"location":"api/python/#get_jobs","title":".get_jobs","text":"<pre><code>.get_jobs(\nproject_id: Optional[str] = None, task_id: Optional[str] = None,\nmodel_id: Optional[str] = None, status: Optional[JobStatus] = None,\njob_id: Optional[str] = None\n)\n</code></pre> <p>Get current jobs information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/#get_job","title":".get_job","text":"<pre><code>.get_job(\njob_id: str\n)\n</code></pre> <p>Get current job information.</p> <p>Args</p> <ul> <li>job_id  : id of the job to retrieve</li> </ul>"},{"location":"api/python/#show_jobs","title":".show_jobs","text":"<pre><code>.show_jobs()\n</code></pre> <p>Show current job information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/#wait_job_completion","title":".wait_job_completion","text":"<pre><code>.wait_job_completion(\njob_id: str, max_wait_timeout: int = 600\n)\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"user_guide/","title":"User Guide","text":"<p>ML cube Platform is an MLOps tool focused on the serving stage of MLOps pipeline. In particular, it is an AI Supervision tool that implements AI Monitoring and Observability  to avoid AI's models obsolescence and performance degradation.</p> <p> </p> Covered Areas in the MLOps Stack."},{"location":"user_guide/basic_concepts/","title":"Basic Concepts","text":"<p>In ML cube Platform, each User works in a Company that has a subscription plan and handles billing and payment method.</p> <p>Inside a Company, a User can create Projects that contains AI Tasks.  An AI Task is anything that involves an AI model that is used in production to provide outputs. Examples are predicting sales forecast with a regression model, estimating fraud detection with classification model or customer segmentation with clustering algorithms.</p> <p>ML cube suggests to put in a Project AI Tasks that either belong to the same domain, or shares data, or that are interrelated with each other. That's why in a Project the User can see statistics or can do operations that involve its AI Tasks. </p> <p> </p> Structure of entities inside ML cube Platform."},{"location":"user_guide/basic_concepts/#drift-detection","title":"Drift Detection","text":"<p>Drift detection is done at AI Task level. A Task has a dataset composed of four categories of data:</p> <ul> <li>metadata: additional information that AI models do not use but are important to define the data or the samples. Mandatory for this category are the <code>sample-id</code>, a unique identifier for each sample used to avoid confusion and misinterpretation; and the <code>sample-timestamp</code>, a timestamp associated with each sample used for ordering. Moreover, the User can provide additional data used to segment the data space.  For instance, sensitive information like zip code or country are not used by AI models to prevent bias, however, ML cube Platform can use them to  check and prevent bias in the suggested retraining dataset or to perform segmented drift detection.</li> <li>input: set of input features the AI model uses to predict the output.  ML cube Platform uses the input data that come at the end of the processing data pipeline and not the raw data. This is due to the fact that ML cube Platform detects drifts in what the AI model uses and not in the general data the customer has.</li> <li>output: target quantity predicted by the AI models. It is present in the training data but can be not available for production data.</li> <li>models' predictions: predicted target for each AI model in the AI Task.</li> </ul> <p>For each AI Task, ML cube Platform provides a set of Detectors that analyze different quantities of the Task. Data Detectors are independent of the AI models inside the Task, and they check for input and concept drifts. There is one Model Detector for each model in the task, a model detector analyses the model error to detect negative trends in its performance.</p> <p> </p> ML cube Platform in the ML inference pipeline."},{"location":"user_guide/glossary/","title":"Glossary","text":""},{"location":"user_guide/glossary/#general-terms","title":"General Terms","text":"<ul> <li>User: registered user with username and password that interact with ML cube Platform.  A User can create API keys that inherits his/her permissions and that the he/she uses to communicate with ML cube Platform though API. </li> <li>Company: collection of Users that work with ML cube Platform.  Subscription plan and contracts with ML cube are managed at Company level. A Company has one owner that has all the privileges and that can assign admin role to other Users in the Company.</li> <li>Project: collection of AI Tasks that belong to the same business domain.</li> <li>Task: it is the standard AI problem with a dataset, a target and a set of AI models that predicts the target. All AI models inside the AI Task predicts the same target quantity and they are considered as champion and challengers or deployed and shadow models. Data drift detection is done at Task level because the models uses the same dataset.</li> <li>Model: AI model inside a Task that makes predictions over the Task's dataset.</li> </ul>"},{"location":"user_guide/glossary/#data-terms","title":"Data Terms","text":"<ul> <li>Historical data: data not used for the newest retraining but that belong to the Task. ML cube Platform uses these data during the retraining dataset selection to exploit all the available information. They are not mandatory, if they are not present then the Retraining Tool selects data from the reference set and the production data.</li> <li>Reference data: dataset used as reference for the current model version. It can be the training dataset, the test set or both. Reference data represents the current view of the model over the Task</li> <li>Production data: data the model encounter during production, the production data are monitored by the ML cube Platform detectors to detect drifts</li> <li>Data schema: represents the schema of the data that ML cube Platform uses to know the features and the target columns.</li> </ul>"},{"location":"user_guide/glossary/#drifts-terms","title":"Drifts Terms","text":"<ul> <li>Input drift: statistically significant change in the input data P(X)</li> <li>Concept drift: statistically significant change in the input and target data P(X, y)</li> <li>Model drift: statistically significant change in the model error P(y \u2013 y_pred).</li> </ul>"},{"location":"user_guide/glossary/#actions-terms","title":"Actions Terms","text":"<ul> <li>Importance weights: the retraining dataset is given in form of a set of importance weights associated to every data available for the Task. This importance score will be used during the training pipeline of the customer to weights samples. In particular, the ML model will use the form of the sample weighted loss instead of the standard loss during its retraining phase</li> <li>Dataset boostrapping: if the ML model does not support the sample weighted loss then ML cube Platform can provide a dataset extracted from the available data using sampling with replacement based on the importance weights of the data. The customer can specify the size of the retraining dataset and ML cube Platform provides the best retraining bootstapped dataset of that size</li> <li>Relabeling: in case of concept drift in a classification Task, old labels are no meaningful, given a budget/size constraint ML cube Platform provides the subset of data to be relabelled</li> <li>Active Learning: ML cube Platform provides a set of new synthetic data to label or it provides indication where to collect new real data from the environment</li> </ul>"}]}