{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ML cube Platform","text":"<p>Welcome to the official ML cube Platform documentation site. Here you can find everything you need to start using the product.</p> <p>In the Documentation you will find:</p> <p>Getting Started User Guide API</p>"},{"location":"api/","title":"Client SDK","text":"<p>ML cube Platform allows interaction through REST APIs:</p> <ul> <li> Python \u2013 Install Python Client on your environment</li> <li> REST \u2013 Use directly the API</li> </ul>"},{"location":"api/examples/","title":"Examples","text":"<p>You can check this nodebook:</p> <ul> <li>First example</li> </ul>"},{"location":"api/python/","title":"Python SDK","text":""},{"location":"api/python/#ml3platformclient","title":"ML3PlatformClient","text":"<pre><code>ML3PlatformClient(\nurl: str = '', api_key: str = ''\n)\n</code></pre> <p>Client for interacting with ML3Platform APIs</p> <p>Methods:</p>"},{"location":"api/python/#create_company","title":".create_company","text":"<pre><code>.create_company(\nname: str, address: str, vat: str\n)\n</code></pre> <p>Create a company</p> <p>Args</p> <ul> <li>name  : the name of the company</li> <li>address  : the address of the company</li> <li>vat  : the vat of the company</li> </ul> <p>Returns</p> <p>the company id associated with the new company (string)</p>"},{"location":"api/python/#get_company","title":".get_company","text":"<pre><code>.get_company()\n</code></pre> <p>Get company</p> <p>Returns</p> <p>the company</p>"},{"location":"api/python/#update_company","title":".update_company","text":"<pre><code>.update_company(\nname: Optional[str], address: Optional[str], vat: Optional[str]\n)\n</code></pre> <p>Update company</p> <p>Args</p> <p>Returns</p> <p>None</p>"},{"location":"api/python/#create_project","title":".create_project","text":"<pre><code>.create_project(\nname: str, description: Optional[str]\n)\n</code></pre> <p>Create a project</p> <p>Args</p> <ul> <li>name  : the name of the project</li> <li>description  : optional description of the project</li> </ul> <p>Returns</p> <p>the project id associated with the created project (string)</p>"},{"location":"api/python/#get_projects","title":".get_projects","text":"<pre><code>.get_projects()\n</code></pre> <p>Get the list of all projects</p>"},{"location":"api/python/#get_project","title":".get_project","text":"<pre><code>.get_project(\nproject_id: str\n)\n</code></pre> <p>Get the list of all projects</p>"},{"location":"api/python/#update_project","title":".update_project","text":"<pre><code>.update_project(\nproject_id: str, name: Optional[str], description: Optional[str]\n)\n</code></pre> <p>Update project details</p>"},{"location":"api/python/#show_projects","title":".show_projects","text":"<pre><code>.show_projects()\n</code></pre> <p>Show a list all projects</p> <p>Example output: <pre><code>Project ID                Name\n------------------------  ----------\n6475f8c9ebac5081e529s63f  my project\n</code></pre></p>"},{"location":"api/python/#create_task","title":".create_task","text":"<pre><code>.create_task(\nproject_id: str, name: str, tags: List[str], task_type: TaskType\n)\n</code></pre> <p>Create a task</p> <p>Args</p> <ul> <li>project_id  : the identifier of the project that includes the task</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task</li> <li>task_type  : the type of the task</li> </ul> <p>Returns</p> <p>the task id associated with the created task (string)</p>"},{"location":"api/python/#get_tasks","title":".get_tasks","text":"<pre><code>.get_tasks(\nproject_id: str\n)\n</code></pre> <p>Get all project tasks</p>"},{"location":"api/python/#get_task","title":".get_task","text":"<pre><code>.get_task(\ntask_id: str\n)\n</code></pre> <p>Get task by id</p>"},{"location":"api/python/#show_tasks","title":".show_tasks","text":"<pre><code>.show_tasks(\nproject_id: str\n)\n</code></pre> <p>Show a list of tasks included in a project</p> <p>Args</p> <ul> <li>project_id  : the identifier of a project</li> </ul> <p>Example output: <pre><code>Task ID                   Name     Type            Status     Status start date\n------------------------  -------  --------------  --------   -----------------\n6476040d583201813ab4539a  my task  classification  OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/#create_model","title":".create_model","text":"<pre><code>.create_model(\ntask_id: str, name: str, version: str\n)\n</code></pre> <p>Create a model.</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the model</li> <li>version  : the current version of the model</li> </ul> <p>Returns</p> <p>the model id associated with the created model (string)</p>"},{"location":"api/python/#get_models","title":".get_models","text":"<pre><code>.get_models(\ntask_id: str\n)\n</code></pre> <p>Get all models of a task</p>"},{"location":"api/python/#get_model","title":".get_model","text":"<pre><code>.get_model(\nmodel_id: str\n)\n</code></pre> <p>Get model by id</p>"},{"location":"api/python/#show_models","title":".show_models","text":"<pre><code>.show_models(\ntask_id: str\n)\n</code></pre> <p>Show a list of models included in a task.</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> </ul> <p>Example output: <pre><code>Model ID                  Name        Version    Status     Status start date\n------------------------  ----------  ---------  --------   -----------------\n64760430583201813ab4ad1e  model_name  v1.0       OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/#update_model_version","title":".update_model_version","text":"<pre><code>.update_model_version(\nmodel_id: str, new_model_version: str, suggestion_id: Optional[str] = None,\nraw_data_storing_process_id: Optional[str] = None\n)\n</code></pre> <p>Update model version</p>"},{"location":"api/python/#add_data_schema","title":".add_data_schema","text":"<pre><code>.add_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Associate a data schema to a task</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the data schema that characterize your task</li> </ul>"},{"location":"api/python/#get_data_schema","title":".get_data_schema","text":"<pre><code>.get_data_schema(\ntask_id: str\n)\n</code></pre> <p>Get task data schema</p>"},{"location":"api/python/#show_data_schema","title":".show_data_schema","text":"<pre><code>.show_data_schema(\ntask_id: str\n)\n</code></pre> <p>Show data schema of associated with a task</p> <p>Example output: <pre><code>Column name       Role     Type      Nullable\n----------------  -------  --------  ----------\nsample_id         id       string    False\ntimestamp         time_id  string    False\nsepallength       input    float     False\nsepalwidth        input    float     False\npetallength       input    float     False\npetalwidth        input    float     False\nclass             target   category  False\n</code></pre></p>"},{"location":"api/python/#update_data_schema","title":".update_data_schema","text":"<pre><code>.update_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Update an existing data schema</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the set of new columns that should be added to the data schema</li> </ul>"},{"location":"api/python/#add_historical_data","title":".add_historical_data","text":"<pre><code>.add_historical_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of historical data</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the historical data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#add_model_reference","title":".add_model_reference","text":"<pre><code>.add_model_reference(\nmodel_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of reference data associated with a given model</p> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the reference data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#add_production_data","title":".add_production_data","text":"<pre><code>.add_production_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of production data associated with a given task</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the production data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/#compute_importance_weights","title":".compute_importance_weights","text":"<pre><code>.compute_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul> <p>It returns the job_id associated to the job that computes the weights</p>"},{"location":"api/python/#get_importance_weights","title":".get_importance_weights","text":"<pre><code>.get_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul>"},{"location":"api/python/#get_jobs","title":".get_jobs","text":"<pre><code>.get_jobs(\nproject_id: Optional[str] = None, task_id: Optional[str] = None,\nmodel_id: Optional[str] = None, status: Optional[JobStatus] = None,\njob_id: Optional[str] = None\n)\n</code></pre> <p>Get current jobs information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/#get_job","title":".get_job","text":"<pre><code>.get_job(\njob_id: str\n)\n</code></pre> <p>Get current job information.</p> <p>Args</p> <ul> <li>job_id  : id of the job to retrieve</li> </ul>"},{"location":"api/python/#show_jobs","title":".show_jobs","text":"<pre><code>.show_jobs()\n</code></pre> <p>Show current job information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/#wait_job_completion","title":".wait_job_completion","text":"<pre><code>.wait_job_completion(\njob_id: str, max_wait_timeout: int = 600\n)\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"user_guide/","title":"User Guide","text":"<p>ML cube Platform is an MLOps tool in the Serving Stage of MLOps pipeline. It is an AI Supervision tool that implements Monitoring and Observability to avoid AI's models obsolescence and performance degradation.</p> <p>In the Figure below are depicted the covered areas by ML cube Platform:</p> <p> </p> Covered Areas in the MLOps Stack. <p>With ML cube Platform you can:</p> <ul> <li>log inference data and identify the presence of drifts;</li> <li>obtain the best retraining dataset to update your model after a drift;</li> <li>have a business perspective on your AI Tasks to link your KPIs with AI models' performance</li> <li>apply expert learning techniques during inference to mitigate the problems due to changes in the data;</li> <li>use relabeling module to obtain the most important samples to relabel.</li> </ul>"},{"location":"user_guide/#artificial-intelligence-applications-monitoring","title":"Artificial Intelligence applications monitoring","text":"<p>AI monitoring consists of applying detection algorithms to metrics that comes from an Artificial Intelligence system. The monitored metrics are split in two categories:</p> <ul> <li>Serving metrics: quantities related to the infrastructure and the software application like inference time and network rate;</li> <li>AI metrics: quantities related to the Artificial Intelligence application like model performance, missing values and data distributions.</li> </ul> <p>ML cube Platform focuses on AI metrics, its goal is to monitor data and AI models to detect drifts and AI related problems and to provide actions keep model performance high.</p>"},{"location":"user_guide/#data-and-model-monitoring","title":"Data and model monitoring","text":"<p>ML cube Platform implements data monitoring and model monitoring.  Model monitoring detects drifts and problems in the monitored AI model. Model monitoring means analyzing its performance metric (like RMSE, precision, or any custom performance metric) over time to detect deviations and negative trends before they will be problematic. Whenever a drift in the model performance is detected, an alarm is raised because the model needs to be updated with a new training data.</p> <p>Data monitoring processes the input and the ground truth. Detectors that monitor only the input check for input drift, i.e., a change in \\(P(X)\\) distribution, while detectors that monitor both input and ground truth check for concept drift i.e., change in \\(P(y | X)\\) distribution.</p> <p>Model and data monitoring are related and interdependent since the presence of a concept drift usually determines a model drift as well. They are used simultaneously to improve the overall detection quality.</p>"},{"location":"user_guide/#what-do-you-need-to-log-on-ml-cube-platform","title":"What do you need to log on ML cube Platform?","text":"<p>ML cube Platform's detection algorithms works at model level. Therefore, uploaded input data are the numeric features the model model receives as input to make inferece. Those data are the ones at the end of the data processing pipeline after the cleaning, feature extraction and normalization.</p>"},{"location":"user_guide/#creating-a-baseline-with-reference-data","title":"Creating a baseline with Reference Data","text":"<p>Reference data are part of the datasets used during the development of the AI model: they contain training, validation, and test sets, i.e., anything the AI model saw during its training phase. Reference data are used to initialize data detectors calibrating them to what the model learnt.</p> <p>Reference data are not used to initialize the model detectors since the error on training set is not fair with respect the error with external data. Therefore, model detectors initialize themselves with production data assuming that the performance the AI model has in the first timesteps after the deployment belong to the same data distribution.</p>"},{"location":"user_guide/#improving-retraining-quality-with-historical-data","title":"Improving retraining quality with Historical Data","text":"<p>Historical data are composed of any dataset the customer has that were not used to train the AI model that is used in production (they potentially can be old training datasets of old models). Historical data are not used during the drift detection phase but during the retraining dataset selection phase. They are not mandatory, but their availability increase the quality and the information of the retraining dataset ML cube Platform provides to the customer. Indeed, ML cube Platform will use all the information available to provide the best dataset for retraining.  The historical data have the same format as the input data, therefore, they are data after the data processing pipeline.</p>"},{"location":"user_guide/#what-is-a-retraining-dataset","title":"What is a retraining dataset?","text":"<p>When a drift occurs, the AI model performance decreases. The retraining dataset is the new dataset ML cube Platform provides to the customer that should be used to retrain the AI model in order to increase the AI model performance. Conceptually, the retraining dataset is composed of the production data after the data drift with all the data that are similar to them. What ML cube Platform provides is a set of importance weights, one for each data sample belonging to the three data categories: historical, reference, production. The magnitude of the importance weights indicates how much the single sample is important for the current retraining. The customer integrates the weights in the training procedure using a weighted loss function. If the AI model does not support weighted loss function, ML cube Platform can provide a list of sample ids to use as training dataset.</p>"},{"location":"user_guide/basic_concepts/","title":"Basic Concepts","text":"<p>In ML cube Platform, each User works in a Company that has a subscription plan and handles billing and payment method.</p> <p>Inside a Company, a User can create Projects that contains AI Tasks.  An AI Task is anything that involves an AI model that is used in production to provide outputs. Examples are predicting sales forecast with a regression model, estimating fraud detection with classification model or customer segmentation with clustering algorithms.</p> <p>ML cube suggests to put in a Project AI Tasks that either belong to the same domain, or shares data, or that are interrelated with each other. That's why in a Project the User can see statistics or can do operations that involve its AI Tasks. </p> <p> </p> Structure of entities inside ML cube Platform."},{"location":"user_guide/basic_concepts/#drift-detection","title":"Drift Detection","text":"<p>Drift detection is done at AI Task level. A Task has a dataset composed of four categories of data:</p> <ul> <li>metadata: additional information that AI models do not use but are important to define the data or the samples. Mandatory for this category are the <code>sample-id</code>, a unique identifier for each sample used to avoid confusion and misinterpretation; and the <code>sample-timestamp</code>, a timestamp associated with each sample used for ordering. Moreover, the User can provide additional data used to segment the data space.  For instance, sensitive information like zip code or country are not used by AI models to prevent bias, however, ML cube Platform can use them to  check and prevent bias in the suggested retraining dataset or to perform segmented drift detection.</li> <li>input: set of input features the AI model uses to predict the output.  ML cube Platform uses the input data that come at the end of the processing data pipeline and not the raw data. This is due to the fact that ML cube Platform detects drifts in what the AI model uses and not in the general data the customer has.</li> <li>output: target quantity predicted by the AI models. It is present in the training data but can be not available for production data.</li> <li>models' predictions: predicted target for each AI model in the AI Task.</li> </ul> <p>For each AI Task, ML cube Platform provides a set of Detectors that analyze different quantities of the Task. Data Detectors are independent of the AI models inside the Task, and they check for input and concept drifts. There is one Model Detector for each model in the task, a model detector analyses the model error to detect negative trends in its performance.</p> <p> </p> ML cube Platform in the ML inference pipeline."},{"location":"user_guide/glossary/","title":"Glossary","text":""},{"location":"user_guide/glossary/#general-terms","title":"General Terms","text":"<ul> <li>User: registered user with username and password that interact with ML cube Platform.  A User can create API keys that inherits his/her permissions and that the he/she uses to communicate with ML cube Platform though API. </li> <li>Company: collection of Users that work with ML cube Platform.  Subscription plan and contracts with ML cube are managed at Company level. A Company has one owner that has all the privileges and that can assign admin role to other Users in the Company.</li> <li>Project: collection of AI Tasks that belong to the same business domain.</li> <li>Task: it is the standard AI problem with a dataset, a target and a set of AI models that predicts the target. All AI models inside the AI Task predicts the same target quantity and they are considered as champion and challengers or deployed and shadow models. Data drift detection is done at Task level because the models uses the same dataset.</li> <li>Model: AI model inside a Task that makes predictions over the Task's dataset.</li> </ul>"},{"location":"user_guide/glossary/#data-terms","title":"Data Terms","text":"<ul> <li>Historical data: data not used for the newest retraining but that belong to the Task. ML cube Platform uses these data during the retraining dataset selection to exploit all the available information. They are not mandatory, if they are not present then the Retraining Tool selects data from the reference set and the production data.</li> <li>Reference data: dataset used as reference for the current model version. It can be the training dataset, the test set or both. Reference data represents the current view of the model over the Task</li> <li>Production data: data the model encounter during production, the production data are monitored by the ML cube Platform detectors to detect drifts</li> <li>Data schema: represents the schema of the data that ML cube Platform uses to know the features and the target columns.</li> </ul>"},{"location":"user_guide/glossary/#drifts-terms","title":"Drifts Terms","text":"<ul> <li>Input drift: statistically significant change in the input data P(X)</li> <li>Concept drift: statistically significant change in the input and target data P(X, y)</li> <li>Model drift: statistically significant change in the model error P(y \u2013 y_pred).</li> </ul>"},{"location":"user_guide/glossary/#actions-terms","title":"Actions Terms","text":"<ul> <li>Importance weights: the retraining dataset is given in form of a set of importance weights associated to every data available for the Task. This importance score will be used during the training pipeline of the customer to weights samples. In particular, the ML model will use the form of the sample weighted loss instead of the standard loss during its retraining phase</li> <li>Dataset boostrapping: if the ML model does not support the sample weighted loss then ML cube Platform can provide a dataset extracted from the available data using sampling with replacement based on the importance weights of the data. The customer can specify the size of the retraining dataset and ML cube Platform provides the best retraining bootstapped dataset of that size</li> <li>Relabeling: in case of concept drift in a classification Task, old labels are no meaningful, given a budget/size constraint ML cube Platform provides the subset of data to be relabelled</li> <li>Active Learning: ML cube Platform provides a set of new synthetic data to label or it provides indication where to collect new real data from the environment</li> </ul>"}]}