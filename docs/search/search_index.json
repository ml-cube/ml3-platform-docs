{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ML cube Platform","text":"<p>Welcome to the official ML cube Platform documentation site. Here you can find everything you need to start using the product.</p> <p>In the Documentation you will find:</p> <p>User Guide API</p>"},{"location":"api/","title":"Client SDK","text":"<p>ML cube Platform allows interaction through REST APIs:</p> <ul> <li> Python \u2013 Install Python Client on your environment</li> <li> REST \u2013 Use directly the API</li> </ul>"},{"location":"api/examples/","title":"Examples","text":"<p>You can check this nodebook:</p> <ul> <li>First example</li> </ul>"},{"location":"api/python/","title":"Python SDK","text":"<p>ciao ciao</p>"},{"location":"api/python/client/","title":"Client","text":""},{"location":"api/python/client/#ml3platformclient","title":"ML3PlatformClient","text":"<pre><code>ML3PlatformClient(\nurl: str, api_key: str\n)\n</code></pre> <p>Client class is the single point of interaction with ML cube Platform APIs, it is initialized providing the <code>url</code> and the User <code>api_key</code>. Every operation is performed verifying the API Key and the permissions associated to the User that own that key.</p>"},{"location":"api/python/client/#methods-categories","title":"Methods categories","text":"<p>The there are the following types of methods:</p> <ul> <li>entity creation: create the entity and return its identifier. It is used in the other methods to indicate the entity.</li> <li>entity update: modify the entity but do not return anything.</li> <li>entity getters: return a Pydantic <code>BaseModel</code> with the required entity.</li> <li>entity show: print to the stdout the entity, but they do not return anything.</li> <li>entity delete: delete the entity</li> <li>job submission: submit a job on ML cube Platform that will take some time. They return the job identifier that can be used to monitor its state.</li> <li>job waiters: given a job id wait the until the job is completed</li> </ul>"},{"location":"api/python/client/#exceptions","title":"Exceptions","text":"<p>The Client class raises only exceptions that are subclasses of <code>SDKClientException</code>. The exception has two fields that you can share with ML cube Support to get help in identifying the problem:</p> <ul> <li>error_code: unique identifier of the error</li> <li>error_message: message that explain the error</li> </ul> <p>The page is structured in different blocks of methods, one for each entity.</p> <p>Methods:</p>"},{"location":"api/python/client/#create_company","title":".create_company","text":"<pre><code>.create_company(\nname: str, address: str, vat: str\n)\n</code></pre> <p>Create a company for the User, this method works only is the User has not a company yet. After the Company is created the User is the Company Owner.</p> <p>Args</p> <ul> <li>name  : the name of the company</li> <li>address  : the address of the company</li> <li>vat  : the vat of the company</li> </ul> <p>Returns</p> <ul> <li>company_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateCompanyException</code></p>"},{"location":"api/python/client/#get_company","title":".get_company","text":"<pre><code>.get_company()\n</code></pre> <p>Returns the company of the User</p> <p>Returns</p> <ul> <li>company  : <code>Company</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_company","title":".update_company","text":"<pre><code>.update_company(\nname: Optional[str], address: Optional[str], vat: Optional[str]\n)\n</code></pre> <p>Update company information.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : new the of the company</li> <li>address  : new billing address for the company</li> <li>vat  : new vat of the company</li> </ul> <p>Raises</p> <p><code>UpdateCompanyException</code></p>"},{"location":"api/python/client/#create_project","title":".create_project","text":"<pre><code>.create_project(\nname: str, description: Optional[str]\n)\n</code></pre> <p>Create a project inside the company. You don't need to specify the company because a User belong only to one company and it is retrieved automatically.</p> <p>Allowed Roles</p> <ul> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>name  : the name of the project</li> <li>description  : optional description of the project</li> </ul> <p>Returns</p> <ul> <li>project_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateProjectException</code></p>"},{"location":"api/python/client/#get_projects","title":".get_projects","text":"<pre><code>.get_projects()\n</code></pre> <p>Get the list of all projects in the company the User has permissions to view.</p> <p>Returns</p> <ul> <li>projects_list  : <code>List[Project]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_project","title":".get_project","text":"<pre><code>.get_project(\nproject_id: str\n)\n</code></pre> <p>Get a project with the given id</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_project","title":".update_project","text":"<pre><code>.update_project(\nproject_id: str, name: Optional[str], description: Optional[str]\n)\n</code></pre> <p>Update project details.</p> <p>Empty values will not be updated.</p> <p>Allowed Roles</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : project identifier</li> <li>name  : new name of the project</li> <li>description  : new description of the project</li> </ul> <p>Returns</p> <ul> <li>project  : <code>Project</code></li> </ul> <p>Raises</p> <p><code>UpdateProjectException</code></p>"},{"location":"api/python/client/#show_projects","title":".show_projects","text":"<pre><code>.show_projects()\n</code></pre> <p>Show a list all projects printing to stdout.</p> <p>Example output: <pre><code>Project ID                Name\n------------------------  ----------\n6475f8c9ebac5081e529s63f  my project\n</code></pre></p>"},{"location":"api/python/client/#create_task","title":".create_task","text":"<pre><code>.create_task(\nproject_id: str, name: str, tags: List[str], task_type: TaskType\n)\n</code></pre> <p>Create a task inside the project.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>project_id  : the identifier of the project</li> <li>name  : the name of the task</li> <li>tags  : a list of tags associated with the task</li> <li>task_type  : the type of the task. See <code>TaskType</code> documentation for more information</li> </ul> <p>Returns</p> <ul> <li>task_id  : <code>str</code></li> </ul> <p>Raises</p> <p><code>CreateTaskException</code></p>"},{"location":"api/python/client/#get_tasks","title":".get_tasks","text":"<pre><code>.get_tasks(\nproject_id: str\n)\n</code></pre> <p>Get the list of the Tasks inside the project.</p> <p>Args</p> <ul> <li>project_id  : identifier of the project</li> </ul> <p>Returns</p> <ul> <li>task_list  : <code>List[Task]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_task","title":".get_task","text":"<pre><code>.get_task(\ntask_id: str\n)\n</code></pre> <p>Get task by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>task  : <code>Task</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_tasks","title":".show_tasks","text":"<pre><code>.show_tasks(\nproject_id: str\n)\n</code></pre> <p>Show a list of tasks included in a project to stdout.</p> <p>Args</p> <ul> <li>project_id  : the identifier of a project</li> </ul> <p>Example output: <pre><code>Task ID                   Name     Type            Status     Status start date\n------------------------  -------  --------------  --------   -----------------\n6476040d583201813ab4539a  my task  classification  OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/client/#create_model","title":".create_model","text":"<pre><code>.create_model(\ntask_id: str, name: str, version: str\n)\n</code></pre> <p>Create a model inside the task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>name  : the name of the model</li> <li>version  : the current version of the model</li> </ul> <p>Returns</p> <ul> <li>model_id  : <code>str</code> identifier of the created model</li> </ul> <p>Raises</p> <p><code>CreateModelException</code></p>"},{"location":"api/python/client/#get_models","title":".get_models","text":"<pre><code>.get_models(\ntask_id: str\n)\n</code></pre> <p>Get all models of a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>models_list  : <code>List[Model]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model","title":".get_model","text":"<pre><code>.get_model(\nmodel_id: str\n)\n</code></pre> <p>Get model by id.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : identifier of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#get_model_by_name_and_version","title":".get_model_by_name_and_version","text":"<pre><code>.get_model_by_name_and_version(\ntask_id: str, model_name: str, model_version: str\n)\n</code></pre> <p>Get model by name and version.</p> <p>A Model can have multiple versions according to the updates and retraining done. This method allow to get the Model object by specifying its name and the version tag.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>model_name  : the name of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>model  : <code>Model</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_models","title":".show_models","text":"<pre><code>.show_models(\ntask_id: str\n)\n</code></pre> <p>Show a list of models included in a task to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> </ul> <p>Example output: <pre><code>Model ID                  Name        Version    Status     Status start date\n------------------------  ----------  ---------  --------   -----------------\n64760430583201813ab4ad1e  model_name  v1.0       OK         03-02-2023 10:14:06\n</code></pre></p>"},{"location":"api/python/client/#get_suggestions","title":".get_suggestions","text":"<pre><code>.get_suggestions(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>Retrieve suggestions associated with a model.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Returns</p> <ul> <li>suggestion_list  : <code>List[Suggestion]</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_suggestions","title":".show_suggestions","text":"<pre><code>.show_suggestions(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>Show the list of suggestions associated with a model printing them to stdout.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>model_version  : the version of the model</li> </ul> <p>Example output: <pre><code>Suggestion Id                     Executed    Timestamp\n--------------------------------  ----------  --------------------------\n79a8710c351c4b6a9ece7322e153f200  True        2023-08-21 10:54:40.386189\n</code></pre></p> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#update_model_version_by_suggestion_id","title":".update_model_version_by_suggestion_id","text":"<pre><code>.update_model_version_by_suggestion_id(\nmodel_id: str, new_model_version: str, suggestion_id: str\n)\n</code></pre> <p>Update model version by suggestion id. To retrain the Model, ML cube Platform provides importance weights through a <code>Suggestion</code>. After the retraining is completed, you use this method to create the new model version in ML cube Platform. By specifying the <code>suggestion_id</code>, ML cube Platform automatically knows which is the reference data the model is trained on.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model</li> <li>suggestion_id  : the identifier of the suggestion</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> job identifier of the pipeline in execution</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p>"},{"location":"api/python/client/#update_model_version_from_raw_data","title":".update_model_version_from_raw_data","text":"<pre><code>.update_model_version_from_raw_data(\nmodel_id: str, new_model_version: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Update model version by suggestion id. To retrain the Model, ML cube Platform provides importance weights through a <code>Suggestion</code>. However, it is possible to train the model with new data that has been not already upload to ML cube Platform. After the retraining is completed, you use this method to create the new model version in ML cube Platform by specifying the data to load.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>new_model_version  : the new version of the model</li> <li>dataset_type  :  Dataset type describes the nature                of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the data            which will be used as new reference</li> </ul> <p>Returns</p> <ul> <li>job_id  : <code>str</code> job identifier of the pipeline in execution</li> </ul> <p>Raises</p> <p><code>UpdateModelVersionException</code></p> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#add_data_schema","title":".add_data_schema","text":"<pre><code>.add_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Associate a data schema to a task.</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the data schema that characterize your task</li> </ul> <p>Raises</p> <p><code>AddDataSchemaException</code></p>"},{"location":"api/python/client/#get_data_schema","title":".get_data_schema","text":"<pre><code>.get_data_schema(\ntask_id: str\n)\n</code></pre> <p>Get task data schema</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Returns</p> <ul> <li>data_schema  : <code>DataSchema</code></li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p>"},{"location":"api/python/client/#show_data_schema","title":".show_data_schema","text":"<pre><code>.show_data_schema(\ntask_id: str\n)\n</code></pre> <p>Show data schema of associated with a task</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_VIEW</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : identifier of the task</li> </ul> <p>Raises</p> <p><code>SDKClientException</code></p> <p>Example output:</p> <pre><code>Column name       Role     Type      Nullable\n----------------  -------  --------  ----------\nsample_id         id       string    False\ntimestamp         time_id  string    False\nsepallength       input    float     False\nsepalwidth        input    float     False\npetallength       input    float     False\npetalwidth        input    float     False\nclass             target   category  False\n</code></pre>"},{"location":"api/python/client/#update_data_schema","title":".update_data_schema","text":"<pre><code>.update_data_schema(\ntask_id: str, data_schema: DataSchema\n)\n</code></pre> <p>Update an existing data schema</p> <p>Allowed Roles:</p> <ul> <li>At least <code>PROJECT_EDIT</code> for that project</li> <li><code>COMPANY_OWNER</code></li> <li><code>COMPANY_ADMIN</code></li> </ul> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>data_schema  : the set of new columns that should be added to the data schema</li> </ul> <p>Raises</p> <p><code>UpdateDataSchemaException</code></p>"},{"location":"api/python/client/#add_historical_data","title":".add_historical_data","text":"<pre><code>.add_historical_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of historical data</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the historical data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#add_model_reference","title":".add_model_reference","text":"<pre><code>.add_model_reference(\nmodel_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of reference data associated with a given model</p> <p>Args</p> <ul> <li>model_id  : the identifier of the model</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the reference data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#add_production_data","title":".add_production_data","text":"<pre><code>.add_production_data(\ntask_id: str, dataset_type: DatasetType, data_path: str\n)\n</code></pre> <p>Add a batch of production data associated with a given task</p> <p>Args</p> <ul> <li>task_id  : the identifier of the task</li> <li>dataset_type  :  Dataset type describes the nature of data stored (DatasetType)</li> <li>data_path  : path to the csv file containing the production data</li> </ul> <p>Returns the job_id associated to the pipeline</p>"},{"location":"api/python/client/#compute_importance_weights","title":".compute_importance_weights","text":"<pre><code>.compute_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul> <p>It returns the job_id associated to the job that computes the weights</p>"},{"location":"api/python/client/#get_importance_weights","title":".get_importance_weights","text":"<pre><code>.get_importance_weights(\nmodel_id: str, model_version: str\n)\n</code></pre> <p>For a given model version, get the importance weights with the possibility to specify a retrain_event_id.</p> <p>Args</p> <ul> <li>model_id  : the identifier of the task</li> <li>model_version  : the version of the model</li> </ul>"},{"location":"api/python/client/#get_jobs","title":".get_jobs","text":"<pre><code>.get_jobs(\nproject_id: Optional[str] = None, task_id: Optional[str] = None,\nmodel_id: Optional[str] = None, status: Optional[JobStatus] = None,\njob_id: Optional[str] = None\n)\n</code></pre> <p>Get current jobs information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/client/#get_job","title":".get_job","text":"<pre><code>.get_job(\njob_id: str\n)\n</code></pre> <p>Get current job information.</p> <p>Args</p> <ul> <li>job_id  : id of the job to retrieve</li> </ul>"},{"location":"api/python/client/#show_jobs","title":".show_jobs","text":"<pre><code>.show_jobs()\n</code></pre> <p>Show current job information. Jobs can be filtered by project_id, task_id, model_id or status</p> <p>Args</p> <ul> <li>project_id  : the project_id to filter job. If <code>None</code> job of every project will be returned</li> <li>task_id  : the task_id to filter job. If <code>None</code> job of every task will be returned</li> <li>model_id  : the model_id to filter job. If <code>None</code> job of every model will be returned</li> <li>status  : the status to filter job. If <code>None</code> job with every status will be retrieved</li> <li>job_id  : id of the job to filter. If <code>None</code> job with every id will be retrieved</li> </ul>"},{"location":"api/python/client/#get_detection_event_rules","title":".get_detection_event_rules","text":"<pre><code>.get_detection_event_rules(\ntask_id: str\n)\n</code></pre> <p>Get all detection event rules of a given task.</p> <p>Args</p> <ul> <li>task_id  : id of the task for which you want to retrieve the detection event rules</li> </ul>"},{"location":"api/python/client/#get_detection_event_rule","title":".get_detection_event_rule","text":"<pre><code>.get_detection_event_rule(\nrule_id: str\n)\n</code></pre> <p>Get a detection event rule by id.</p> <p>Args</p> <ul> <li>rule_id  : id of the rule</li> </ul>"},{"location":"api/python/client/#create_detection_event_rule","title":".create_detection_event_rule","text":"<pre><code>.create_detection_event_rule(\nname: str, task_id: str, model_id: str, severity: DetectionEventSeverity,\ndetection_event_type: DetectionEventType, monitoring_target: MonitoringTarget,\nactions: List[Union[DiscordNotificationAction, SlackNotificationAction]]\n)\n</code></pre> <p>Create a detection event rule.</p> <p>Args</p> <ul> <li>name  : the name of the rule</li> <li>task_id  : the id of the task to which the rule belongs.</li> <li>model_id  : the id of the model, only required if event_type</li> <li>detection_event_type  : the type of detection event that this</li> <li>monitoring_target  : the type of monitoring target that this</li> <li>severity  : the level of severity of the detection event that</li> <li>actions  : the list of actions to execute, in order, when the</li> </ul> <p>The rule will only respond to detection events generated by this task.</p> <p>is set to PERFORMANCE.</p> <p>rule should respond to.</p> <p>rule should respond to.</p> <p>this rule should respond to.</p> <p>conditions of the rule are matched.</p>"},{"location":"api/python/client/#update_detection_event_rule","title":".update_detection_event_rule","text":"<pre><code>.update_detection_event_rule(\nrule_id: str, name: Optional[str] = None, model_id: Optional[str] = None,\nseverity: Optional[DetectionEventSeverity] = None,\ndetection_event_type: Optional[DetectionEventType] = None,\nmonitoring_target: Optional[MonitoringTarget] = None,\nactions: Optional[List[Union[DiscordNotificationAction,\nSlackNotificationAction]]] = None\n)\n</code></pre> <p>Update a detection event rule.</p> <p>Args</p> <ul> <li>rule_id  : the id of the rule to update</li> <li>name  : the name of the rule.</li> <li>model_id  : the id of the model, only required if event_type</li> <li>detection_event_type  : the type of detection event that this</li> <li>monitoring_target  : the type of monitoring target that this</li> <li>severity  : the level of severity of the detection event that</li> <li>actions  : the list of actions to execute, in order, when the</li> </ul> <p>If None, keeps the existing value.</p> <p>is set to PERFORMANCE. If None, keeps the existing value.</p> <p>rule should respond to. If None, keeps the existing value.</p> <p>rule should respond to. If None, keeps the existing value.</p> <p>this rule should respond to. If None, keeps the existing value.</p> <p>conditions of the rule are matched. If None, keeps the existing value.</p>"},{"location":"api/python/client/#delete_detection_event_rule","title":".delete_detection_event_rule","text":"<pre><code>.delete_detection_event_rule(\nrule_id: str\n)\n</code></pre> <p>Delete a detection event rule by id.</p> <p>Args</p> <ul> <li>rule_id  : id of the rule to delete</li> </ul>"},{"location":"api/python/client/#wait_job_completion","title":".wait_job_completion","text":"<pre><code>.wait_job_completion(\njob_id: str, max_wait_timeout: int = 600\n)\n</code></pre>"},{"location":"api/python/client/#delete_company","title":".delete_company","text":"<pre><code>.delete_company()\n</code></pre>"},{"location":"api/python/client/#create_company_user","title":".create_company_user","text":"<pre><code>.create_company_user(\nname: str, surname: str, username: str, password: str, email: str,\ncompany_role: UserCompanyRole\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#remove_user_from_company","title":".remove_user_from_company","text":"<pre><code>.remove_user_from_company(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#add_user_to_company","title":".add_user_to_company","text":"<pre><code>.add_user_to_company(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#get_company_users","title":".get_company_users","text":"<pre><code>.get_company_users()\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#change_user_company_role","title":".change_user_company_role","text":"<pre><code>.change_user_company_role(\nuser_id: str, company_role: UserCompanyRole\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#show_company_users","title":".show_company_users","text":"<pre><code>.show_company_users()\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#get_user_projects","title":".get_user_projects","text":"<pre><code>.get_user_projects(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#show_user_projects","title":".show_user_projects","text":"<pre><code>.show_user_projects(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#add_user_project_role","title":".add_user_project_role","text":"<pre><code>.add_user_project_role(\nuser_id: str, project_id: str, project_role: UserProjectRole\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#delete_project_role","title":".delete_project_role","text":"<pre><code>.delete_project_role(\nuser_id: str, project_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#get_api_keys","title":".get_api_keys","text":"<pre><code>.get_api_keys()\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#show_api_keys","title":".show_api_keys","text":"<pre><code>.show_api_keys()\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#create_api_key","title":".create_api_key","text":"<pre><code>.create_api_key()\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#delete_api_key","title":".delete_api_key","text":"<pre><code>.delete_api_key(\napi_key: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#get_user_api_keys","title":".get_user_api_keys","text":"<pre><code>.get_user_api_keys(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#show_user_api_keys","title":".show_user_api_keys","text":"<pre><code>.show_user_api_keys(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#create_user_api_key","title":".create_user_api_key","text":"<pre><code>.create_user_api_key(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#delete_user_api_key","title":".delete_user_api_key","text":"<pre><code>.delete_user_api_key(\nuser_id: str, api_key: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#change_company_owner","title":".change_company_owner","text":"<pre><code>.change_company_owner(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/client/#delete_company_user","title":".delete_company_user","text":"<pre><code>.delete_company_user(\nuser_id: str\n)\n</code></pre> <p>TODO</p>"},{"location":"api/python/enums/","title":"Enums","text":""},{"location":"api/python/enums/#tasktype","title":"TaskType","text":"<pre><code>TaskType()\n</code></pre> <p>Task Type</p>"},{"location":"api/python/enums/#taskstatus","title":"TaskStatus","text":"<pre><code>TaskStatus()\n</code></pre> <p>Status of a task</p>"},{"location":"api/python/enums/#modelstatus","title":"ModelStatus","text":"<pre><code>ModelStatus()\n</code></pre> <p>Status of a model</p>"},{"location":"api/python/enums/#datasettype","title":"DatasetType","text":"<pre><code>DatasetType()\n</code></pre> <p>Enum class to describe the type of data that can be handled</p>"},{"location":"api/python/enums/#storingdatatype","title":"StoringDataType","text":"<pre><code>StoringDataType()\n</code></pre> <p>Data type describing which dataset the user is storing in ml3 platform</p>"},{"location":"api/python/enums/#filetype","title":"FileType","text":"<pre><code>FileType()\n</code></pre> <p>Enum class for file types</p>"},{"location":"api/python/enums/#jobstatus","title":"JobStatus","text":"<pre><code>JobStatus()\n</code></pre> <p>Job status</p>"},{"location":"api/python/enums/#usercompanyrole","title":"UserCompanyRole","text":"<pre><code>UserCompanyRole()\n</code></pre> <p>UserCompanyRole</p>"},{"location":"api/python/enums/#userprojectrole","title":"UserProjectRole","text":"<pre><code>UserProjectRole()\n</code></pre> <p>UserProjectRole</p>"},{"location":"api/python/enums/#detectioneventseverity","title":"DetectionEventSeverity","text":"<pre><code>DetectionEventSeverity()\n</code></pre> <p>Severity of a detection event</p>"},{"location":"api/python/enums/#detectioneventtype","title":"DetectionEventType","text":"<pre><code>DetectionEventType()\n</code></pre> <p>Type of event that a detection event rule will respond to</p>"},{"location":"api/python/enums/#monitoringtarget","title":"MonitoringTarget","text":"<pre><code>MonitoringTarget()\n</code></pre> <p>Type of target that a detection event rule will respond to</p>"},{"location":"api/python/enums/#detectioneventactiontype","title":"DetectionEventActionType","text":"<pre><code>DetectionEventActionType()\n</code></pre> <p>Type of detection event action</p>"},{"location":"api/python/exceptions/","title":"Exceptions","text":""},{"location":"api/python/exceptions/#sdkclientexception","title":"SDKClientException","text":"<pre><code>SDKClientException(\nerror_code: str = 'UNEXPECTED', error_message: str = 'Anunexpectederroroccurred'\n)\n</code></pre> <p>Base class for client sdk exceptions</p>"},{"location":"api/python/exceptions/#createcompanyexception","title":"CreateCompanyException","text":"<pre><code>CreateCompanyException()\n</code></pre> <p>CreateCompanyException</p>"},{"location":"api/python/exceptions/#updatecompanyexception","title":"UpdateCompanyException","text":"<pre><code>UpdateCompanyException()\n</code></pre> <p>UpdateCompanyException</p>"},{"location":"api/python/exceptions/#createprojectexception","title":"CreateProjectException","text":"<pre><code>CreateProjectException()\n</code></pre> <p>CreateProjectException</p>"},{"location":"api/python/exceptions/#updateprojectexception","title":"UpdateProjectException","text":"<pre><code>UpdateProjectException()\n</code></pre> <p>UpdateProjectException</p>"},{"location":"api/python/exceptions/#createtaskexception","title":"CreateTaskException","text":"<pre><code>CreateTaskException()\n</code></pre> <p>CreateTaskException</p>"},{"location":"api/python/exceptions/#createmodelexception","title":"CreateModelException","text":"<pre><code>CreateModelException()\n</code></pre> <p>CreateModelException</p>"},{"location":"api/python/exceptions/#adddataschemaexception","title":"AddDataSchemaException","text":"<pre><code>AddDataSchemaException()\n</code></pre> <p>AddDataSchemaException</p>"},{"location":"api/python/exceptions/#addhistoricaldataexception","title":"AddHistoricalDataException","text":"<pre><code>AddHistoricalDataException()\n</code></pre> <p>AddHistoricalDataException</p>"},{"location":"api/python/exceptions/#addmodelreferenceexception","title":"AddModelReferenceException","text":"<pre><code>AddModelReferenceException()\n</code></pre> <p>AddModelReferenceException</p>"},{"location":"api/python/exceptions/#updatemodelversionexception","title":"UpdateModelVersionException","text":"<pre><code>UpdateModelVersionException()\n</code></pre> <p>UpdateModelVersionException</p>"},{"location":"api/python/exceptions/#addproductiondataexception","title":"AddProductionDataException","text":"<pre><code>AddProductionDataException()\n</code></pre> <p>AddProductionDataException</p>"},{"location":"api/python/exceptions/#computeimportanceweightsexception","title":"ComputeImportanceWeightsException","text":"<pre><code>ComputeImportanceWeightsException()\n</code></pre> <p>ComputeImportanceWeightsException</p>"},{"location":"api/python/exceptions/#getimportanceweightsexception","title":"GetImportanceWeightsException","text":"<pre><code>GetImportanceWeightsException()\n</code></pre> <p>ComputeImportanceWeightsException</p>"},{"location":"api/python/exceptions/#updatedataschemaexception","title":"UpdateDataSchemaException","text":"<pre><code>UpdateDataSchemaException()\n</code></pre> <p>UpdateDataSchemaException</p>"},{"location":"api/python/exceptions/#jobwaittimeoutexception","title":"JobWaitTimeoutException","text":"<pre><code>JobWaitTimeoutException()\n</code></pre> <p>JobWaitTimeoutException</p>"},{"location":"api/python/exceptions/#jobnotfoundexception","title":"JobNotFoundException","text":"<pre><code>JobNotFoundException()\n</code></pre> <p>JobNotFoundException</p>"},{"location":"api/python/exceptions/#jobfailureexception","title":"JobFailureException","text":"<pre><code>JobFailureException()\n</code></pre> <p>JobFailureException</p>"},{"location":"api/python/exceptions/#createdetectioneventruleexception","title":"CreateDetectionEventRuleException","text":"<pre><code>CreateDetectionEventRuleException()\n</code></pre> <p>CreateDetectionEventRuleException</p>"},{"location":"api/python/exceptions/#updatedetectioneventruleexception","title":"UpdateDetectionEventRuleException","text":"<pre><code>UpdateDetectionEventRuleException()\n</code></pre> <p>UpdateDetectionEventRuleException</p>"},{"location":"api/python/models/","title":"Models","text":""},{"location":"api/python/models/#company","title":"Company","text":"<pre><code>Company()\n</code></pre> <p>Company model</p>"},{"location":"api/python/models/#project","title":"Project","text":"<pre><code>Project()\n</code></pre> <p>Project model</p>"},{"location":"api/python/models/#task","title":"Task","text":"<pre><code>Task()\n</code></pre> <p>Task model</p>"},{"location":"api/python/models/#model","title":"Model","text":"<pre><code>Model()\n</code></pre> <p>Base model to define model item</p>"},{"location":"api/python/models/#job","title":"Job","text":"<pre><code>Job()\n</code></pre> <p>Job information item model</p>"},{"location":"api/python/models/#columninfo","title":"ColumnInfo","text":"<pre><code>ColumnInfo()\n</code></pre> <p>Column base model</p>"},{"location":"api/python/models/#dataschema","title":"DataSchema","text":"<pre><code>DataSchema()\n</code></pre> <p>Data schema base model</p>"},{"location":"api/python/models/#suggestion","title":"Suggestion","text":"<pre><code>Suggestion()\n</code></pre> <p>Suggestion base model</p>"},{"location":"api/python/models/#importanceweightssuggestion","title":"ImportanceWeightsSuggestion","text":"<pre><code>ImportanceWeightsSuggestion()\n</code></pre> <p>base model for importance weights suggestion</p>"},{"location":"api/python/models/#companyuser","title":"CompanyUser","text":"<pre><code>CompanyUser()\n</code></pre> <p>base model for company user</p>"},{"location":"api/python/models/#apikey","title":"ApiKey","text":"<pre><code>ApiKey()\n</code></pre> <p>base model for api key</p>"},{"location":"api/python/models/#detectioneventaction","title":"DetectionEventAction","text":"<pre><code>DetectionEventAction()\n</code></pre> <p>Generic action that can be performed</p>"},{"location":"api/python/models/#discordnotificationaction","title":"DiscordNotificationAction","text":"<pre><code>DiscordNotificationAction()\n</code></pre> <p>Action that sends a notification to a Discord server through a webhook that you configure</p>"},{"location":"api/python/models/#slacknotificationaction","title":"SlackNotificationAction","text":"<pre><code>SlackNotificationAction()\n</code></pre> <p>Action that sends a notification to a Slack channel through a webhook that you configure.</p>"},{"location":"api/python/models/#detectioneventrule","title":"DetectionEventRule","text":"<pre><code>DetectionEventRule(\n**kwargs\n)\n</code></pre> <p>A rule that can be triggered by a detection event, and executes a series of actions.</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>ML cube Platform is an MLOps tool in the Serving Stage of MLOps pipeline. It is an AI Supervision tool that implements Monitoring and Observability to avoid AI's models obsolescence and performance degradation.</p> <p>In the Figure below are depicted the covered areas by ML cube Platform:</p> <p> </p> Covered Areas in the MLOps Stack. <p>With ML cube Platform you can:</p> <ul> <li>log inference data and identify the presence of drifts;</li> <li>obtain the best retraining dataset to update your model after a drift;</li> <li>have a business perspective on your AI Tasks to link your KPIs with AI models' performance</li> <li>apply expert learning techniques during inference to mitigate the problems due to changes in the data;</li> <li>use relabeling module to obtain the most important samples to relabel.</li> </ul>"},{"location":"user_guide/#artificial-intelligence-applications-monitoring","title":"Artificial Intelligence applications monitoring","text":"<p>AI monitoring consists of applying detection algorithms to metrics that comes from an Artificial Intelligence system. The monitored metrics are split in two categories:</p> <ul> <li>Serving metrics: quantities related to the infrastructure and the software application like inference time and network rate;</li> <li>AI metrics: quantities related to the Artificial Intelligence application like model performance, missing values and data distributions.</li> </ul> <p>ML cube Platform focuses on AI metrics, its goal is to monitor data and AI models to detect drifts and AI related problems and to provide actions keep model performance high.</p>"},{"location":"user_guide/#data-and-model-monitoring","title":"Data and model monitoring","text":"<p>ML cube Platform implements data monitoring and model monitoring.  Model monitoring detects drifts and problems in the monitored AI model. Model monitoring means analyzing its performance metric (like RMSE, precision, or any custom performance metric) over time to detect deviations and negative trends before they will be problematic. Whenever a drift in the model performance is detected, an alarm is raised because the model needs to be updated with a new training data.</p> <p>Data monitoring processes the input and the ground truth. Detectors that monitor only the input check for input drift, i.e., a change in \\(P(X)\\) distribution, while detectors that monitor both input and ground truth check for concept drift i.e., change in \\(P(y | X)\\) distribution.</p> <p>Model and data monitoring are related and interdependent since the presence of a concept drift usually determines a model drift as well. They are used simultaneously to improve the overall detection quality.</p>"},{"location":"user_guide/#what-do-you-need-to-log-on-ml-cube-platform","title":"What do you need to log on ML cube Platform?","text":"<p>ML cube Platform's detection algorithms works at model level. Therefore, uploaded input data are the numeric features the model model receives as input to make inferece. Those data are the ones at the end of the data processing pipeline after the cleaning, feature extraction and normalization.</p> <p> </p> ML cube Platform in the ML inference pipeline."},{"location":"user_guide/#creating-a-baseline-with-reference-data","title":"Creating a baseline with Reference Data","text":"<p>Reference data are part of the datasets used during the development of the AI model: they contain training, validation, and test sets, i.e., anything the AI model saw during its training phase. Reference data are used to initialize data detectors calibrating them to what the model learnt.</p> <p>Reference data are not used to initialize the model detectors since the error on training set is not fair with respect the error with external data. Therefore, model detectors initialize themselves with production data assuming that the performance the AI model has in the first timesteps after the deployment belong to the same data distribution.</p>"},{"location":"user_guide/#improving-retraining-quality-with-historical-data","title":"Improving retraining quality with Historical Data","text":"<p>Historical data are composed of any dataset the customer has that were not used to train the AI model that is used in production (they potentially can be old training datasets of old models). Historical data are not used during the drift detection phase but during the retraining dataset selection phase. They are not mandatory, but their availability increase the quality and the information of the retraining dataset ML cube Platform provides to the customer. Indeed, ML cube Platform will use all the information available to provide the best dataset for retraining.  The historical data have the same format as the input data, therefore, they are data after the data processing pipeline.</p>"},{"location":"user_guide/#what-is-a-retraining-dataset","title":"What is a retraining dataset?","text":"<p>When a drift occurs, the AI model performance decreases. The retraining dataset is the new dataset ML cube Platform provides to the customer that should be used to retrain the AI model in order to increase the AI model performance. Conceptually, the retraining dataset is composed of the production data after the data drift with all the data that are similar to them. What ML cube Platform provides is a set of importance weights, one for each data sample belonging to the three data categories: historical, reference, production. The magnitude of the importance weights indicates how much the single sample is important for the current retraining. The customer integrates the weights in the training procedure using a weighted loss function. If the AI model does not support weighted loss function, ML cube Platform can provide a list of sample ids to use as training dataset.</p>"},{"location":"user_guide/basic_concepts/","title":"Basic Concepts","text":"<p>This page will explain you the basic concept of ML cube Platform to get familiar with the product.</p>"},{"location":"user_guide/basic_concepts/#company-project-task-and-model","title":"Company, Project, Task and Model","text":"<p>Everything starts with a Company, when you register on ML cube Platform, you are asked to create a Company. A Company has a Subscription Plan that defines how many Projects, Tasks, Data you can create. Moreover, billing and payments are done at Company level.</p> <p> </p> ML cube Platform entities structure. <p>After you created your Company you become the company owner, and as company owner, you can create new Users, assigning them the right Role.</p> <p>To help you to better understand the concepts and the entities in ML cube Platform we use a fictional company: it is called Delta Energy, and it is a producer of Photovoltaic Modules that own Photovoltaic fields and trades the energy to the market.</p> <p>After the Company is created, you can create a Project and AI Tasks inside it. Think of a Project as an application of Artificial Intelligence algorithms and techniques to optimize a KPI.</p> <p>Delta Energy created the Project Energy Revenue for increasing the revenue from trading the produced energy. They invested in four AI algorithms:</p> <ol> <li>Fault detection</li> <li>Fault diagnosis</li> <li>Soiling detection</li> <li>Trading</li> </ol> <p>In ML cube Platform, these four algorithms define four Tasks inside the Project Energy Revenue. They have been placed into the same Project because they share the business goal i.e., the net revenue, the data and are interdependent.</p> <p>Putting Tasks inside the same Project allows to leverage Tasks and data correlation having a comprehensive view of the problem.</p> <p>As you may have guessed, in ML cube Platform a Task corresponds to an AI Algorithm. To be more precise, a Task is an AI Problem with a dataset composed of input features and a target. A Task can have more than one AI Model that uses the input features estimates the target.</p> <p>In out example company, the Fault Detection Task has as input features the PV moduels and weather data and the target is the presence of a fault. The Task has two Models: logistic regression and random forest. Both models use the same data and predict the same target but are different in the techniques used to perform the estimation.</p> <p>The last entity is the Model that is the actual AI model that predicts the target. A Model has a Version that defines the training data used to train it. All model's data will be uploaded specifying the model version in order to track each prediction with the right model instance. The model version is updated whenever a new training of the model is done.</p> <p>It's worth nothing to note that in ML cube Platform you do not actually need to upload the model on the application. We just need to know its training data and its predictions for the production data. In this way, ML cube Platform is considered as model agnostic.</p>"},{"location":"user_guide/basic_concepts/#data-tassonomy","title":"Data Tassonomy","text":"<p>A Batch of data is composed of four types of data:</p> <ul> <li>metadata: additional information that AI models do not use as input but that are important to define the data or the samples. Mandatory for this category are the <code>sample-id</code>, a unique identifier for each sample used to avoid confusion and misinterpretation; and the <code>sample-timestamp</code>, a timestamp associated with each sample used for ordering. Moreover, the User can provide additional data used to segment the data space.  For instance, sensitive information like zip code or country are not used by AI models to prevent bias, however, ML cube Platform can use them to  check and prevent bias in the suggested retraining dataset or to perform segmented drift detection.</li> <li>input: set of input features the AI model uses to predict the output.  ML cube Platform uses the input data that come at the end of the processing data pipeline and not the raw data. This is due to the fact that ML cube Platform detects drifts in what the AI model uses and not in the general data the customer has.</li> <li>output: target quantity predicted by the AI models. It is present in the training data but can be not available for production data.</li> <li>models' predictions: predicted target for each AI model in the AI Task.</li> </ul>"},{"location":"user_guide/basic_concepts/#data-categories","title":"Data Categories","text":"<p>ML cube Platform are present three categories of data:</p> <ul> <li>Reference: represents the dataset used to train the model. Each model version has a reference dataset. Detection algorithms use reference data during their initialization.</li> <li>Production: represents data that comes from the production environment in which the AI model is operating. Detection algorithms analise production data to detect the presence of drifts.</li> <li>Historical: represents additional data that ML cube Platform can use to define the retraining dataset after a drift.</li> </ul> <p> </p> ML cube Platform data categories. <p>Delta Energy company trained its models using the data in the year 2022 and used the algorithms starting from the 2023. This means that the data in the 2022 are the reference data and every data from the january first 2023 are considered as production data. Data previous 2022 are historical data instead.</p>"},{"location":"user_guide/basic_concepts/#user-roles","title":"User Roles","text":"<p>Before to dive into details about the functionalities and modules covered, let's talk about the Role Based Access Control in ML cube Platform. As mentioned above, the company owner can create new Users assigning to them a Role. The Role defines the set of actions a User has inside the ML cube Platform. There are two levels of roles:</p> <ul> <li>Company: each User has a role inside the company.  The roles are Owner, Admin, Standard User.</li> <li>Project: by default a User does not have roles in a Project.  The Company Owner or Admin will assign a Project Role to User when needed. The roles are Admin, Edit User, View User.</li> </ul> <p> </p> User Roles in ML cube Platform. <p>Delta Energy has one dedicatd AI Team to each Task.  Hence, they assigned specific Project Administrator Role to each Team leader; while the other Data Scientists have the Project Edit Role for the project they are working on.</p>"},{"location":"user_guide/basic_concepts/#drift-detection","title":"Drift Detection","text":"<p>For each AI Task, ML cube Platform provides a set of Detectors that analyze different quantities of the Task. Data Detectors look at the Task's data without considering its AI models. They are resposible to identify input and concept drifts and more generally changes that happen in the data.</p> <p>Indeed, each Model has associated a Model Detector that analyses its performance metrics and detect negative trends.</p>"},{"location":"user_guide/basic_concepts/#retraining","title":"Retraining","text":"<p>A Data drift determines a drop in the model's performance that starts providing bad estimation or predictions. In Artificial Intelligence, Data plays a crucial role and usually, choosing the best data has higher impact in the resulting Model quality with respect to increasing the model complexity.</p> <p>ML cube Platform with its Retraining Tool Module provides you the best retraining dataset to use when updating the Model after a drift reducing the reaction time after the detection. Even if, the data has changed you can extract useful information from the past. ML cube Platform leverages all the available data belonging to the three categories: histrical, reference and production, computing an Importance Score to every data sample you have. These Importance Scores will be used during the training phase of your model as weights in the loss function.</p>"},{"location":"user_guide/basic_concepts/#model-life-cycle","title":"Model Life Cycle","text":"<p>ML cube Platform covers all the aspects of the post-deployment life cycle of your AI models:</p> <p> </p> Post-deployment AI model life cycle. <p>In Delta Energy data are collected every minute and are sent simultaneously to ML cube Platform. Ground truth data like the presence of a fault and the fault category are uploaded after they are available and therefore, they will sent with a delay compared the others.</p> <p>Drift alerting system is integrated with their Microsoft Teams and ML cube Platform sends alerts to the specified channels. After they receive an alerting message, they run a retraining pipeline that communicated with ML cube Platform to retrieve the retraining dataset to use. After that, they are ready to update the new version on ML cube Platform to start the monitoring.</p>"},{"location":"user_guide/glossary/","title":"Glossary","text":""},{"location":"user_guide/glossary/#general-terms","title":"General Terms","text":"<ul> <li>User: registered user with username and password that interact with ML cube Platform.  A User can create API keys that inherits his/her permissions and that the he/she uses to communicate with ML cube Platform though API. </li> <li>Company: collection of Users that work with ML cube Platform.  Subscription plan and contracts with ML cube are managed at Company level. A Company has one owner that has all the privileges and that can assign admin role to other Users in the Company.</li> <li>Project: collection of AI Tasks that belong to the same business domain.</li> <li>Task: it is the standard AI problem with a dataset, a target and a set of AI models that predicts the target. All AI models inside the AI Task predicts the same target quantity and they are considered as champion and challengers or deployed and shadow models. Data drift detection is done at Task level because the models uses the same dataset.</li> <li>Model: AI model inside a Task that makes predictions over the Task's dataset.</li> </ul>"},{"location":"user_guide/glossary/#data-terms","title":"Data Terms","text":"<ul> <li>Historical data: data not used for the newest retraining but that belong to the Task. ML cube Platform uses these data during the retraining dataset selection to exploit all the available information. They are not mandatory, if they are not present then the Retraining Tool selects data from the reference set and the production data.</li> <li>Reference data: dataset used as reference for the current model version. It can be the training dataset, the test set or both. Reference data represents the current view of the model over the Task</li> <li>Production data: data the model encounter during production, the production data are monitored by the ML cube Platform detectors to detect drifts</li> <li>Data schema: represents the schema of the data that ML cube Platform uses to know the features and the target columns.</li> </ul>"},{"location":"user_guide/glossary/#drifts-terms","title":"Drifts Terms","text":"<ul> <li>Input drift: statistically significant change in the input data P(X)</li> <li>Concept drift: statistically significant change in the input and target data P(X, y)</li> <li>Model drift: statistically significant change in the model error P(y \u2013 y_pred).</li> </ul>"},{"location":"user_guide/glossary/#actions-terms","title":"Actions Terms","text":"<ul> <li>Importance weights: the retraining dataset is given in form of a set of importance weights associated to every data available for the Task. This importance score will be used during the training pipeline of the customer to weights samples. In particular, the ML model will use the form of the sample weighted loss instead of the standard loss during its retraining phase</li> <li>Dataset boostrapping: if the ML model does not support the sample weighted loss then ML cube Platform can provide a dataset extracted from the available data using sampling with replacement based on the importance weights of the data. The customer can specify the size of the retraining dataset and ML cube Platform provides the best retraining bootstapped dataset of that size</li> <li>Relabeling: in case of concept drift in a classification Task, old labels are no meaningful, given a budget/size constraint ML cube Platform provides the subset of data to be relabelled</li> <li>Active Learning: ML cube Platform provides a set of new synthetic data to label or it provides indication where to collect new real data from the environment</li> </ul>"}]}