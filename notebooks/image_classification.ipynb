{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "\n",
    "This notebook demonstrates how to use the ML Cube Platform with image data. We utilize a Huggingface dataset and a pre-trained model for image classification. We load the validation data and split the dataset in two parts, using the first as reference data and the second as production data. \n",
    "\n",
    "In a real-world scenario, the training and validation datasets would be considered historical/reference data, while production data would come from the production environment after the model's deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With this example you will learn:**\n",
    "- how to create an image classification task\n",
    "- how to define a data schema\n",
    "- how to create a model\n",
    "- how to upload historical data\n",
    "- how to set a reference for the model\n",
    "- how to upload production data\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "These are the dependencies your Python environment is required to have in order to properly run this notebook.\n",
    "```\n",
    "ml3-platform-sdk>=0.0.22\n",
    "transformers[torch]==4.41.2\n",
    "torch==2.2.0\n",
    "datasets==2.15.0\n",
    "polars==0.20.31\n",
    "json==2.0.9\n",
    "numpy==1.26.4\n",
    "tqdm==4.66.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml3_platform_sdk import enums as ml3_enums\n",
    "from ml3_platform_sdk import models as ml3_models\n",
    "from ml3_platform_sdk.client import ML3PlatformClient\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import ViTImageProcessor, ViTModel, ViTForImageClassification\n",
    "import polars as pl\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://api.platform.mlcube.com'\n",
    "API_KEY = \"\"\n",
    "PROJECT_ID = ''\n",
    "model_name = 'mymodel'\n",
    "model_version = 'v0.0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, model and predictions\n",
    "Download dataset and model using Huggingface api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ethz/food101'\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only a subset of labels to reduce data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda example: example['label'] in LABELS).train_test_split(test_size=0.4, seed=42, stratify_by_column='label', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"train\"]['image']), len(dataset[\"test\"]['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the model and embedder classes. We use two wrappers to simplify the process of getting predictions and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.model = ViTModel.from_pretrained(\"nateraw/food\")\n",
    "        self.processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        with torch.no_grad():\n",
    "            return self.model(\n",
    "                **self.processor(images=images, return_tensors='pt')\n",
    "            ).last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.classifier = ViTForImageClassification.from_pretrained(\"nateraw/food\")\n",
    "        self.processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        with torch.no_grad():\n",
    "            return self.classifier(\n",
    "                **self.processor(images=images, return_tensors='pt')\n",
    "            ).logits.argmax(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "processor.do_normalize = False\n",
    "processor.do_rescale = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder()\n",
    "classifier_model = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data objects for ML cube Platform\n",
    "We will use local data sources to upload data. Hence, we need to create local files that will be shared with the ML cube Platform.\n",
    "Image data are sent as a zipped folder containing the image samples. An additional file (usually csv) is uploaded to map each image file name with its timestamp and sample id.\n",
    "Along with those two data it is possible to send custom embeddings of the images as a parquet file.\n",
    "Target and predictions can be sent as csv tabular files.\n",
    "\n",
    "Data are uploaded separately for each category:\n",
    "- **inputs:** ImageData object pointing to a zip folder containing jpg images;\n",
    "- **target:** TabularData object, pointing to csv file\n",
    "- **predictions:** TabularData object, also pointing to a csv file.\n",
    "\n",
    "When dealing with unstructured data like images, there are three ways to send them:\n",
    "1. Sending only embeddings, which are a numerical representation of the image sample as a vector, using `EmbeddingData`;\n",
    "2. Sending only the raw image, using `ImageData`. In this case ML cube Platform will create the numerical representation using internal encoders;\n",
    "3. Sending the raw image and its embeddings using `ImageData` with the `embedding_source` attribute. This more complete option has two benefits: it allows the usage of a personal embedder, which is usually focused on the domain rather than a general one, and it enables the extraction of additional metrics from the image, providing more functionalities in the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_objects(\n",
    "    dataset,\n",
    "    model,\n",
    "    embedder,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    starting_id: int,\n",
    "    starting_timestamp: float,\n",
    "    prefix: str,\n",
    ") -> tuple[\n",
    "    ml3_models.ImageData,\n",
    "    ml3_models.TabularData,\n",
    "    ml3_models.TabularData,\n",
    "    int,\n",
    "    float\n",
    "]:\n",
    "    \"\"\"Builds data objects for inputs, target and predictions.\n",
    "    \n",
    "    Since each sample has associated an id and a timestamp we generate \n",
    "    them as incremental counters.\n",
    "    Therefore, we need a starting point for both.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dataset: huggingface dataset\n",
    "    starting_id: sample id to start from\n",
    "    starting_timestamp: timestamp to start from\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    image_data, last_sample_id, last_timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = len(dataset['image'])\n",
    "    next_starting_sample_id = starting_id + n_samples\n",
    "    sample_ids = list(map(lambda x: f'sample_{x}', range(starting_id, starting_id + n_samples)))\n",
    "    # each sample has a time delta of 2 minutes\n",
    "    next_starting_timestamp = starting_timestamp + n_samples * 120\n",
    "    timestamps = list(np.arange(starting_timestamp, starting_timestamp + n_samples * 120, 120))\n",
    "\n",
    "    # Create inputs embedding file and save it\n",
    "    print('Creating image file')\n",
    "    with tempfile.TemporaryDirectory() as image_dir:\n",
    "        \n",
    "        image_names = []\n",
    "        mapping_samples = []\n",
    "        for (i, sample) in enumerate(dataset['image']):\n",
    "            file_name = f'sample_{i}.jpg'\n",
    "            image = Image.fromarray(processor(sample)['pixel_values'][0].transpose([1, 2, 0]))\n",
    "            image.convert('RGB').save(os.path.join(image_dir, file_name))\n",
    "            image_names.append(file_name)\n",
    "            mapping_samples.append(file_name)\n",
    "    \n",
    "        # save mapping dataframe\n",
    "        mapping = pl.DataFrame({\n",
    "            'sample-id': sample_ids,\n",
    "            'timestamp': timestamps,\n",
    "            'file_name': image_names,\n",
    "        })\n",
    "        mapping.write_csv(f'{prefix}_mapping.csv')\n",
    "\n",
    "        # compress images folder as zip\n",
    "        shutil.make_archive(f'{prefix}_images', 'zip', image_dir)\n",
    "        \n",
    "        # Create embedding dataframe\n",
    "        embedding_list = []\n",
    "        for sample in tqdm.tqdm(dataset['image']):\n",
    "            embedding_list.append(embedder(sample).tolist()[0])\n",
    "        print('Creating embedding file')\n",
    "        embeddings = pl.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "            'embedding': embedding_list\n",
    "        })\n",
    "        embeddings.write_parquet(f'{prefix}_embeddings.parquet')\n",
    "    \n",
    "        print('Creating target file')\n",
    "        target = pl.DataFrame({\n",
    "            'label': dataset['label'],\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "        })\n",
    "        target.write_csv(f'{prefix}_target.csv')\n",
    "    \n",
    "        print('Creating predictions file')\n",
    "        predicted_labels = []\n",
    "        for sample in tqdm.tqdm(dataset['image']):\n",
    "            prediction = model(sample).item()\n",
    "            if prediction not in LABELS:\n",
    "                prediction = LABELS[0]\n",
    "            predicted_labels.append(prediction)\n",
    "            \n",
    "        predictions = pl.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "            f'{model_name}@{model_version}': predicted_labels,\n",
    "        })\n",
    "        predictions.write_csv(f'{prefix}_predictions.csv')\n",
    "    \n",
    "        print('Creating inputs data')\n",
    "        inputs_data = ml3_models.ImageData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.JPG,\n",
    "                is_folder=True,\n",
    "                folder_type=ml3_enums.FolderType.ZIP,\n",
    "                file_path=f'{prefix}_images.zip'\n",
    "            ),\n",
    "            mapping_source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_mapping.csv'\n",
    "            ),\n",
    "            embedding_source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.PARQUET,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_embeddings.parquet',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        print('Creating target data')\n",
    "        target_data = ml3_models.TabularData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_target.csv'\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        print('Creating predictions data')\n",
    "        predictions_data = ml3_models.TabularData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_predictions.csv'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            inputs_data,\n",
    "            target_data,\n",
    "            predictions_data,\n",
    "            next_starting_sample_id,\n",
    "            next_starting_timestamp\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_initial_sample_id = 0\n",
    "training_initial_timestamp = datetime.datetime.now().timestamp()\n",
    "\n",
    "(\n",
    "    training_inputs_data,\n",
    "    training_target_data,\n",
    "    _,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    ") = build_data_objects(\n",
    "    dataset[\"train\"],\n",
    "    classifier_model,\n",
    "    embedder,\n",
    "    model_name,\n",
    "    model_version,\n",
    "    training_initial_sample_id,\n",
    "    training_initial_timestamp,\n",
    "    'train'\n",
    ")\n",
    "training_end_timestamp = starting_timestamp - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    production_0_inputs_data,\n",
    "    production_0_target_data,\n",
    "    production_0_prediction_data,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    ") = build_data_objects(\n",
    "    dataset[\"test\"],\n",
    "    classifier_model,\n",
    "    embedder,\n",
    "    model_name,\n",
    "    model_version,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    "    'prod_0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data schema\n",
    "\n",
    "The data schema describes the data used in the task, with their specific names.\n",
    "A data schema contains:\n",
    "- *sample id*, column that is used to uniquely identify each sample\n",
    "- *timestamp*, column that is used to order samples\n",
    "- *input*, column that specifies the nature of the input. In this case, it's an ARRAY_3 representing the image\n",
    "- *input additional embedding*, optional column for the embedding of the image data\n",
    "- *target*, column that specifies the nature of the target. In this case, categorical with three possible values\n",
    "\n",
    "The prediction column must not be specified because it will be automatically added during the model creation, with a name like `MODEL_NAME@MODEL_VERSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = ml3_models.DataSchema(\n",
    "    columns=[\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='timestamp',\n",
    "            role=ml3_enums.ColumnRole.TIME_ID,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.FLOAT,\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='sample-id',\n",
    "            role=ml3_enums.ColumnRole.ID,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.STRING,\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='image',\n",
    "            role=ml3_enums.ColumnRole.INPUT,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.ARRAY_3,\n",
    "            dims=(224, 224, 3),\n",
    "            image_mode=ml3_enums.ImageMode.RGB\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name=\"embedding\",\n",
    "            role=ml3_enums.ColumnRole.INPUT_ADDITIONAL_EMBEDDING,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.ARRAY_1,\n",
    "            dims=(768,),\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='label',\n",
    "            role=ml3_enums.ColumnRole.TARGET,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.CATEGORICAL,\n",
    "            possible_values=LABELS\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with ML cube Platform\n",
    "To start, we create an instance of ML cube Platform client using the provided api key.\n",
    "Then, we create a task, a dataschema, a model and finally we upload data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ML3PlatformClient(URL, API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a task there are some information we need to specify:\n",
    "- **task_type:** artificial intelligence task type. In this case it is a multiclass classification.\n",
    "- **data_structure:** the type of input data. In this case, it is Image.\n",
    "- **optional_target:** if the target can be missing for production data. We assume that reference data, being the training data, always have the target.\n",
    "    However, it is possible that target is not available in other historical data or production data. By enabling the optional target option, the ML cube Platform will not check its presence in the data sent to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = client.create_task(\n",
    "    project_id=PROJECT_ID,\n",
    "    name='image_task',\n",
    "    tags=[\"tag_1\", \"tag_2\"],\n",
    "    task_type=ml3_enums.TaskType.CLASSIFICATION_MULTICLASS,\n",
    "    data_structure=ml3_enums.DataStructure.IMAGE,\n",
    "    optional_target=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_data_schema(task_id=task_id, data_schema=data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is uniquely identified by its `name` and the `model version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = client.create_model(\n",
    "    task_id=task_id,\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    metric_name=ml3_enums.ModelMetricName.ACCURACY,\n",
    "    preferred_suggestion_type=ml3_enums.SuggestionType.SAMPLE_WEIGHTS,\n",
    "    with_probabilistic_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data are uploaded as historical data i.e., any data that do not come from production.\n",
    "Then we indicate them as reference data of our model in order to set up the detection algorithms.\n",
    "\n",
    "Note that it is possible to add other historical data in any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.add_historical_data(\n",
    "    task_id=task_id,\n",
    "    inputs=training_inputs_data,\n",
    "    target=training_target_data\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.set_model_reference(\n",
    "    model_id,\n",
    "    from_timestamp=training_initial_timestamp,\n",
    "    to_timestamp=training_end_timestamp,\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to upload production data.\n",
    "Production data can be uploaded asynchronously, that means that we can upload each data category whenever, it is available without waiting for the others.\n",
    "This is specially true for *target* data that usually are available with an amount of delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.add_production_data(\n",
    "    task_id=task_id,\n",
    "    inputs=production_0_inputs_data,\n",
    "    target=production_0_target_data,\n",
    "    predictions=[(model_id, production_0_prediction_data)]\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
