{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "\n",
    "This notebook shows how to use ML cube Platform with image data.\n",
    "We use a Huggingface dataset and trained model for image classification.\n",
    "The dataset contains train and validation sets, we use train as reference dataset while validation as production data.\n",
    "Of course, in a real scenario all those dataset will be part of historical/reference data and production will come from the production environment after the deployment of the algorithm.\n",
    "\n",
    "**With this example you will learn:**\n",
    "- how to create an image classification task\n",
    "- how to define a data schema\n",
    "- how to create a model\n",
    "- how to upload historical data\n",
    "- how to set reference for the model\n",
    "- how to upload production data\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "In order to properly run this notebook the Python environment has those requirements.\n",
    "```\n",
    "ml3-platform-sdk>=0.0.15\n",
    "transformers[torch]==4.41.2\n",
    "torch==2.2.0\n",
    "datasets==2.15.0\n",
    "polars==0.20.31\n",
    "json==2.0.9\n",
    "numpy==1.26.4\n",
    "tqdm==4.66.4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml3_platform_sdk import enums as ml3_enums\n",
    "from ml3_platform_sdk import models as ml3_models\n",
    "from ml3_platform_sdk.client import ML3PlatformClient\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import ViTImageProcessor, ViTModel, ViTForImageClassification\n",
    "import polars as pl\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://api.platform.mlcube.com'\n",
    "API_KEY = \"\"\n",
    "PROJECT_ID = ''\n",
    "model_name = 'mymodel'\n",
    "model_version = 'v0.0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, model and predictions\n",
    "Download dataset and model using Huggingface api.\n",
    "After the dataset and the model are downloaded we run the model to get predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ethz/food101\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only a subset of labels to reduce data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset, classes, fraction=0.05, seed=42):\n",
    "    sampled_dataset = DatasetDict()\n",
    "    for split in dataset.keys():\n",
    "        sampled_dataset[split] = dataset[split].filter(lambda example: example['label'] in classes)\n",
    "        if fraction is not None:\n",
    "            sampled_dataset[split] = sampled_dataset[split].train_test_split(test_size=fraction, seed=seed)['test']\n",
    "    return sampled_dataset\n",
    "\n",
    "# Perform the sampling\n",
    "dataset = sample_dataset(dataset, LABELS, fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['train']['image']), len(dataset['validation']['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model pipeline, we use two wrappers to simplify the way to get predictions and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder():\n",
    "    def __init__(self):\n",
    "        self.model = ViTModel.from_pretrained(\"nateraw/food\")\n",
    "        self.processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        with torch.no_grad():\n",
    "            return self.model(\n",
    "                **self.processor(images=images, return_tensors='pt')\n",
    "            ).last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self):\n",
    "        self.classifier = ViTForImageClassification.from_pretrained(\"nateraw/food\")\n",
    "        self.processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        with torch.no_grad():\n",
    "            return self.classifier(\n",
    "                **self.processor(images=images, return_tensors='pt')\n",
    "            ).logits.argmax(-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "processor.do_normalize = False\n",
    "processor.do_rescale = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder()\n",
    "classifier_model = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data objects for ML cube Platform\n",
    "We use local data sources to upload data, hence, we need to create local files that will be shared with ML cube Platform.\n",
    "Image data are sent as a zipped folder containing one image sample, an additional file (usually csv) is uploaded to map image file name with timestamp and sample id.\n",
    "Along with those two data it is possible to send custom emeddings of the images as a parquet file.\n",
    "While target and predictions can be sent as csv tabular files.\n",
    "\n",
    "In ML cube Platform data are uploaded separately for each category:\n",
    "- **inputs:** ImageData object in json format\n",
    "- **target:** TabularData object in csv format\n",
    "- **predictions:** TabularData object in csv format\n",
    "\n",
    "\n",
    "When dealing with unstructured data like image it is possible to send them in three ways:\n",
    "1. By sending only embeddings i.e., a numerical representation of the image sample as a vector, using `EmbeddingData`;\n",
    "2. By sending only unstructured image, using `ImageData`. In this case ML cube Platform will create the numerical representation using internal encoders;\n",
    "3. By sending ustructured image along with embeddings using `ImageData` with `embedding_source` attribute. This more complete option has two benefits, the first is the usage of personal embedder that usually is focused on the domain instead of a general one; the other is using image to extract additional metrics and to have full capability in the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_objects(\n",
    "    dataset,\n",
    "    model,\n",
    "    embedder,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    starting_id: int,\n",
    "    starting_timestamp: float,\n",
    "    prefix: str,\n",
    ") -> tuple[\n",
    "    ml3_models.ImageData,\n",
    "    ml3_models.TabularData,\n",
    "    ml3_models.TabularData,\n",
    "    int,\n",
    "    float\n",
    "]:\n",
    "    \"\"\"Builds data objects for inputs, target and predictions.\n",
    "    \n",
    "    Since each sample has associated an id and a timestamp we generate \n",
    "    them as incremental counters.\n",
    "    Therefore, we need a starting point for both.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dataset: huggingface dataset\n",
    "    starting_id: sample id to start from\n",
    "    starting_timestamp: timestamp to start from\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    image_data, last_sample_id, last_timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = len(dataset['image'])\n",
    "    next_starting_sample_id = starting_id + n_samples\n",
    "    sample_ids = list(map(lambda x: f'sample_{x}', range(starting_id, starting_id + n_samples)))\n",
    "    # each sample has a time delta of 2 minutes\n",
    "    next_starting_timestamp = starting_timestamp + n_samples * 120\n",
    "    timestamps = list(np.arange(starting_timestamp, starting_timestamp + n_samples * 120, 120))\n",
    "\n",
    "    # Create inputs embedding file and save it\n",
    "    print('Creating image file')\n",
    "    with tempfile.TemporaryDirectory() as image_dir:\n",
    "        \n",
    "        image_names = []\n",
    "        mapping_samples = []\n",
    "        for (i, sample) in enumerate(dataset['image']):\n",
    "            file_name = f'sample_{i}.jpg'\n",
    "            image = Image.fromarray(processor(sample)['pixel_values'][0].transpose([1, 2, 0]))\n",
    "            image.convert('RGB').save(os.path.join(image_dir, file_name))\n",
    "            image_names.append(file_name)\n",
    "            mapping_samples.append(file_name)\n",
    "    \n",
    "        # save mapping dataframe\n",
    "        mapping = pl.DataFrame({\n",
    "            'sample-id': sample_ids,\n",
    "            'timestamp': timestamps,\n",
    "            'file_name': image_names,\n",
    "        })\n",
    "        mapping.write_csv(f'{prefix}_mapping.csv')\n",
    "\n",
    "        # compress images folder as zip\n",
    "        shutil.make_archive(f'{prefix}_images', 'zip', image_dir)\n",
    "        \n",
    "        # Create embedding dataframe\n",
    "        embedding_list = []\n",
    "        for sample in tqdm.tqdm(dataset['image']):\n",
    "            embedding_list.append(embedder(sample).tolist()[0])\n",
    "        print('Creating embedding file')\n",
    "        embeddings = pl.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "            'embedding': embedding_list\n",
    "        })\n",
    "        embeddings.write_parquet(f'{prefix}_embeddings.parquet')\n",
    "    \n",
    "        print('Creating target file')\n",
    "        target = pl.DataFrame({\n",
    "            'label': dataset['label'],\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "        })\n",
    "        target.write_csv(f'{prefix}_target.csv')\n",
    "    \n",
    "        print('Creating predictions file')\n",
    "        predicted_labels = []\n",
    "        for sample in tqdm.tqdm(dataset['image']):\n",
    "            prediction = model(sample).item()\n",
    "            if prediction not in LABELS:\n",
    "                prediction = LABELS[0]\n",
    "            predicted_labels.append(prediction)\n",
    "            \n",
    "        predictions = pl.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'sample-id': sample_ids,\n",
    "            f'{model_name}@{model_version}': predicted_labels,\n",
    "        })\n",
    "        predictions.write_csv(f'{prefix}_predictions.csv')\n",
    "    \n",
    "        print('Creating inputs data')\n",
    "        inputs_data = ml3_models.ImageData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.JPG,\n",
    "                is_folder=True,\n",
    "                folder_type=ml3_enums.FolderType.ZIP,\n",
    "                file_path=f'{prefix}_images.zip'\n",
    "            ),\n",
    "            mapping_source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_mapping.csv'\n",
    "            ),\n",
    "            embedding_source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.PARQUET,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_embeddings.parquet',\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        print('Creating target data')\n",
    "        target_data = ml3_models.TabularData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_target.csv'\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        print('Creating predictions data')\n",
    "        predictions_data = ml3_models.TabularData(\n",
    "            source=ml3_models.LocalDataSource(\n",
    "                file_type=ml3_enums.FileType.CSV,\n",
    "                is_folder=False,\n",
    "                folder_type=None,\n",
    "                file_path=f'{prefix}_predictions.csv'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            inputs_data,\n",
    "            target_data,\n",
    "            predictions_data,\n",
    "            next_starting_sample_id,\n",
    "            next_starting_timestamp\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_initial_sample_id = 0\n",
    "training_initial_timestamp = datetime.datetime.now().timestamp()\n",
    "\n",
    "(\n",
    "    training_inputs_data,\n",
    "    training_target_data,\n",
    "    _,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    ") = build_data_objects(\n",
    "    dataset['train'],\n",
    "    classifier_model,\n",
    "    embedder,\n",
    "    model_name,\n",
    "    model_version,\n",
    "    training_initial_sample_id,\n",
    "    training_initial_timestamp,\n",
    "    'train'\n",
    ")\n",
    "training_end_timestamp = starting_timestamp - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    production_0_inputs_data,\n",
    "    production_0_target_data,\n",
    "    production_0_prediction_data,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    ") = build_data_objects(\n",
    "    dataset['validation'],\n",
    "    classifier_model,\n",
    "    embedder,\n",
    "    model_name,\n",
    "    model_version,\n",
    "    starting_id,\n",
    "    starting_timestamp,\n",
    "    'prod_0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data schema\n",
    "\n",
    "The data schema specifies the type of data present in the task with their specific names.\n",
    "A data schema must contain:\n",
    "- *sample id* column that is used to uniquely identify each sample\n",
    "- *timestamp* column that is used to order samples\n",
    "- *input* column that specify the nature of the input. In this case IMAGE\n",
    "- *input additional embedding* optional column for additional embedding of the image data\n",
    "- *target* column that specify the nature of the target. In this case categorical with three values\n",
    "\n",
    "Prediction column must not be specified because it will be automatically added during the model creation with the name like MODEL_NAME@MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = ml3_models.DataSchema(\n",
    "    columns=[\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='timestamp',\n",
    "            role=ml3_enums.ColumnRole.TIME_ID,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.FLOAT,\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='sample-id',\n",
    "            role=ml3_enums.ColumnRole.ID,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.STRING,\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='image',\n",
    "            role=ml3_enums.ColumnRole.INPUT,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.ARRAY_3,\n",
    "            dims=(224, 224, 3)\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name=\"embedding\",\n",
    "            role=ml3_enums.ColumnRole.INPUT_ADDITIONAL_EMBEDDING,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.ARRAY_1,\n",
    "            dims=(768,),\n",
    "        ),\n",
    "        ml3_models.ColumnInfo(\n",
    "            name='label',\n",
    "            role=ml3_enums.ColumnRole.TARGET,\n",
    "            is_nullable=False,\n",
    "            data_type=ml3_enums.DataType.CATEGORICAL,\n",
    "            possible_values=LABELS\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with ML cube Platform\n",
    "To start, we create an instance of ML cube Platform client using the provided api key.\n",
    "Then, we create a task, a dataschema, a model and finally we upload data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ML3PlatformClient(URL, API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a task there are some information we need to specify:\n",
    "- **task_type:** artificial intelligence task type. In this case it is a multiclass classification\n",
    "- **data_structure:** the type of input data. In this case it is Image\n",
    "- **optional_target:** if the target can be missing for production data.\n",
    "    We assume that reference data being the training one always have the target.\n",
    "    However, it is possible that ofr other historical data or for production data target is not available, enabling this option, ML cube Platform does not force its presence and it will not stop breaks the jobs.\n",
    "- **cost_info**, this optional field allows to specify the costs of the error of the model and will be used during the retraining report computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = client.create_task(\n",
    "    project_id=PROJECT_ID,\n",
    "    name='image_task',\n",
    "    tags=[\"tag_1\", \"tag_2\"],\n",
    "    task_type=ml3_enums.TaskType.CLASSIFICATION_MULTICLASS,\n",
    "    data_structure=ml3_enums.DataStructure.IMAGE,\n",
    "    optional_target=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_data_schema(task_id=task_id, data_schema=data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we added the data schema, we are able to create our model.\n",
    "\n",
    "A model is uniquely identified by `name` and `model version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = client.create_model(\n",
    "    task_id=task_id,\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    metric_name=ml3_enums.ModelMetricName.ACCURACY,\n",
    "    preferred_suggestion_type=ml3_enums.SuggestionType.SAMPLE_WEIGHTS,\n",
    "    with_probabilistic_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data are uploaded as historical data i.e., any data that do not come from production.\n",
    "Then we indicate them as reference data of our model in order to set up the detection algorithms.\n",
    "\n",
    "Note that it is possible to add other historical data in any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.add_historical_data(\n",
    "    task_id=task_id,\n",
    "    inputs=training_inputs_data,\n",
    "    target=training_target_data\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.set_model_reference(\n",
    "    model_id,\n",
    "    from_timestamp=training_initial_timestamp,\n",
    "    to_timestamp=training_end_timestamp,\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to upload production data.\n",
    "Production data can be uploaded asynchronously, that means that we can upload each data category whenever, it is available without waiting for the others.\n",
    "This is specially true for *target* data that usually are available with an amount of delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.add_production_data(\n",
    "    task_id=task_id,\n",
    "    inputs=production_0_inputs_data,\n",
    "    target=production_0_target_data,\n",
    "    predictions=[(model_id, production_0_prediction_data)]\n",
    ")\n",
    "print(f'Waiting for job {job_id}')\n",
    "client.wait_job_completion(job_id=job_id)\n",
    "print(f'Job {job_id} completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
